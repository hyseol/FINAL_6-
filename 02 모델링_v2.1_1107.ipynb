{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "N44QYORV8wFy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1qAeLjZVWZz"
   },
   "source": [
    "- 시드값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nVyhJ6uOVVNE"
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd7JpzNBHa1"
   },
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KFGKUIWt89fZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523105, 7), (14940, 2), (441196, 7), (12225, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Data/\"\n",
    "train_tr = pd.read_csv(f\"{DATA_PATH}store_train_transactions.csv\") # 학습용 구매기록 데이터\n",
    "train_target = pd.read_csv(f\"{DATA_PATH}store_train.csv\") # 학습용 정답 데이터\n",
    "test_tr = pd.read_csv(f\"{DATA_PATH}store_test_transactions.csv\") # 테스트용 구매기록 데이터\n",
    "submit = pd.read_csv(f\"{DATA_PATH}store_submission.csv\") # 제출 양식 데이터\n",
    "\n",
    "train_tr.shape , train_target.shape , test_tr.shape , submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZq4x4CuP2gr"
   },
   "source": [
    "- 공통 피처 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "T3tcFrkLPv1g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1455), (12225, 1455))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.2_1107.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.2_1107.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r43SCHUujW-f"
   },
   "source": [
    "# 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.isnull().sum().sum(), test_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgPa4QG0RF2d"
   },
   "source": [
    "# 특성 공학(Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXuo6unbRLGm"
   },
   "source": [
    "- ID 변수 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xfksFVguRFuZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1454), (12225, 1454))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjuSj8URRa_q"
   },
   "source": [
    "- 추가 피처 만들어 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "EQaqdQSARFr4"
   },
   "outputs": [],
   "source": [
    "# cols = [ col for col in train_ft.columns if col.startswith(\"pivot_cnt_\") ]\n",
    "\n",
    "# train_ft[\"중분류별_구매횟수_std\"] = train_ft[cols].std(axis=1)\n",
    "# train_ft[\"중분류별_구매횟수_skew\"] = train_ft[cols].skew(axis=1)\n",
    "# train_ft[\"중분류별_구매횟수_kurt\"] = train_ft[cols].kurt(axis=1)\n",
    "\n",
    "# test_ft[\"중분류별_구매횟수_std\"] = test_ft[cols].std(axis=1)\n",
    "# test_ft[\"중분류별_구매횟수_skew\"] = test_ft[cols].skew(axis=1)\n",
    "# test_ft[\"중분류별_구매횟수_kurt\"] = test_ft[cols].kurt(axis=1)\n",
    "\n",
    "# train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXvdNLMtSVlW"
   },
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0YvdL9OVSRab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3d6B3II8T25p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1458), (12225, 1458))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "q0ztgmEMRFpN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1460), (12225, 1460))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "# train_ft[\"주구매지점_cnt\"] = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "# test_ft[\"주구매지점_cnt\"] = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPURwRnPUj-B"
   },
   "source": [
    "- 문자열 피처 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "suLVrqBCRFmK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['주구매지점', '주구매_대분류', '주구매_중분류']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "zZlZoAMZUbGp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1457), (12225, 1457))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1-y4-kmTUmso"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object'), Index([], dtype='object'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.select_dtypes(\"object\").columns , test_ft.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAQ-3TU5U0Pk"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가중치 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft[\"18시_21시_구매비율\"] = train_ft[\"18시_21시_구매비율\"] * 3\n",
    "train_ft[\"18시_21시_구매횟수\"] = train_ft[\"18시_21시_구매횟수\"] * 3\n",
    "\n",
    "test_ft[\"18시_21시_구매비율\"] = test_ft[\"18시_21시_구매비율\"] * 3\n",
    "test_ft[\"18시_21시_구매횟수\"] = test_ft[\"18시_21시_구매횟수\"] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "vyDpuu4OUmnO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>내점일수</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>평일방문비율</th>\n",
       "      <th>주말방문횟수</th>\n",
       "      <th>평일방문횟수</th>\n",
       "      <th>봄_구매비율</th>\n",
       "      <th>여름_구매비율</th>\n",
       "      <th>가을_구매비율</th>\n",
       "      <th>겨울_구매비율</th>\n",
       "      <th>...</th>\n",
       "      <th>공휴일_대분류_영플라자_구매횟수</th>\n",
       "      <th>공휴일_대분류_잡화_구매횟수</th>\n",
       "      <th>공휴일_대분류_케주얼_구두_아동_구매횟수</th>\n",
       "      <th>공휴일_대분류_패션잡화_구매횟수</th>\n",
       "      <th>주구매지점_1</th>\n",
       "      <th>주구매지점_2</th>\n",
       "      <th>주구매지점_3</th>\n",
       "      <th>주구매지점_4</th>\n",
       "      <th>주구매_중분류_cnt</th>\n",
       "      <th>주구매_대분류_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369867</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.257728</td>\n",
       "      <td>-0.257728</td>\n",
       "      <td>-0.230862</td>\n",
       "      <td>-0.390544</td>\n",
       "      <td>-1.029777</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.838272</td>\n",
       "      <td>0.338186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>-0.209907</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.741478</td>\n",
       "      <td>-1.315250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144110</td>\n",
       "      <td>-0.356452</td>\n",
       "      <td>-1.008554</td>\n",
       "      <td>1.008554</td>\n",
       "      <td>-0.619841</td>\n",
       "      <td>0.412809</td>\n",
       "      <td>0.323951</td>\n",
       "      <td>-0.390607</td>\n",
       "      <td>0.620171</td>\n",
       "      <td>-0.552996</td>\n",
       "      <td>...</td>\n",
       "      <td>2.389509</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>-0.209907</td>\n",
       "      <td>4.161199</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>1.604686</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.448069</td>\n",
       "      <td>-0.626416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.943028</td>\n",
       "      <td>-0.869935</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>-0.036742</td>\n",
       "      <td>1.616788</td>\n",
       "      <td>1.926821</td>\n",
       "      <td>0.798943</td>\n",
       "      <td>-0.514333</td>\n",
       "      <td>-0.304527</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>-0.209907</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>1.632592</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.869072</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.793345</td>\n",
       "      <td>-1.023980</td>\n",
       "      <td>-0.080558</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>3.172703</td>\n",
       "      <td>4.429574</td>\n",
       "      <td>0.420933</td>\n",
       "      <td>-0.327474</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>-0.135636</td>\n",
       "      <td>...</td>\n",
       "      <td>10.044273</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>1.301424</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>1.515861</td>\n",
       "      <td>-0.248364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452496</td>\n",
       "      <td>-0.613193</td>\n",
       "      <td>0.302875</td>\n",
       "      <td>-0.302875</td>\n",
       "      <td>0.838830</td>\n",
       "      <td>0.567300</td>\n",
       "      <td>-0.752532</td>\n",
       "      <td>1.707410</td>\n",
       "      <td>-0.130285</td>\n",
       "      <td>-0.821561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>4.377687</td>\n",
       "      <td>4.324087</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.847712</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       내점일수      구매주기    주말방문비율    평일방문비율    주말방문횟수    평일방문횟수    봄_구매비율  \\\n",
       "0 -0.369867  0.002987  0.257728 -0.257728 -0.230862 -0.390544 -1.029777   \n",
       "1  0.144110 -0.356452 -1.008554  1.008554 -0.619841  0.412809  0.323951   \n",
       "2  1.943028 -0.869935  0.036742 -0.036742  1.616788  1.926821  0.798943   \n",
       "3  3.793345 -1.023980 -0.080558  0.080558  3.172703  4.429574  0.420933   \n",
       "4  0.452496 -0.613193  0.302875 -0.302875  0.838830  0.567300 -0.752532   \n",
       "\n",
       "    여름_구매비율   가을_구매비율   겨울_구매비율  ...  공휴일_대분류_영플라자_구매횟수  공휴일_대분류_잡화_구매횟수  \\\n",
       "0  0.001191  0.838272  0.338186  ...          -0.162079        -0.286379   \n",
       "1 -0.390607  0.620171 -0.552996  ...           2.389509        -0.286379   \n",
       "2 -0.514333 -0.304527 -0.059266  ...          -0.162079        -0.286379   \n",
       "3 -0.327474  0.008592 -0.135636  ...          10.044273        -0.286379   \n",
       "4  1.707410 -0.130285 -0.821561  ...          -0.162079         4.377687   \n",
       "\n",
       "   공휴일_대분류_케주얼_구두_아동_구매횟수  공휴일_대분류_패션잡화_구매횟수   주구매지점_1   주구매지점_2   주구매지점_3  \\\n",
       "0               -0.209907          -0.213001  1.654066 -0.623175 -0.612523   \n",
       "1               -0.209907           4.161199 -0.604571  1.604686 -0.612523   \n",
       "2               -0.209907          -0.213001 -0.604571 -0.623175  1.632592   \n",
       "3                1.301424          -0.213001  1.654066 -0.623175 -0.612523   \n",
       "4                4.324087          -0.213001  1.654066 -0.623175 -0.612523   \n",
       "\n",
       "    주구매지점_4  주구매_중분류_cnt  주구매_대분류_cnt  \n",
       "0 -0.468181    -0.741478    -1.315250  \n",
       "1 -0.468181    -0.448069    -0.626416  \n",
       "2 -0.468181    -0.869072     1.064726  \n",
       "3 -0.468181     1.515861    -0.248364  \n",
       "4 -0.468181    -0.847712     1.064726  \n",
       "\n",
       "[5 rows x 1457 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)\n",
    "train_ft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlmnx5QsU8_x"
   },
   "source": [
    "# 정답 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sawXnAciUmkJ"
   },
   "outputs": [],
   "source": [
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXinfWehVH4-"
   },
   "source": [
    "# cv 점수 확인해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Macro Score: 0.7184464536223091\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {'n_estimators': 800,\n",
    " 'learning_rate': 0.04036413044768581,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.7505214930635562,\n",
    " 'colsample_bytree': 0.6290102054237857,\n",
    " 'gamma': 0.648553153047272}\n",
    "\n",
    "# F1 매크로 스코어와 모델을 저장할 리스트\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "# Stratified K-Fold 교차 검증 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 루프\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "    # 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "\n",
    "    # 모델 초기화 및 학습\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)   \n",
    "    \n",
    "    # 모델 저장\n",
    "    models.append(model)\n",
    "\n",
    "    # 예측 및 F1 매크로 스코어 계산\n",
    "    pred = model.predict(x_valid)\n",
    "    score = f1_score(y_valid, pred, average='macro')\n",
    "    scores.append(score)\n",
    "\n",
    "# F1 매크로 스코어의 평균 출력\n",
    "print(\"Mean F1 Macro Score:\", np.mean(scores))\n",
    "\n",
    "\n",
    "# v3.0 원핫 + 스탠다드 : 0.7195019304392802\n",
    "# submit_v3.0_02 : 원핫(주구매지점) + 카운트(주구매대분류, 주구매중분류) + 스탠다드  (0.7202916471187197)\n",
    "# submit_v3.0_02 : 원핫(주구매지점) + 카운트(주구매대분류, 주구매중분류) + 스탠다드 + 가중치적용  ( 0.7202916471187197 )\n",
    "# 3.2 셋다 카운트 + 스탠다드 (0.7184464536223091)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rY6xQ68PVGwP"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# cv = KFold(n_splits=5,shuffle=True, random_state=SEED)\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# model = LGBMClassifier(random_state=SEED)\n",
    "# scores = cross_val_score(model,train_ft,target,cv = cv ,scoring='f1_macro',n_jobs = -1)\n",
    "# np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16GsDHp0VGtd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6290102054237857, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.648553153047272,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.04036413044768581,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6290102054237857, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.648553153047272,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.04036413044768581,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6290102054237857, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.648553153047272,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.04036413044768581,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(**params)\n",
    "model.fit(train_ft,target)\n",
    "pred = model.predict(test_ft)\n",
    "submit[\"target\"] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjw87GeIV-BP"
   },
   "source": [
    "- 예측 결과를 csv 파일로 저장하여 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "SsLTeJeoWBc_"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'C:/Users/user/Desktop/데이터분석/05 Project_Final/Submit_csv/'\n",
    "submit.to_csv(f\"{DATA_PATH}submit_v3.0_1106.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSU2eoSNVGn4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*70,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"eval_method\": \"cv\",                 # 교차 검증\n",
    "           \"n_splits\": 10,                      # Stratified K-Fold로 10분할 교차 검증\n",
    "           \"ensemble\" : {'final_estimator' : XGBClassifier() },    # 메타모델이 로지스틱 회귀!\n",
    "           \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2']  }   # 앙상블에 사용할 모델 지정\n",
    "\n",
    "auto_ml_ens.fit(train_ft, target, **params)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피처셀렉션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d4880743564d3a956cbdee86cde923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['내점일수', '구매주기', '주말방문비율', '평일방문비율', '주말방문횟수', '평일방문횟수', '봄_구매비율',\n",
       "       '여름_구매비율', '겨울_구매비율', '주구매요일', '주구매_년', '주구매_월', '주구매_시간대',\n",
       "       '일별평균구매횟수', '거래개월수', '9시_12시_구매비율', '12시_15시_구매비율', '18시_21시_구매비율',\n",
       "       '9시_12시_구매횟수', '12시_15시_구매횟수', '18시_21시_구매횟수', '월초_구매횟수',\n",
       "       '월말_구매횟수', '웨딩성수기_구매횟수', '1월_구매비율', '2월_구매비율', '3월_구매비율',\n",
       "       '4월_구매비율', '5월_구매비율', '6월_구매비율', '7월_구매비율', '8월_구매비율', '10월_구매비율',\n",
       "       '12월_구매비율', '1월_구매횟수', '2월_구매횟수', '3월_구매횟수', '4월_구매횟수', '5월_구매횟수',\n",
       "       '6월_구매횟수', '7월_구매횟수', '8월_구매횟수', '9월_구매횟수', '10월_구매횟수', '11월_구매횟수',\n",
       "       '12월_구매횟수', '1월_방문횟수', '2월_방문횟수', '3월_방문횟수', '4월_방문횟수', '5월_방문횟수',\n",
       "       '6월_방문횟수', '7월_방문횟수', '8월_방문횟수', '9월_방문횟수', '10월_방문횟수', '11월_방문횟수',\n",
       "       '12월_방문횟수', '공휴일_구매유무', '여름휴가_구매유무', '연말_구매유무', '여름휴가_구매비율',\n",
       "       '연말_구매비율', '공휴일_구매횟수', '여름휴가_구매횟수', '연말_구매횟수', '1월_총구매금액',\n",
       "       '2월_총구매금액', '3월_총구매금액', '4월_총구매금액', '5월_총구매금액', '6월_총구매금액',\n",
       "       '7월_총구매금액', '8월_총구매금액', '9월_총구매금액', '10월_총구매금액', '11월_총구매금액',\n",
       "       '12월_총구매금액', '1월_평균구매금액', '2월_평균구매금액', '3월_평균구매금액', '4월_평균구매금액',\n",
       "       '5월_평균구매금액', '6월_평균구매금액', '7월_평균구매금액', '8월_평균구매금액', '9월_평균구매금액',\n",
       "       '10월_평균구매금액', '11월_평균구매금액', '12월_평균구매금액', '최근구매일', '웨딩성수기_저가_구매횟수',\n",
       "       '웨딩성수기_중저가_구매횟수', '웨딩성수기_중고가_구매횟수', '웨딩성수기_고가_구매횟수',\n",
       "       '웨딩성수기_전체_구매횟수', '웨딩성수기_중저가_구매비율', '웨딩성수기_중고가_구매비율', '방문지점수',\n",
       "       '지점다양성_비율', '브랜드코드_nunique', '브랜드다양성_비율', '대분류_nunique',\n",
       "       '중분류_nunique', '총구매액', '총구매횟수', '평균구매액', '최대구매액', '환불금액', '환불건수',\n",
       "       '구매금액표준편차', '저가_구매횟수', '중저가_구매횟수', '중고가_구매횟수', '고가_구매횟수',\n",
       "       '중저가_구매비율', '고가_구매비율', '공휴일_총구매금액', '여름휴가_총구매금액', '연말_총구매금액',\n",
       "       '고가_구매주기', '등급', 'A144000지점_구매금액', 'A373000지점_구매금액',\n",
       "       'A202000지점_구매금액', 'A1440000_구매브랜드_갯수', 'A373000_구매브랜드_갯수',\n",
       "       'A202000_구매브랜드_갯수', 'pv_대분류_가정용품_총구매금액', 'pv_대분류_골프_유니캐쥬얼_총구매금액',\n",
       "       'pv_대분류_공산품_총구매금액', 'pv_대분류_남성의류_총구매금액', 'pv_대분류_남성정장스포츠_총구매금액',\n",
       "       'pv_대분류_로얄부틱_총구매금액', 'pv_대분류_명품잡화_총구매금액', 'pv_대분류_생식품_총구매금액',\n",
       "       'pv_대분류_스포츠캐쥬얼_총구매금액', 'pv_대분류_아동_총구매금액', 'pv_대분류_아동_스포츠_총구매금액',\n",
       "       'pv_대분류_아동문화_총구매금액', 'pv_대분류_여성의류파트_총구매금액', 'pv_대분류_여성정장_총구매금액',\n",
       "       'pv_대분류_영라이브_총구매금액', 'pv_대분류_영캐릭터_총구매금액', 'pv_대분류_영플라자_총구매금액',\n",
       "       'pv_대분류_잡화_총구매금액', 'pv_대분류_케주얼_구두_아동_총구매금액', 'pv_대분류_가정용품_구매횟수',\n",
       "       'pv_대분류_골프_유니캐쥬얼_구매횟수', 'pv_대분류_공산품_구매횟수', 'pv_대분류_남성의류_구매횟수',\n",
       "       'pv_대분류_남성정장스포츠_구매횟수', 'pv_대분류_로얄부틱_구매횟수', 'pv_대분류_생식품_구매횟수',\n",
       "       'pv_대분류_스포츠캐쥬얼_구매횟수', 'pv_대분류_아동_구매횟수', 'pv_대분류_아동_스포츠_구매횟수',\n",
       "       'pv_대분류_아동문화_구매횟수', 'pv_대분류_여성의류파트_구매횟수', 'pv_대분류_여성정장_구매횟수',\n",
       "       'pv_대분류_여성캐쥬얼_구매횟수', 'pv_대분류_영라이브_구매횟수', 'pv_대분류_영어덜트캐쥬얼_구매횟수',\n",
       "       'pv_대분류_영캐릭터_구매횟수', 'pv_대분류_영플라자_구매횟수', 'pv_대분류_잡화_구매횟수',\n",
       "       'pv_대분류_케주얼_구두_아동_구매횟수', 'pv_대분류_패션잡화_구매횟수', 'pv_대분류_가정용품_평균구매금액',\n",
       "       'pv_대분류_골프_유니캐쥬얼_평균구매금액', 'pv_대분류_공산품_평균구매금액',\n",
       "       'pv_대분류_남성의류_평균구매금액', 'pv_대분류_남성정장스포츠_평균구매금액',\n",
       "       'pv_대분류_로얄부틱_평균구매금액', 'pv_대분류_명품잡화_평균구매금액', 'pv_대분류_생식품_평균구매금액',\n",
       "       'pv_대분류_스포츠캐쥬얼_평균구매금액', 'pv_대분류_아동_평균구매금액', 'pv_대분류_아동_스포츠_평균구매금액',\n",
       "       'pv_대분류_아동문화_평균구매금액', 'pv_대분류_여성의류파트_평균구매금액', 'pv_대분류_여성정장_평균구매금액',\n",
       "       'pv_대분류_영캐릭터_평균구매금액', 'pv_대분류_영플라자_평균구매금액', 'pv_대분류_잡화_평균구매금액',\n",
       "       'pv_대분류_케주얼_구두_아동_평균구매금액', 'pv_대분류_공산품_구입금액비중', 'pv_대분류_잡화_구입금액비중',\n",
       "       'pv_대분류_가정용품_구입금액비중', 'pv_대분류_아동문화_구입금액비중', 'pv_대분류_스포츠캐쥬얼_구입금액비중',\n",
       "       'pv_대분류_아동_구입금액비중', 'pv_대분류_패션잡화_구입금액비중', 'pv_대분류_여성캐쥬얼_구입금액비중',\n",
       "       'pv_대분류_생식품_구입금액비중', 'pv_대분류_영어덜트캐쥬얼_구입금액비중', 'pv_대분류_로얄부틱_구입금액비중',\n",
       "       'pv_대분류_남성정장스포츠_구입금액비중', 'pv_대분류_명품잡화_구입금액비중',\n",
       "       'pv_대분류_골프_유니캐쥬얼_구입금액비중', 'pv_대분류_여성정장_구입금액비중',\n",
       "       'pv_대분류_영플라자_구입금액비중', 'pv_대분류_영캐릭터_구입금액비중', '대분류_가정용품_구매주기',\n",
       "       '대분류_골프_유니캐쥬얼_구매주기', '대분류_공산품_구매주기', '대분류_남성의류_구매주기',\n",
       "       '대분류_남성정장스포츠_구매주기', '대분류_로얄부틱_구매주기', '대분류_생식품_구매주기',\n",
       "       '대분류_스포츠캐쥬얼_구매주기', '대분류_아동_구매주기', '대분류_아동_스포츠_구매주기',\n",
       "       '대분류_아동문화_구매주기', '대분류_여성의류파트_구매주기', '대분류_여성정장_구매주기',\n",
       "       '대분류_영라이브_구매주기', '대분류_영어덜트캐쥬얼_구매주기', '대분류_영캐릭터_구매주기',\n",
       "       '대분류_영플라자_구매주기', '대분류_잡화_구매주기', '대분류_케주얼_구두_아동_구매주기',\n",
       "       '대분류_패션잡화_구매주기', 'pv_중분류_TV_VTR_총구매금액', 'pv_중분류_가방_총구매금액',\n",
       "       'pv_중분류_가스렌지_총구매금액', 'pv_중분류_가정잡화_총구매금액', 'pv_중분류_건강식품_총구매금액',\n",
       "       'pv_중분류_건식품_총구매금액', 'pv_중분류_건어물_총구매금액', 'pv_중분류_곡물_총구매금액',\n",
       "       'pv_중분류_골프(LC)_총구매금액', 'pv_중분류_골프(NB)_총구매금액',\n",
       "       'pv_중분류_골프(국내)_총구매금액', 'pv_중분류_골프(단품)_총구매금액',\n",
       "       'pv_중분류_골프(수입)_총구매금액', 'pv_중분류_골프단품_총구매금액', 'pv_중분류_골프웨어_총구매금액',\n",
       "       'pv_중분류_과자_총구매금액', 'pv_중분류_과자류_총구매금액', 'pv_중분류_교복행사_총구매금액',\n",
       "       'pv_중분류_국내화장품_총구매금액', 'pv_중분류_국산화장품_총구매금액', 'pv_중분류_기타식품_총구매금액',\n",
       "       'pv_중분류_내셔날_총구매금액', 'pv_중분류_내의_총구매금액', 'pv_중분류_냉난방_총구매금액',\n",
       "       'pv_중분류_냉동식품_총구매금액', 'pv_중분류_냉장식품_총구매금액', 'pv_중분류_뉴베이직캐주얼_총구매금액',\n",
       "       'pv_중분류_니트_총구매금액', 'pv_중분류_단품_총구매금액', 'pv_중분류_단품_행사(트래디셔널)_총구매금액',\n",
       "       'pv_중분류_드레스구두_총구매금액', 'pv_중분류_디자이너니트_총구매금액', 'pv_중분류_디자이너숍_총구매금액',\n",
       "       'pv_중분류_라이센스_총구매금액', 'pv_중분류_레이디숍A_총구매금액', 'pv_중분류_로얄부틱2F_총구매금액',\n",
       "       'pv_중분류_로얄수입행사_총구매금액', 'pv_중분류_마춤_총구매금액', 'pv_중분류_면류_총구매금액',\n",
       "       'pv_중분류_명품_총구매금액', 'pv_중분류_모자_총구매금액', 'pv_중분류_문구_총구매금액',\n",
       "       'pv_중분류_베이직캐주얼_총구매금액', 'pv_중분류_보석_총구매금액', 'pv_중분류_부띠끄_총구매금액',\n",
       "       'pv_중분류_브랜드침구_총구매금액', 'pv_중분류_상품개발지원_총구매금액', 'pv_중분류_상품군미지정_총구매금액',\n",
       "       'pv_중분류_색조화장품_총구매금액', 'pv_중분류_생선_총구매금액', 'pv_중분류_세탁기_냉장고_총구매금액',\n",
       "       'pv_중분류_셔츠_총구매금액', 'pv_중분류_소파_총구매금액', 'pv_중분류_소형취사가전_총구매금액',\n",
       "       'pv_중분류_수예_총구매금액', 'pv_중분류_수예침장_총구매금액', 'pv_중분류_수예행사_총구매금액',\n",
       "       'pv_중분류_수입_총구매금액', 'pv_중분류_수입구두_총구매금액', 'pv_중분류_수입도자기_총구매금액',\n",
       "       'pv_중분류_수입부띠끄_총구매금액', 'pv_중분류_수입종합화장품_총구매금액', 'pv_중분류_슈즈_총구매금액',\n",
       "       'pv_중분류_스카프_총구매금액', 'pv_중분류_스포츠단품_총구매금액', 'pv_중분류_스포츠웨어_총구매금액',\n",
       "       'pv_중분류_싸롱화_총구매금액', 'pv_중분류_아동_총구매금액', 'pv_중분류_아동_단품_총구매금액',\n",
       "       'pv_중분류_아동_란제리_총구매금액', 'pv_중분류_아동_문화_총구매금액', 'pv_중분류_아동_잡화_총구매금액',\n",
       "       'pv_중분류_아동_트래디셔널_총구매금액', 'pv_중분류_아동단품_총구매금액', 'pv_중분류_아동복_총구매금액',\n",
       "       'pv_중분류_아동잡화_총구매금액', 'pv_중분류_아동특선_총구매금액', 'pv_중분류_야채_총구매금액',\n",
       "       'pv_중분류_양말_총구매금액', 'pv_중분류_어덜트_총구매금액', 'pv_중분류_엘레강스_총구매금액',\n",
       "       'pv_중분류_엘레강스부틱_총구매금액', 'pv_중분류_영캐주얼_총구매금액', 'pv_중분류_영트랜드_총구매금액',\n",
       "       'pv_중분류_완구_총구매금액', 'pv_중분류_욕실용품_총구매금액', 'pv_중분류_용기보증_총구매금액',\n",
       "       'pv_중분류_용품_총구매금액', 'pv_중분류_원목_주니어_총구매금액', 'pv_중분류_유아_총구매금액',\n",
       "       'pv_중분류_유아복_총구매금액', 'pv_중분류_음료_총구매금액', 'pv_중분류_인스탄트식품_총구매금액',\n",
       "       'pv_중분류_일반식품명품_총구매금액', 'pv_중분류_일반조리_총구매금액', 'pv_중분류_일용잡화_총구매금액',\n",
       "       'pv_중분류_임대골프_총구매금액', 'pv_중분류_임대슈즈_총구매금액', 'pv_중분류_전문가구(가구)_총구매금액',\n",
       "       'pv_중분류_전화기_총구매금액', 'pv_중분류_전화기_카세트_총구매금액', 'pv_중분류_정육_총구매금액',\n",
       "       'pv_중분류_조미료_총구매금액', 'pv_중분류_주방용품_총구매금액', 'pv_중분류_즉석조리_총구매금액',\n",
       "       'pv_중분류_진캐쥬얼_총구매금액', 'pv_중분류_진케주얼_총구매금액', 'pv_중분류_차류_총구매금액',\n",
       "       'pv_중분류_청과_총구매금액', 'pv_중분류_초도자기_총구매금액', 'pv_중분류_침구_총구매금액',\n",
       "       'pv_중분류_카페트_총구매금액', 'pv_중분류_크리스탈_총구매금액', 'pv_중분류_타운단품_총구매금액',\n",
       "       'pv_중분류_타운웨어_총구매금액', 'pv_중분류_테이프_총구매금액', 'pv_중분류_토탈_총구매금액',\n",
       "       'pv_중분류_통병조림_총구매금액', 'pv_중분류_트래디셔널_총구매금액', 'pv_중분류_트래디셔널캐쥬얼_총구매금액',\n",
       "       'pv_중분류_트렌드캐주얼_총구매금액', 'pv_중분류_특정_총구매금액', 'pv_중분류_패션란제리_총구매금액',\n",
       "       'pv_중분류_패션시계_총구매금액', 'pv_중분류_팬시_총구매금액', 'pv_중분류_피혁A행사_총구매금액',\n",
       "       'pv_중분류_피혁B행사_총구매금액', 'pv_중분류_피혁토탈(B2)_총구매금액', 'pv_중분류_행사_총구매금액',\n",
       "       'pv_중분류_행사슈즈_총구매금액', 'pv_중분류_행사핸드백_총구매금액', 'pv_중분류_헤어ACC_총구매금액',\n",
       "       'pv_중분류_화장잡화_총구매금액', 'pv_중분류_화장품_총구매금액', 'pv_중분류_훼미닌부틱_총구매금액',\n",
       "       'pv_중분류_N_B침구_구매횟수', 'pv_중분류_TV_VTR_구매횟수', 'pv_중분류_가방_구매횟수',\n",
       "       'pv_중분류_가전특정_구매횟수', 'pv_중분류_가정잡화_구매횟수', 'pv_중분류_건강식품_구매횟수',\n",
       "       'pv_중분류_건식품_구매횟수', 'pv_중분류_건어물_구매횟수', 'pv_중분류_곡물_구매횟수',\n",
       "       'pv_중분류_골프(LC)_구매횟수', 'pv_중분류_골프(NB)_구매횟수', 'pv_중분류_골프(국내)_구매횟수',\n",
       "       'pv_중분류_골프(단품)_구매횟수', 'pv_중분류_골프(수입)_구매횟수', 'pv_중분류_골프(용품)_구매횟수',\n",
       "       'pv_중분류_골프단품_구매횟수', 'pv_중분류_골프웨어_구매횟수', 'pv_중분류_과자_구매횟수',\n",
       "       'pv_중분류_과자류_구매횟수', 'pv_중분류_교복행사_구매횟수', 'pv_중분류_국내부띠끄_구매횟수',\n",
       "       'pv_중분류_국내화장품_구매횟수', 'pv_중분류_국산화장품_구매횟수', 'pv_중분류_기타식품_구매횟수',\n",
       "       'pv_중분류_남성구두_구매횟수', 'pv_중분류_내셔날_구매횟수', 'pv_중분류_내의_구매횟수',\n",
       "       'pv_중분류_냉난방_구매횟수', 'pv_중분류_냉동식품_구매횟수', 'pv_중분류_냉장식품_구매횟수',\n",
       "       'pv_중분류_넥타이_구매횟수', 'pv_중분류_뉴베이직캐주얼_구매횟수', 'pv_중분류_니트_구매횟수',\n",
       "       'pv_중분류_니트웨어_구매횟수', 'pv_중분류_단품_구매횟수', 'pv_중분류_드레스구두_구매횟수',\n",
       "       'pv_중분류_디자이너니트_구매횟수', 'pv_중분류_디자이너부띠끄_구매횟수', 'pv_중분류_디자이너숍_구매횟수',\n",
       "       'pv_중분류_디자이너캐릭터_구매횟수', 'pv_중분류_라디오.카세트_구매횟수', 'pv_중분류_라이센스_구매횟수',\n",
       "       'pv_중분류_레이디숍A_구매횟수', 'pv_중분류_레포츠_구매횟수', 'pv_중분류_레포츠단품_구매횟수',\n",
       "       'pv_중분류_로얄부틱2F_구매횟수', 'pv_중분류_로얄수입행사_구매횟수', 'pv_중분류_마춤_구매횟수',\n",
       "       'pv_중분류_면류_구매횟수', 'pv_중분류_명품_구매횟수', 'pv_중분류_모자_구매횟수',\n",
       "       'pv_중분류_모피_피혁_구매횟수', 'pv_중분류_모피니트_구매횟수', 'pv_중분류_문구_구매횟수',\n",
       "       'pv_중분류_문구_팬시_구매횟수', 'pv_중분류_미시케쥬얼_구매횟수', 'pv_중분류_베이직캐주얼_구매횟수',\n",
       "       'pv_중분류_부띠끄_구매횟수', 'pv_중분류_부띠끄행사_구매횟수', 'pv_중분류_브랜드침구_구매횟수',\n",
       "       'pv_중분류_상품개발지원_구매횟수', 'pv_중분류_상품군미지정_구매횟수', 'pv_중분류_색조화장품_구매횟수',\n",
       "       'pv_중분류_생선_구매횟수', 'pv_중분류_세탁기_냉장고_구매횟수', 'pv_중분류_셔츠_구매횟수',\n",
       "       'pv_중분류_소형취사가전_구매횟수', 'pv_중분류_수영복_구매횟수', 'pv_중분류_수예_구매횟수',\n",
       "       'pv_중분류_수예침장_구매횟수', 'pv_중분류_수예행사_구매횟수', 'pv_중분류_수입_구매횟수',\n",
       "       'pv_중분류_수입구두_구매횟수', 'pv_중분류_수입도자기_구매횟수', 'pv_중분류_수입부띠끄_구매횟수',\n",
       "       'pv_중분류_수입슈즈_구매횟수', 'pv_중분류_수입의류_구매횟수', 'pv_중분류_슈즈_구매횟수',\n",
       "       'pv_중분류_스키_구매횟수', 'pv_중분류_스포츠단품_구매횟수', 'pv_중분류_스포츠슈즈_구매횟수',\n",
       "       'pv_중분류_스포츠용퓸_구매횟수', 'pv_중분류_스포츠웨어_구매횟수', 'pv_중분류_시계_구매횟수',\n",
       "       'pv_중분류_싸롱화_구매횟수', 'pv_중분류_아동_구매횟수', 'pv_중분류_아동_단품_구매횟수',\n",
       "       'pv_중분류_아동_란제리_구매횟수', 'pv_중분류_아동_문화_구매횟수', 'pv_중분류_아동_스포츠용품_구매횟수',\n",
       "       'pv_중분류_아동_스포츠웨어_구매횟수', 'pv_중분류_아동_아웃도어_구매횟수', 'pv_중분류_아동_잡화_구매횟수',\n",
       "       'pv_중분류_아동_트래디셔널_구매횟수', 'pv_중분류_아동단품_구매횟수', 'pv_중분류_아동복_구매횟수',\n",
       "       'pv_중분류_아동잡화_구매횟수', 'pv_중분류_아동특선_구매횟수', 'pv_중분류_아웃도어_구매횟수',\n",
       "       'pv_중분류_야채_구매횟수', 'pv_중분류_양말_구매횟수', 'pv_중분류_어덜트_구매횟수',\n",
       "       'pv_중분류_엘레강스_구매횟수', 'pv_중분류_엘레강스부틱_구매횟수', 'pv_중분류_영트랜드_구매횟수',\n",
       "       'pv_중분류_완구_구매횟수', 'pv_중분류_욕실용품_구매횟수', 'pv_중분류_용기보증_구매횟수',\n",
       "       'pv_중분류_용품_구매횟수', 'pv_중분류_우산장갑_구매횟수', 'pv_중분류_원목_주니어_구매횟수',\n",
       "       'pv_중분류_유아_구매횟수', 'pv_중분류_음료_구매횟수', 'pv_중분류_인스탄트식품_구매횟수',\n",
       "       'pv_중분류_일반식품명품_구매횟수', 'pv_중분류_일반조리_구매횟수', 'pv_중분류_일용잡화_구매횟수',\n",
       "       'pv_중분류_임대골프_구매횟수', 'pv_중분류_임대슈즈_구매횟수', 'pv_중분류_장신구_구매횟수',\n",
       "       'pv_중분류_전문가구(가구)_구매횟수', 'pv_중분류_전화기_구매횟수', 'pv_중분류_전화기_카세트_구매횟수',\n",
       "       'pv_중분류_정육_구매횟수', 'pv_중분류_조미료_구매횟수', 'pv_중분류_주방용품_구매횟수',\n",
       "       'pv_중분류_즉석조리_구매횟수', 'pv_중분류_진캐쥬얼_구매횟수', 'pv_중분류_진케주얼_구매횟수',\n",
       "       'pv_중분류_차류_구매횟수', 'pv_중분류_청과_구매횟수', 'pv_중분류_초도자기_구매횟수',\n",
       "       'pv_중분류_침구_구매횟수', 'pv_중분류_카페트_구매횟수', 'pv_중분류_캐릭터슈즈_구매횟수',\n",
       "       'pv_중분류_크리스탈_구매횟수', 'pv_중분류_타운단품_구매횟수', 'pv_중분류_타운웨어_구매횟수',\n",
       "       'pv_중분류_테이프_구매횟수', 'pv_중분류_토탈_구매횟수', 'pv_중분류_통병조림_구매횟수',\n",
       "       'pv_중분류_트래디셔널_구매횟수', 'pv_중분류_트래디셔널캐쥬얼_구매횟수', 'pv_중분류_트렌드캐주얼_구매횟수',\n",
       "       'pv_중분류_특정_구매횟수', 'pv_중분류_패션란제리_구매횟수', 'pv_중분류_패션시계_구매횟수',\n",
       "       'pv_중분류_팬시_구매횟수', 'pv_중분류_페레  지원_구매횟수', 'pv_중분류_피혁A행사_구매횟수',\n",
       "       'pv_중분류_피혁B행사_구매횟수', 'pv_중분류_피혁토탈(B2)_구매횟수', 'pv_중분류_행사_구매횟수',\n",
       "       'pv_중분류_행사슈즈_구매횟수', 'pv_중분류_헤어ACC_구매횟수', 'pv_중분류_화장품_구매횟수',\n",
       "       'pv_중분류_훼미닌부틱_구매횟수', 'pv_중분류_용기보증_구입금액비중', 'pv_중분류_아동복_구입금액비중',\n",
       "       'pv_중분류_수입종합화장품_구입금액비중', 'pv_중분류_아동_구입금액비중', 'pv_중분류_수영복_구입금액비중',\n",
       "       'pv_중분류_상품군미지정_구입금액비중', 'pv_중분류_야채_구입금액비중',\n",
       "       'pv_중분류_세탁기_냉장고_구입금액비중', 'pv_중분류_주방용품_구입금액비중',\n",
       "       'pv_중분류_수입부띠끄_구입금액비중', 'pv_중분류_면류_구입금액비중', 'pv_중분류_정육_구입금액비중',\n",
       "       'pv_중분류_골프웨어_구입금액비중', 'pv_중분류_패션시계_구입금액비중', 'pv_중분류_골프(국내)_구입금액비중',\n",
       "       'pv_중분류_진캐쥬얼_구입금액비중', 'pv_중분류_색조화장품_구입금액비중', 'pv_중분류_영트랜드_구입금액비중',\n",
       "       'pv_중분류_핸드백_구입금액비중', 'pv_중분류_골프(LC)_구입금액비중', 'pv_중분류_곡물_구입금액비중',\n",
       "       'pv_중분류_란제리_구입금액비중', 'pv_중분류_스타킹_구입금액비중', 'pv_중분류_레이디숍A_구입금액비중',\n",
       "       'pv_중분류_아동_문화_구입금액비중', 'pv_중분류_우산장갑_구입금액비중', 'pv_중분류_셔츠_구입금액비중',\n",
       "       'pv_중분류_영캐주얼_구입금액비중', 'pv_중분류_생선_구입금액비중', 'pv_중분류_아동잡화_구입금액비중',\n",
       "       'pv_중분류_하이캐쥬얼_구입금액비중', 'pv_중분류_타운웨어_구입금액비중', 'pv_중분류_남성잡화_구입금액비중',\n",
       "       'pv_중분류_캐릭터_구입금액비중', 'pv_중분류_아동_단품_구입금액비중', 'pv_중분류_로얄부틱2F_구입금액비중',\n",
       "       'pv_중분류_침구_구입금액비중', 'pv_중분류_청과_구입금액비중', 'pv_중분류_부띠끄_구입금액비중',\n",
       "       'pv_중분류_캐릭터캐주얼_구입금액비중', 'pv_중분류_냉장식품_구입금액비중',\n",
       "       'pv_중분류_패션란제리_구입금액비중', 'pv_중분류_수입ACC_구입금액비중',\n",
       "       'pv_중분류_캐쥬얼구두_구입금액비중', 'pv_중분류_즉석조리_구입금액비중', 'pv_중분류_여성구두_구입금액비중',\n",
       "       'pv_중분류_골프(수입)_구입금액비중', 'pv_중분류_NB제화_구입금액비중',\n",
       "       'pv_중분류_디자이너숍_구입금액비중', 'pv_중분류_썬그라스_구입금액비중', 'pv_중분류_싸롱화_구입금액비중',\n",
       "       'pv_중분류_화장품_구입금액비중', 'pv_중분류_라이센스_구입금액비중', 'pv_중분류_엘레강스부틱_구입금액비중',\n",
       "       'pv_중분류_수입구두_구입금액비중', 'pv_중분류_스포츠캐주얼_구입금액비중',\n",
       "       'pv_중분류_베이직캐주얼_구입금액비중', 'pv_중분류_디자이너니트_구입금액비중', 'pv_중분류_토탈_구입금액비중',\n",
       "       'pv_중분류_건식품_구입금액비중', 'pv_중분류_우산_장갑_구입금액비중', 'pv_중분류_유아_구입금액비중',\n",
       "       'pv_중분류_피혁토탈(B2)_구입금액비중', 'pv_중분류_과자_구입금액비중',\n",
       "       'pv_중분류_영커리어캐주얼_구입금액비중', 'pv_중분류_카페트_구입금액비중', 'pv_중분류_음료_구입금액비중',\n",
       "       'pv_중분류_국내부띠끄_구입금액비중', 'pv_중분류_조미료_구입금액비중', 'pv_중분류_트렌드캐주얼_구입금액비중',\n",
       "       'pv_중분류_아동단품_구입금액비중', 'pv_중분류_내셔날_구입금액비중',\n",
       "       'pv_중분류_전문가구(가구)_구입금액비중', 'pv_중분류_엘레강스_구입금액비중',\n",
       "       'pv_중분류_장신구_구입금액비중', 'pv_중분류_임대골프_구입금액비중', 'pv_중분류_의류기타_구입금액비중',\n",
       "       'pv_중분류_골프단품_구입금액비중', 'pv_중분류_건어물_구입금액비중', 'pv_중분류_골프(NB)_구입금액비중',\n",
       "       'pv_중분류_뉴베이직캐주얼_구입금액비중', 'pv_중분류_수입도자기_구입금액비중', 'pv_중분류_수예_구입금액비중',\n",
       "       'pv_중분류_수예행사_구입금액비중', 'pv_중분류_레포츠_구입금액비중', 'pv_중분류_인스탄트식품_구입금액비중',\n",
       "       'pv_중분류_냉동식품_구입금액비중', 'pv_중분류_선글라스_구입금액비중', 'pv_중분류_훼미닌부틱_구입금액비중',\n",
       "       '중분류_가정잡화_구매주기', '중분류_건강식품_구매주기', '중분류_건식품_구매주기', '중분류_건어물_구매주기',\n",
       "       '중분류_곡물_구매주기', '중분류_골프(LC)_구매주기', '중분류_골프(NB)_구매주기',\n",
       "       '중분류_골프(국내)_구매주기', '중분류_골프(수입)_구매주기', '중분류_골프단품_구매주기',\n",
       "       '중분류_골프웨어_구매주기', '중분류_과자_구매주기', '중분류_과자류_구매주기', '중분류_국내부띠끄_구매주기',\n",
       "       '중분류_국산화장품_구매주기', '중분류_내셔날_구매주기', '중분류_내의_구매주기', '중분류_냉동식품_구매주기',\n",
       "       '중분류_냉장식품_구매주기', '중분류_뉴베이직캐주얼_구매주기', '중분류_니트_구매주기',\n",
       "       '중분류_니트웨어_구매주기', '중분류_단품_구매주기', '중분류_드레스구두_구매주기',\n",
       "       '중분류_디자이너니트_구매주기', '중분류_디자이너숍_구매주기', '중분류_라이센스_구매주기',\n",
       "       '중분류_레이디숍A_구매주기', '중분류_레포츠_구매주기', '중분류_레포츠단품_구매주기',\n",
       "       '중분류_로얄부틱2F_구매주기', '중분류_면류_구매주기', '중분류_문구_구매주기', '중분류_베이직캐주얼_구매주기',\n",
       "       '중분류_부띠끄_구매주기', '중분류_브랜드침구_구매주기', '중분류_상품군미지정_구매주기',\n",
       "       '중분류_색조화장품_구매주기', '중분류_생선_구매주기', '중분류_셔츠_구매주기', '중분류_소형취사가전_구매주기',\n",
       "       '중분류_수예_구매주기', '중분류_수입구두_구매주기', '중분류_수입도자기_구매주기', '중분류_수입부띠끄_구매주기',\n",
       "       '중분류_수입의류_구매주기', '중분류_슈즈_구매주기', '중분류_스포츠단품_구매주기', '중분류_스포츠슈즈_구매주기',\n",
       "       '중분류_스포츠웨어_구매주기', '중분류_아동_구매주기', '중분류_아동_란제리_구매주기',\n",
       "       '중분류_아동_문화_구매주기', '중분류_아동_잡화_구매주기', '중분류_아동_트래디셔널_구매주기',\n",
       "       '중분류_아동복_구매주기', '중분류_아동특선_구매주기', '중분류_야채_구매주기', '중분류_양말_구매주기',\n",
       "       '중분류_어덜트_구매주기', '중분류_엘레강스_구매주기', '중분류_엘레강스부틱_구매주기',\n",
       "       '중분류_영캐주얼_구매주기', '중분류_영트랜드_구매주기', '중분류_완구_구매주기', '중분류_욕실용품_구매주기',\n",
       "       '중분류_용기보증_구매주기', '중분류_유아_구매주기', '중분류_음료_구매주기', '중분류_의류기타_구매주기',\n",
       "       '중분류_인텔리젼스캐주얼_구매주기', '중분류_일반조리_구매주기', '중분류_일용잡화_구매주기',\n",
       "       '중분류_임대골프_구매주기', '중분류_정육_구매주기', '중분류_조미료_구매주기', '중분류_주방용품_구매주기',\n",
       "       '중분류_즉석조리_구매주기', '중분류_진케주얼_구매주기', '중분류_청과_구매주기', '중분류_초도자기_구매주기',\n",
       "       '중분류_타운단품_구매주기', '중분류_타운웨어_구매주기', '중분류_테이프_구매주기', '중분류_통병조림_구매주기',\n",
       "       '중분류_트래디셔널_구매주기', '중분류_트래디셔널캐쥬얼_구매주기', '중분류_트렌드캐주얼_구매주기',\n",
       "       '중분류_팬시_구매주기', '중분류_피혁토탈(B2)_구매주기', '중분류_행사_구매주기', '중분류_화장품_구매주기',\n",
       "       '중분류_훼미닌부틱_구매주기', '공휴일_대분류_가정용품_총구매금액', '공휴일_대분류_골프_유니캐쥬얼_총구매금액',\n",
       "       '공휴일_대분류_공산품_총구매금액', '공휴일_대분류_남성정장스포츠_총구매금액', '공휴일_대분류_로얄부틱_총구매금액',\n",
       "       '공휴일_대분류_생식품_총구매금액', '공휴일_대분류_스포츠캐쥬얼_총구매금액',\n",
       "       '공휴일_대분류_아동_스포츠_총구매금액', '공휴일_대분류_아동문화_총구매금액', '공휴일_대분류_영플라자_총구매금액',\n",
       "       '공휴일_대분류_케주얼_구두_아동_총구매금액', '공휴일_대분류_가정용품_구매횟수',\n",
       "       '공휴일_대분류_골프_유니캐쥬얼_구매횟수', '공휴일_대분류_공산품_구매횟수',\n",
       "       '공휴일_대분류_남성정장스포츠_구매횟수', '공휴일_대분류_로얄부틱_구매횟수', '공휴일_대분류_생식품_구매횟수',\n",
       "       '공휴일_대분류_스포츠캐쥬얼_구매횟수', '공휴일_대분류_아동_스포츠_구매횟수', '공휴일_대분류_아동문화_구매횟수',\n",
       "       '공휴일_대분류_여성의류파트_구매횟수', '공휴일_대분류_여성정장_구매횟수', '공휴일_대분류_영캐릭터_구매횟수',\n",
       "       '공휴일_대분류_영플라자_구매횟수', '공휴일_대분류_케주얼_구두_아동_구매횟수', '공휴일_대분류_패션잡화_구매횟수',\n",
       "       '주구매지점_1', '주구매지점_2', '주구매지점_4', '주구매_중분류_cnt', '주구매_대분류_cnt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "for percentile in tqdm(range(1,101)):\n",
    "    sp = SelectPercentile(percentile=percentile)\n",
    "    x = sp.fit_transform(train_ft, target)\n",
    "    score = cross_val_score(model, x, target, cv=cv, scoring=\"f1_macro\", n_jobs=-1).mean()\n",
    "    scores.append([percentile, score])\n",
    "scores = np.array(scores)\n",
    "idx = np.argmax(scores[:,1])\n",
    "best_score = scores[idx]\n",
    "\n",
    "sp = SelectPercentile(percentile=best_score[0])\n",
    "sp.fit(train_ft,target)\n",
    "best_cols = sp.get_feature_names_out()\n",
    "len(best_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_ft[best_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-07 15:26:03] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-07 15:26:03] {1739} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 11-07 15:26:03] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-07 15:26:03] {1955} INFO - List of ML learners in AutoML Run: ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2']\n",
      "[flaml.automl.logger: 11-07 15:26:03] {2258} INFO - iteration 0, current learner catboost\n",
      "[flaml.automl.logger: 11-07 15:26:52] {2393} INFO - Estimated sufficient time budget=487344s. Estimated necessary time budget=668s.\n",
      "[flaml.automl.logger: 11-07 15:26:52] {2442} INFO -  at 50.4s,\testimator catboost's best error=0.2944,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:26:52] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:27:00] {2442} INFO -  at 58.7s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:27:00] {2258} INFO - iteration 2, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:27:09] {2442} INFO -  at 68.2s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:27:09] {2258} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:27:17] {2442} INFO -  at 75.3s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:27:17] {2258} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:27:19] {2442} INFO -  at 77.6s,\testimator rf's best error=0.3983,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:27:19] {2258} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:27:21] {2442} INFO -  at 80.3s,\testimator rf's best error=0.3983,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:27:21] {2258} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:27:29] {2442} INFO -  at 87.4s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:27:29] {2258} INFO - iteration 7, current learner catboost\n",
      "[flaml.automl.logger: 11-07 15:28:56] {2442} INFO -  at 174.3s,\testimator catboost's best error=0.2928,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:28:56] {2258} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:28:58] {2442} INFO -  at 177.0s,\testimator rf's best error=0.3605,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:28:58] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:29:07] {2442} INFO -  at 185.6s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:07] {2258} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:29:15] {2442} INFO -  at 193.6s,\testimator lgbm's best error=0.3989,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:15] {2258} INFO - iteration 11, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:29:18] {2442} INFO -  at 196.4s,\testimator rf's best error=0.3539,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:18] {2258} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:29:20] {2442} INFO -  at 199.1s,\testimator rf's best error=0.3539,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:20] {2258} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:29:24] {2442} INFO -  at 202.4s,\testimator rf's best error=0.3539,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:24] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:29:31] {2442} INFO -  at 209.9s,\testimator xgboost's best error=0.3950,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:31] {2258} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:29:34] {2442} INFO -  at 212.8s,\testimator rf's best error=0.3445,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:34] {2258} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:29:41] {2442} INFO -  at 220.1s,\testimator xgboost's best error=0.3950,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:41] {2258} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:29:44] {2442} INFO -  at 222.7s,\testimator rf's best error=0.3367,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:44] {2258} INFO - iteration 18, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:29:53] {2442} INFO -  at 232.2s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:29:53] {2258} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:30:01] {2442} INFO -  at 240.3s,\testimator lgbm's best error=0.3193,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:01] {2258} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:30:05] {2442} INFO -  at 243.7s,\testimator rf's best error=0.3367,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:05] {2258} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:30:08] {2442} INFO -  at 246.8s,\testimator rf's best error=0.3367,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:08] {2258} INFO - iteration 22, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:30:11] {2442} INFO -  at 249.6s,\testimator rf's best error=0.3307,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:11] {2258} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:30:18] {2442} INFO -  at 257.3s,\testimator lgbm's best error=0.3193,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:18] {2258} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:30:29] {2442} INFO -  at 267.5s,\testimator lgbm's best error=0.3051,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:29] {2258} INFO - iteration 25, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:30:38] {2442} INFO -  at 277.1s,\testimator histgb's best error=0.3641,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:38] {2258} INFO - iteration 26, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:30:52] {2442} INFO -  at 291.2s,\testimator histgb's best error=0.3369,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:52] {2258} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:30:56] {2442} INFO -  at 294.6s,\testimator rf's best error=0.3238,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:56] {2258} INFO - iteration 28, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:30:59] {2442} INFO -  at 297.7s,\testimator rf's best error=0.3238,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:30:59] {2258} INFO - iteration 29, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:31:08] {2442} INFO -  at 307.2s,\testimator histgb's best error=0.3369,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:31:08] {2258} INFO - iteration 30, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:31:21] {2442} INFO -  at 319.5s,\testimator histgb's best error=0.3369,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:31:21] {2258} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:31:33] {2442} INFO -  at 331.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:31:33] {2258} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:31:43] {2442} INFO -  at 341.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:31:43] {2258} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:31:54] {2442} INFO -  at 352.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:31:54] {2258} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:32:03] {2442} INFO -  at 361.7s,\testimator xgboost's best error=0.3079,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:32:03] {2258} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:32:16] {2442} INFO -  at 375.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:32:16] {2258} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:32:21] {2442} INFO -  at 379.4s,\testimator rf's best error=0.3238,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:32:21] {2258} INFO - iteration 37, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:32:45] {2442} INFO -  at 404.2s,\testimator histgb's best error=0.3025,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:32:45] {2258} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:32:48] {2442} INFO -  at 407.0s,\testimator rf's best error=0.3238,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:32:48] {2258} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:32:55] {2442} INFO -  at 414.0s,\testimator xgboost's best error=0.3079,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:32:55] {2258} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:32:59] {2442} INFO -  at 417.7s,\testimator rf's best error=0.3238,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:32:59] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:33:15] {2442} INFO -  at 433.9s,\testimator xgboost's best error=0.3015,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:33:15] {2258} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:33:44] {2442} INFO -  at 462.5s,\testimator xgboost's best error=0.2896,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 15:33:44] {2258} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 11-07 15:35:50] {2442} INFO -  at 588.6s,\testimator catboost's best error=0.2928,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 15:35:50] {2258} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:36:07] {2442} INFO -  at 605.9s,\testimator xgboost's best error=0.2896,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 15:36:07] {2258} INFO - iteration 45, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:36:25] {2442} INFO -  at 624.1s,\testimator histgb's best error=0.3025,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 15:36:25] {2258} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:37:08] {2442} INFO -  at 666.7s,\testimator xgboost's best error=0.2896,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 15:37:08] {2258} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:37:11] {2442} INFO -  at 670.0s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 15:37:11] {2258} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:37:57] {2442} INFO -  at 715.6s,\testimator xgboost's best error=0.2856,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:37:57] {2258} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:38:19] {2442} INFO -  at 738.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:38:19] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:38:23] {2442} INFO -  at 741.7s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:38:23] {2258} INFO - iteration 51, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:39:08] {2442} INFO -  at 787.3s,\testimator histgb's best error=0.2933,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:39:08] {2258} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:39:12] {2442} INFO -  at 790.8s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:39:12] {2258} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:39:16] {2442} INFO -  at 795.3s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:39:16] {2258} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:39:25] {2442} INFO -  at 804.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:39:25] {2258} INFO - iteration 55, current learner catboost\n",
      "[flaml.automl.logger: 11-07 15:40:22] {2442} INFO -  at 860.9s,\testimator catboost's best error=0.2928,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:40:22] {2258} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:40:26] {2442} INFO -  at 864.8s,\testimator rf's best error=0.3199,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:40:26] {2258} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:40:35] {2442} INFO -  at 873.5s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:40:35] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:40:40] {2442} INFO -  at 879.0s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:40:40] {2258} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:40:44] {2442} INFO -  at 883.2s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:40:44] {2258} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:41:03] {2442} INFO -  at 901.5s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:41:03] {2258} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:41:06] {2442} INFO -  at 905.2s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:41:06] {2258} INFO - iteration 62, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:41:20] {2442} INFO -  at 918.5s,\testimator rf's best error=0.3069,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:41:20] {2258} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:41:28] {2442} INFO -  at 926.7s,\testimator rf's best error=0.3069,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:41:28] {2258} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:41:48] {2442} INFO -  at 947.3s,\testimator rf's best error=0.2985,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:41:48] {2258} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:42:21] {2442} INFO -  at 979.5s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:42:21] {2258} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:42:29] {2442} INFO -  at 987.6s,\testimator rf's best error=0.2985,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:42:29] {2258} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:42:52] {2442} INFO -  at 1010.8s,\testimator xgboost's best error=0.2856,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:42:52] {2258} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:43:40] {2442} INFO -  at 1058.8s,\testimator rf's best error=0.2985,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:43:40] {2258} INFO - iteration 69, current learner catboost\n",
      "[flaml.automl.logger: 11-07 15:45:56] {2442} INFO -  at 1194.9s,\testimator catboost's best error=0.2873,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:45:56] {2258} INFO - iteration 70, current learner lrl2\n",
      "[flaml.automl.logger: 11-07 15:46:02] {2442} INFO -  at 1200.4s,\testimator lrl2's best error=0.2859,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 15:46:02] {2582} INFO - [('xgboost', {'n_jobs': -1, 'n_estimators': 83, 'max_leaves': 17, 'min_child_weight': 4.975895288142883, 'learning_rate': 0.083660950667513, 'subsample': 0.7892030060147662, 'colsample_bylevel': 0.9043499601072365, 'colsample_bytree': 0.9178237934420507, 'reg_alpha': 0.0009765625, 'reg_lambda': 11.536101348451462, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('lrl2', {'n_jobs': -1, 'C': 1.0, 'tol': 0.0001, 'solver': 'lbfgs', 'penalty': 'l2'}), ('catboost', {'early_stopping_rounds': 15, 'learning_rate': 0.04827850182915462, 'n_estimators': 219, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('lgbm', {'n_jobs': -1, 'n_estimators': 53, 'num_leaves': 10, 'min_child_samples': 13, 'learning_rate': 0.21480951571013288, 'colsample_bytree': 0.996498378007316, 'reg_alpha': 0.002255250947893723, 'reg_lambda': 0.10239167483099826, 'max_bin': 63, 'verbose': -1}), ('histgb', {'min_samples_leaf': 36, 'learning_rate': 0.16350793801372152, 'l2_regularization': 16.570878144147258, 'max_iter': 44, 'max_bins': 31, 'max_leaf_nodes': 251, 'random_state': 24092023, 'verbose': 0}), ('rf', {'n_jobs': -1, 'n_estimators': 57, 'max_features': 0.04941962351223344, 'criterion': 'entropy', 'max_leaf_nodes': 960, 'random_state': 12032022, 'verbose': 0})]\n",
      "[flaml.automl.logger: 11-07 15:46:02] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 11-07 15:48:42] {2631} INFO - ensemble: StackingClassifier(estimators=[('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x0000029C468AD1E0>),\n",
      "                               ('lrl2',\n",
      "                                <flaml.automl.model.LRL2Classifier object at 0x0000029C468AC3D0>),\n",
      "                               ('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x0000029C468AC2E0>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x0000029C468AEB90>),\n",
      "                               ('histgb',\n",
      "                                <flaml....\n",
      "                                                 importance_type=None,\n",
      "                                                 interaction_constraints=None,\n",
      "                                                 learning_rate=None,\n",
      "                                                 max_bin=None,\n",
      "                                                 max_cat_threshold=None,\n",
      "                                                 max_cat_to_onehot=None,\n",
      "                                                 max_delta_step=None,\n",
      "                                                 max_depth=None,\n",
      "                                                 max_leaves=None,\n",
      "                                                 min_child_weight=None,\n",
      "                                                 missing=nan,\n",
      "                                                 monotone_constraints=None,\n",
      "                                                 multi_strategy=None,\n",
      "                                                 n_estimators=None, n_jobs=None,\n",
      "                                                 num_parallel_tree=None,\n",
      "                                                 random_state=None, ...),\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 11-07 15:48:42] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-07 15:48:42] {1986} INFO - Time taken to find the best model: 715.6303238868713\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*20,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"eval_method\": \"cv\",                 # 교차 검증\n",
    "           \"n_splits\": 10,                      # Stratified K-Fold로 10분할 교차 검증\n",
    "           \"ensemble\" : {'final_estimator' : XGBClassifier() },    # 메타모델이 로지스틱 회귀!\n",
    "           \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2']  }   # 앙상블에 사용할 모델 지정\n",
    "\n",
    "auto_ml_ens.fit(tmp, target, **params)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7079270014995"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum(auto_ml_ens.best_loss_per_estimator.values())/len(auto_ml_ens.best_loss_per_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-07 15:50:16] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-07 15:50:16] {1739} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 11-07 15:50:16] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-07 15:50:16] {1955} INFO - List of ML learners in AutoML Run: ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb']\n",
      "[flaml.automl.logger: 11-07 15:50:16] {2258} INFO - iteration 0, current learner catboost\n",
      "[flaml.automl.logger: 11-07 15:51:05] {2393} INFO - Estimated sufficient time budget=484938s. Estimated necessary time budget=485s.\n",
      "[flaml.automl.logger: 11-07 15:51:05] {2442} INFO -  at 50.1s,\testimator catboost's best error=0.2944,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:51:05] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:51:13] {2442} INFO -  at 58.5s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:51:13] {2258} INFO - iteration 2, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:51:22] {2442} INFO -  at 67.6s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:51:22] {2258} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:51:30] {2442} INFO -  at 74.9s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:51:30] {2258} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:51:32] {2442} INFO -  at 77.5s,\testimator rf's best error=0.3983,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:51:32] {2258} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:51:35] {2442} INFO -  at 80.4s,\testimator rf's best error=0.3983,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:51:35] {2258} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:51:42] {2442} INFO -  at 87.6s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-07 15:51:42] {2258} INFO - iteration 7, current learner catboost\n",
      "[flaml.automl.logger: 11-07 15:53:11] {2442} INFO -  at 176.5s,\testimator catboost's best error=0.2928,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:11] {2258} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:53:16] {2442} INFO -  at 180.8s,\testimator rf's best error=0.3605,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:16] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:53:26] {2442} INFO -  at 191.4s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:26] {2258} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:53:34] {2442} INFO -  at 199.5s,\testimator lgbm's best error=0.3989,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:34] {2258} INFO - iteration 11, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:53:37] {2442} INFO -  at 202.3s,\testimator rf's best error=0.3539,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:37] {2258} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:53:40] {2442} INFO -  at 204.8s,\testimator rf's best error=0.3539,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:40] {2258} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:53:43] {2442} INFO -  at 208.1s,\testimator rf's best error=0.3539,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:43] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:53:50] {2442} INFO -  at 215.7s,\testimator xgboost's best error=0.3950,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:50] {2258} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:53:53] {2442} INFO -  at 218.6s,\testimator rf's best error=0.3445,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:53:53] {2258} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:54:01] {2442} INFO -  at 226.3s,\testimator xgboost's best error=0.3950,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:01] {2258} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:54:04] {2442} INFO -  at 229.1s,\testimator rf's best error=0.3367,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:04] {2258} INFO - iteration 18, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:54:13] {2442} INFO -  at 238.4s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:13] {2258} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:54:21] {2442} INFO -  at 246.6s,\testimator lgbm's best error=0.3193,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:21] {2258} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:54:25] {2442} INFO -  at 250.4s,\testimator rf's best error=0.3367,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:25] {2258} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:54:28] {2442} INFO -  at 253.5s,\testimator rf's best error=0.3367,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:28] {2258} INFO - iteration 22, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:54:31] {2442} INFO -  at 256.4s,\testimator rf's best error=0.3307,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:31] {2258} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:54:39] {2442} INFO -  at 264.4s,\testimator lgbm's best error=0.3193,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:39] {2258} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:54:49] {2442} INFO -  at 274.6s,\testimator lgbm's best error=0.3051,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:49] {2258} INFO - iteration 25, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:54:59] {2442} INFO -  at 284.2s,\testimator histgb's best error=0.3641,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:54:59] {2258} INFO - iteration 26, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:55:13] {2442} INFO -  at 298.6s,\testimator histgb's best error=0.3369,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:55:13] {2258} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:55:17] {2442} INFO -  at 302.2s,\testimator rf's best error=0.3238,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:55:17] {2258} INFO - iteration 28, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:55:20] {2442} INFO -  at 305.1s,\testimator rf's best error=0.3238,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:55:20] {2258} INFO - iteration 29, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:55:29] {2442} INFO -  at 314.7s,\testimator histgb's best error=0.3369,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:55:29] {2258} INFO - iteration 30, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:55:42] {2442} INFO -  at 326.8s,\testimator histgb's best error=0.3369,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-07 15:55:42] {2258} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:55:53] {2442} INFO -  at 338.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:55:53] {2258} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:56:03] {2442} INFO -  at 348.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:56:03] {2258} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:56:14] {2442} INFO -  at 359.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:56:14] {2258} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:56:24] {2442} INFO -  at 368.9s,\testimator xgboost's best error=0.3079,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:56:24] {2258} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 15:56:38] {2442} INFO -  at 382.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:56:38] {2258} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:56:42] {2442} INFO -  at 387.3s,\testimator rf's best error=0.3238,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:56:42] {2258} INFO - iteration 37, current learner histgb\n",
      "[flaml.automl.logger: 11-07 15:57:09] {2442} INFO -  at 414.2s,\testimator histgb's best error=0.3025,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:57:09] {2258} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:57:12] {2442} INFO -  at 417.4s,\testimator rf's best error=0.3238,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:57:12] {2258} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:57:19] {2442} INFO -  at 424.5s,\testimator xgboost's best error=0.3079,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:57:19] {2258} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 11-07 15:57:23] {2442} INFO -  at 428.6s,\testimator rf's best error=0.3238,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:57:23] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:57:40] {2442} INFO -  at 445.0s,\testimator xgboost's best error=0.3015,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 11-07 15:57:40] {2258} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 15:58:09] {2442} INFO -  at 474.7s,\testimator xgboost's best error=0.2896,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 15:58:09] {2258} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 11-07 16:00:19] {2442} INFO -  at 604.1s,\testimator catboost's best error=0.2928,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 16:00:19] {2258} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 16:00:36] {2442} INFO -  at 621.4s,\testimator xgboost's best error=0.2896,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 16:00:36] {2258} INFO - iteration 45, current learner histgb\n",
      "[flaml.automl.logger: 11-07 16:00:53] {2442} INFO -  at 638.7s,\testimator histgb's best error=0.3025,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 16:00:53] {2258} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 16:01:38] {2442} INFO -  at 683.0s,\testimator xgboost's best error=0.2896,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 16:01:38] {2258} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:01:41] {2442} INFO -  at 686.3s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2896\n",
      "[flaml.automl.logger: 11-07 16:01:41] {2258} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 16:02:24] {2442} INFO -  at 729.1s,\testimator xgboost's best error=0.2856,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:02:24] {2258} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 16:02:45] {2442} INFO -  at 749.9s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:02:45] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:02:48] {2442} INFO -  at 753.4s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:02:48] {2258} INFO - iteration 51, current learner histgb\n",
      "[flaml.automl.logger: 11-07 16:03:34] {2442} INFO -  at 799.5s,\testimator histgb's best error=0.2933,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:03:34] {2258} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:03:38] {2442} INFO -  at 803.0s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:03:38] {2258} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:03:42] {2442} INFO -  at 807.1s,\testimator rf's best error=0.3238,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:03:42] {2258} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 16:03:51] {2442} INFO -  at 816.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:03:51] {2258} INFO - iteration 55, current learner catboost\n",
      "[flaml.automl.logger: 11-07 16:04:47] {2442} INFO -  at 872.3s,\testimator catboost's best error=0.2928,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:04:47] {2258} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:04:51] {2442} INFO -  at 876.3s,\testimator rf's best error=0.3199,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:04:51] {2258} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 16:05:00] {2442} INFO -  at 885.1s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:05:00] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:05:06] {2442} INFO -  at 891.1s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:05:06] {2258} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:05:11] {2442} INFO -  at 895.8s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:05:11] {2258} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 16:05:29] {2442} INFO -  at 914.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:05:29] {2258} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:05:33] {2442} INFO -  at 918.4s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:05:33] {2258} INFO - iteration 62, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:05:47] {2442} INFO -  at 932.2s,\testimator rf's best error=0.3069,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:05:47] {2258} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:05:56] {2442} INFO -  at 940.9s,\testimator rf's best error=0.3069,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:05:56] {2258} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:06:16] {2442} INFO -  at 961.1s,\testimator rf's best error=0.2985,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:06:16] {2258} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-07 16:06:48] {2442} INFO -  at 993.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:06:48] {2258} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:06:56] {2442} INFO -  at 1001.3s,\testimator rf's best error=0.2985,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:06:56] {2258} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 11-07 16:07:20] {2442} INFO -  at 1024.9s,\testimator xgboost's best error=0.2856,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:07:20] {2258} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 11-07 16:08:08] {2442} INFO -  at 1073.4s,\testimator rf's best error=0.2985,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:08:08] {2258} INFO - iteration 69, current learner catboost\n",
      "[flaml.automl.logger: 11-07 16:09:44] {2442} INFO -  at 1169.2s,\testimator catboost's best error=0.2928,\tbest estimator xgboost's best error=0.2856\n",
      "[flaml.automl.logger: 11-07 16:09:44] {2582} INFO - [('xgboost', {'n_jobs': -1, 'n_estimators': 83, 'max_leaves': 17, 'min_child_weight': 4.975895288142883, 'learning_rate': 0.083660950667513, 'subsample': 0.7892030060147662, 'colsample_bylevel': 0.9043499601072365, 'colsample_bytree': 0.9178237934420507, 'reg_alpha': 0.0009765625, 'reg_lambda': 11.536101348451462, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('lgbm', {'n_jobs': -1, 'n_estimators': 53, 'num_leaves': 10, 'min_child_samples': 13, 'learning_rate': 0.21480951571013288, 'colsample_bytree': 0.996498378007316, 'reg_alpha': 0.002255250947893723, 'reg_lambda': 0.10239167483099826, 'max_bin': 63, 'verbose': -1}), ('catboost', {'early_stopping_rounds': 11, 'learning_rate': 0.060536189750294574, 'n_estimators': 113, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('histgb', {'min_samples_leaf': 36, 'learning_rate': 0.16350793801372152, 'l2_regularization': 16.570878144147258, 'max_iter': 44, 'max_bins': 31, 'max_leaf_nodes': 251, 'random_state': 24092023, 'verbose': 0}), ('rf', {'n_jobs': -1, 'n_estimators': 57, 'max_features': 0.04941962351223344, 'criterion': 'entropy', 'max_leaf_nodes': 960, 'random_state': 12032022, 'verbose': 0})]\n",
      "[flaml.automl.logger: 11-07 16:09:44] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 11-07 16:11:35] {2631} INFO - ensemble: StackingClassifier(estimators=[('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x0000029C179BFDC0>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x0000029C38C61120>),\n",
      "                               ('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x0000029C38C614B0>),\n",
      "                               ('histgb',\n",
      "                                <flaml.automl.contrib.histgb.HistGradientBoostingEstimator object at 0x0000029C38C61840>),\n",
      "                               ('rf',\n",
      "                                <flaml.automl.model.RandomForestEstimator object at 0x0000029C38C60AC0>)],\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 11-07 16:11:35] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-07 16:11:35] {1986} INFO - Time taken to find the best model: 729.1183187961578\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*20,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"eval_method\": \"cv\",                 # 교차 검증\n",
    "           \"n_splits\": 10,                      # Stratified K-Fold로 10분할 교차 검증\n",
    "           \"ensemble\" : True,    # 메타모델이 로지스틱 회귀!\n",
    "           \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb']  }   # 앙상블에 사용할 모델 지정\n",
    "\n",
    "auto_ml_ens.fit(tmp, target, **params)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catboost': 0.2927925734561826,\n",
       " 'lgbm': 0.29007837477623877,\n",
       " 'rf': 0.298499804898915,\n",
       " 'xgboost': 0.28564726103378735,\n",
       " 'histgb': 0.2933469783373758}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_ens.best_loss_per_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7079270014995"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum(auto_ml_ens.best_loss_per_estimator.values())/len(auto_ml_ens.best_loss_per_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping_rounds': 11,\n",
       " 'learning_rate': 0.060536189750294574,\n",
       " 'n_estimators': 113}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_ens.best_config_per_estimator.get(\"catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The estimator dict should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VotingClassifier\n\u001b[0;32m      6\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m VotingClassifier(\n\u001b[0;32m      7\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_1),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     ], voting\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[43mensemble_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m f1_score(x_valid, y_valid, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:66\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     69\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     72\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:423\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     fit_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, transformed_y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:85\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get common fit operations.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     names, clfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_base.py:240\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    242\u001b[0m                 est\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_estimator_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m[\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m    243\u001b[0m             )\n\u001b[0;32m    244\u001b[0m         )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator dict should be a classifier."
     ]
    }
   ],
   "source": [
    "best_1 = auto_ml_ens.best_config_per_estimator.get(\"xgboost\")\n",
    "best_2 = auto_ml_ens.best_config_per_estimator.get(\"catboost\")\n",
    "best_3 = auto_ml_ens.best_config_per_estimator.get(\"lgbm\")\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators= [\n",
    "        (\"best_1\", best_1),\n",
    "        (\"best_2\", best_2),\n",
    "        (\"best_3\", best_3),\n",
    "    ], voting= \"soft\"\n",
    ")\n",
    "\n",
    "ensemble_model.fit(x_train, y_train)\n",
    "f1_score(x_valid, y_valid, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Macro Score: 0.7191309247065132\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {'n_estimators': 800,\n",
    " 'learning_rate': 0.04036413044768581,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.7505214930635562,\n",
    " 'colsample_bytree': 0.6290102054237857,\n",
    " 'gamma': 0.648553153047272}\n",
    "\n",
    "# F1 매크로 스코어와 모델을 저장할 리스트\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "# Stratified K-Fold 교차 검증 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 루프\n",
    "for tri, vai in cv.split(tmp, target):\n",
    "    # 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "\n",
    "    # 모델 초기화 및 학습\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)   \n",
    "    \n",
    "    # 모델 저장\n",
    "    models.append(model)\n",
    "\n",
    "    # 예측 및 F1 매크로 스코어 계산\n",
    "    pred = model.predict(x_valid)\n",
    "    score = f1_score(y_valid, pred, average='macro')\n",
    "    scores.append(score)\n",
    "\n",
    "# F1 매크로 스코어의 평균 출력\n",
    "print(\"Mean F1 Macro Score:\", np.mean(scores))\n",
    "\n",
    "\n",
    "# v3.0 원핫 + 스탠다드 : 0.7195019304392802\n",
    "# submit_v3.0_02 : 원핫(주구매지점) + 카운트(주구매대분류, 주구매중분류) + 스탠다드  (0.7202916471187197)\n",
    "# submit_v3.0_02 : 원핫(주구매지점) + 카운트(주구매대분류, 주구매중분류) + 스탠다드 + 가중치적용  ( 0.7202916471187197 )\n",
    "# 3.2 셋다 카운트 + 스탠다드 (0.7184464536223091)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
