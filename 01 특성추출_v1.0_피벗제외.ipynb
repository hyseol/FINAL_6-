{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zknWXgof5u-B"
   },
   "source": [
    "# 컴피티션 링크\n",
    "- https://www.kaggle.com/t/2e45abe9f1434b59a3358365432a48bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N44QYORV8wFy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhUuXRB5BCFE"
   },
   "source": [
    "- 데이터 경로 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NfX2HPof87FT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/Desktop/데이터분석/01 Practice/00_data/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/01 Practice/00_data/\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd7JpzNBHa1"
   },
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KFGKUIWt89fZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523105, 7), (14940, 2), (441196, 7), (12225, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_tr = pd.read_csv(f\"{DATA_PATH}store_train_transactions.csv\") # 학습용 구매기록 데이터\n",
    "train_target = pd.read_csv(f\"{DATA_PATH}store_train.csv\") # 학습용 정답 데이터\n",
    "test_tr = pd.read_csv(f\"{DATA_PATH}store_test_transactions.csv\") # 테스트용 구매기록 데이터\n",
    "submit = pd.read_csv(f\"{DATA_PATH}store_submission.csv\") # 제출 양식 데이터\n",
    "\n",
    "train_tr.shape , train_target.shape , test_tr.shape , submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r43SCHUujW-f"
   },
   "source": [
    "# 특성 공학(Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONQYpWOjlbE9"
   },
   "source": [
    "## 날짜 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SYPmQb7dlVTu"
   },
   "outputs": [],
   "source": [
    "train_tr[\"구매일시\"] = pd.to_datetime(train_tr[\"구매일시\"])\n",
    "test_tr[\"구매일시\"] = pd.to_datetime(test_tr[\"구매일시\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzdFiwxsrFa4"
   },
   "source": [
    "## 새로 만든 feature와 병합할 고객ID로만 이루어진 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Is0n2MKZrMWp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1), (12225, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_target[[\"ID\"]]\n",
    "test_ft = submit[[\"ID\"]]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arH5g0kMmCTa"
   },
   "source": [
    "## 구매일시를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OJt2fPnXmAsM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 25), (12225, 25))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "        # 컬럼명, 집계 방식\n",
    "        ('내점일수', lambda x: x.dt.date.nunique()),       # 내점일수 수정 : 날짜만 선택해서 nuique\n",
    "        ('구매주기', lambda x: int( (x.max() - x.min()).days / x.dt.date.nunique()) ),\n",
    "        ('주말방문비율', lambda x: np.mean(x.dt.weekday>4)),\n",
    "        ('봄_구매비율', lambda x: np.mean(x.dt.month.isin([3,4,5]))),\n",
    "        ('여름_구매비율', lambda x: np.mean(x.dt.month.isin([6,7,8]))),\n",
    "        ('가을_구매비율', lambda x: np.mean(x.dt.month.isin([9,10,11]))),\n",
    "        ('겨울_구매비율', lambda x: np.mean(x.dt.month.isin([1,2,12]))),\n",
    "        ('주구매요일', lambda x: x.dt.weekday.mode()[0]),\n",
    "        ('일별평균구매건수', lambda x:  x.count() / x.dt.date.nunique() ),\n",
    "        ('거래개월수', lambda x: x.dt.date.astype(str).str[:-3].nunique() ),\n",
    "        \n",
    "        ('아침_구매비율', lambda x: np.mean(x.dt.hour.isin(range(6, 12)))),       # 시간대 별 구매비율 추가\n",
    "        ('점심_구매비율', lambda x: np.mean(x.dt.hour.isin(range(12, 18)))),      # 시간대 별 구매비율 추가\n",
    "        ('저녁_구매비율', lambda x:np.mean(x.dt.hour.isin(range(18, 22)))),       # 시간대 별 구매비율 추가\n",
    "        ('야간_구매비율', lambda x:np.mean(~x.dt.hour.isin(range(6, 22)))),       # 시간대 별 구매비율 추가\n",
    "\n",
    "        ('아침_구매건수', lambda x: np.sum(x.dt.hour.isin(range(6, 12)))),       # 시간대 별 구매건수 추가\n",
    "        ('점심_구매건수', lambda x: np.sum(x.dt.hour.isin(range(12, 18)))),      # 시간대 별 구매건수 추가\n",
    "        ('저녁_구매건수', lambda x:np.sum(x.dt.hour.isin(range(18, 22)))),       # 시간대 별 구매건수 추가\n",
    "        ('야간_구매건수', lambda x:np.sum(~x.dt.hour.isin(range(6, 22)))),       # 시간대 별 구매건수 추가\n",
    "\n",
    "        ('월초_구매비율', lambda x: np.mean(x.dt.day <= 10)),                     # 월초 구매비율 추가(10일 이전)\n",
    "        ('월말_구매비율', lambda x: np.mean(x.dt.day >= 20)),                     # 월말 구매비율 추가(20일 이후)\n",
    "\n",
    "        ('월초_구매건수', lambda x: np.sum(x.dt.day <= 10)),                     # 월초 구매건수 추가(10일 이전)\n",
    "        ('월말_구매건수', lambda x: np.sum(x.dt.day >= 20)),                     # 월말 구매건수 추가(20일 이후)\n",
    "\n",
    "        (\"주_구매_월\", lambda x: x.dt.month.mode()[0]),         # 주구매 월 추가\n",
    "        (\"주_구매시간대\", lambda x: x.dt.hour.mode()[0]),       # 주구매 시간대 추가\n",
    "\n",
    "        \n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 휴면회원 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 27), (12225, 27))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [(\"최근구매일\", lambda x: int( (x.max() - x.min()).days))]\n",
    "\n",
    "sort_value = train_tr.sort_values([\"ID\", \"구매일시\"], ascending= False).drop_duplicates(subset=[\"ID\", \"구매일시\"],keep='first').groupby(\"ID\").head(2)\n",
    "tmp = sort_value.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "tmp[\"휴면회원\"] = (tmp[\"최근구매일\"] > 90).astype(int)\n",
    "train_ft = train_ft.merge(tmp, how= 'left', on= \"ID\")\n",
    "\n",
    "sort_value = test_tr.sort_values([\"ID\", \"구매일시\"], ascending= False).drop_duplicates(subset=[\"ID\", \"구매일시\"],keep='first').groupby(\"ID\").head(2)\n",
    "tmp = sort_value.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "tmp[\"휴면회원\"] = (tmp[\"최근구매일\"] > 90).astype(int)\n",
    "test_ft = test_ft.merge(tmp, how= 'left', on= \"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxm1aP9bstSP"
   },
   "source": [
    "## 지점을 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NAhiyQqgmAna"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 29), (12225, 29))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "          (\"방문지점수\",\"nunique\"),\n",
    "          ('주구매지점', lambda x: x.mode()[0]),\n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"지점코드\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"지점코드\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC7i927ntZMf"
   },
   "source": [
    "## 브랜드코드를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "U55_ClZktWbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 31), (12225, 31))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "             ('브랜드코드_nunique', 'nunique'),\n",
    "\n",
    "             ('브랜드다양성_비율',lambda x: x.nunique() / len(x)) # 브랜드다양성 추가\n",
    "\n",
    "             ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"브랜드코드\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"브랜드코드\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-mYObgFtrgD"
   },
   "source": [
    "## 중분류를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "foQqMMKatWV2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 33), (12225, 33))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "            ('중분류_nunique', 'nunique'),\n",
    "            ('주구매_중분류', lambda x: x.mode()[0]),\n",
    "            ]\n",
    "tmp = train_tr.groupby('ID')[\"중분류\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"중분류\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvwbAgMluAlT"
   },
   "source": [
    "## 대분류를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>구매일시</th>\n",
       "      <th>지점코드</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>브랜드코드</th>\n",
       "      <th>구매가격</th>\n",
       "      <th>대분류_수정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_13219</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>공산품파트</td>\n",
       "      <td>차류</td>\n",
       "      <td>5100</td>\n",
       "      <td>59700</td>\n",
       "      <td>생활용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_5590</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>화장잡화</td>\n",
       "      <td>5101</td>\n",
       "      <td>17000</td>\n",
       "      <td>생활용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_7200</td>\n",
       "      <td>2004-05-01 10:20:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>공산품</td>\n",
       "      <td>용기보증</td>\n",
       "      <td>5100</td>\n",
       "      <td>34937</td>\n",
       "      <td>생활용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3010</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A373000</td>\n",
       "      <td>아동_스포츠</td>\n",
       "      <td>아동복</td>\n",
       "      <td>5105</td>\n",
       "      <td>19000</td>\n",
       "      <td>아동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_10851</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>가정용품</td>\n",
       "      <td>전화기_카세트</td>\n",
       "      <td>5110</td>\n",
       "      <td>215000</td>\n",
       "      <td>가정용품</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                구매일시     지점코드     대분류      중분류  브랜드코드    구매가격  \\\n",
       "0  train_13219 2004-05-01 09:40:00  A144000   공산품파트       차류   5100   59700   \n",
       "1   train_5590 2004-05-01 09:40:00  A144000    잡화파트     화장잡화   5101   17000   \n",
       "2   train_7200 2004-05-01 10:20:00  A112000     공산품     용기보증   5100   34937   \n",
       "3   train_3010 2004-05-01 10:30:00  A373000  아동_스포츠      아동복   5105   19000   \n",
       "4  train_10851 2004-05-01 10:30:00  A112000    가정용품  전화기_카세트   5110  215000   \n",
       "\n",
       "  대분류_수정  \n",
       "0   생활용품  \n",
       "1   생활용품  \n",
       "2   생활용품  \n",
       "3     아동  \n",
       "4   가정용품  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 대분류 범주 생성\n",
    "def classification(x):\n",
    "    lst_kids = ['아동_스포츠', '아동문화', '케주얼_구두_아동', '아동']\n",
    "    lst_foods = [\"생식품파트\", \"생식품\"]\n",
    "    lst_home = [\"가정용품파트\", \"가정용품\"]\n",
    "    lst_clothes = [\"스포츠캐쥬얼\", \"패션잡화\", \"여성캐쥬얼\",\"여성캐주얼\", \"영어덜트캐쥬얼\", \"남성정장스포츠\",\n",
    "                   \"남성의류\", \"여성정장\", \"여성의류파트\", \"영캐릭터\",\"골프_유니캐쥬얼\", \"영플라자\", \"영라이브\"]\n",
    "    lst_loyal = [\"명품잡화\", \"로얄부띠끄\", \"로얄부틱\"]\n",
    "    lst_daily = [\"공산품\", \"잡화파트\", \"공산품파트\", \"잡화\"]\n",
    "\n",
    "    if x in lst_kids:\n",
    "        ans = \"아동\"\n",
    "    elif x in lst_foods:\n",
    "        ans = \"생식품\"\n",
    "    elif x in lst_home:\n",
    "        ans = \"가정용품\" \n",
    "    elif x in lst_clothes:\n",
    "        ans = \"의류\"      \n",
    "    elif x in lst_loyal:\n",
    "        ans = \"명품\" \n",
    "    elif x in lst_daily:\n",
    "        ans = \"생활용품\" \n",
    "    return ans\n",
    "\n",
    "train_tr[\"대분류_수정\"] = train_tr[\"대분류\"].apply(classification)\n",
    "test_tr[\"대분류_수정\"] = test_tr[\"대분류\"].apply(classification)\n",
    "\n",
    "train_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wjpz9uY4tIzc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 35), (12225, 35))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "            ('대분류_nunique', 'nunique'),\n",
    "            ('주구매_대분류', lambda x: x.mode()[0]),\n",
    "            ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"대분류\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"대분류\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 49), (12225, 49))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "            ('대분류_수정_nunique', 'nunique'),                 # 대분류_수정 기준 구매횟수\n",
    "            ('주구매_대분류_수정', lambda x: x.mode()[0]),      # 대분류_수정 기준 주구매\n",
    "\n",
    "            ('대분류_수정_아동_구매여부', lambda x: int(x.str.contains(\"아동\").any())),              # 대분류_수정에서 아동 구매 여부(1/0)\n",
    "            ('대분류_수정_생식품_구매여부', lambda x: int(x.str.contains(\"생식품\").any())),          # 대분류_수정에서 생식품 구매 여부(1/0)\n",
    "            ('대분류_수정_가정용품_구매여부', lambda x: int(x.str.contains(\"가정용품\").any())),      # 대분류_수정에서 가정용품 구매 여부(1/0)\n",
    "            ('대분류_수정_의류_구매여부', lambda x: int(x.str.contains(\"의류\").any())),              # 대분류_수정에서 의류 구매 여부(1/0)\n",
    "            ('대분류_수정_명품_구매여부', lambda x: int(x.str.contains(\"명품\").any())),              # 대분류_수정에서 명품 구매 여부(1/0)\n",
    "            ('대분류_수정_생활용품_구매여부', lambda x: int(x.str.contains(\"생활용품\").any())),      # 대분류_수정에서 생활용품 구매 여부(1/0)\n",
    "\n",
    "            ('대분류_수정_아동_구매횟수', lambda x: int(x.str.contains(\"아동\").sum())),              # 대분류_수정에서 아동 구매횟수\n",
    "            ('대분류_수정_생식품_구매횟수', lambda x: int(x.str.contains(\"생식품\").sum())),          # 대분류_수정에서 생식품 구매횟수\n",
    "            ('대분류_수정_가정용품_구매횟수', lambda x: int(x.str.contains(\"가정용품\").sum())),      # 대분류_수정에서 가정용품 구매횟수\n",
    "            ('대분류_수정_의류_구매횟수', lambda x: int(x.str.contains(\"의류\").sum())),              # 대분류_수정에서 의류 구매횟수\n",
    "            ('대분류_수정_명품_구매횟수', lambda x: int(x.str.contains(\"명품\").sum())),              # 대분류_수정에서 명품 구매횟수\n",
    "            ('대분류_수정_생활용품_구매횟수', lambda x: int(x.str.contains(\"생활용품\").sum())),      # 대분류_수정에서 생활용품 구매횟수\n",
    "\n",
    "            ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"대분류_수정\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"대분류_수정\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mMqLIDKuTgB"
   },
   "source": [
    "## 구매가격을 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rlrGtiLZtIuI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 59), (12225, 59))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "        ('총구매액',lambda x: x[x > 0].sum()),         # 0 이상에서 적용\n",
    "        ('구매건수', lambda x: x[x > 0].count()),      # 0 이상에서 적용\n",
    "        ('평균구매액', lambda x: x[x > 0].mean()),     # 0 이상에서 적용\n",
    "        ('최대구매액', 'max'),\n",
    "        ('최소구매액',lambda x: x[x > 0].min() ) ,\n",
    "        ('환불금액',lambda x: x[x < 0].sum() ) ,\n",
    "        ('환불건수', lambda x: ( x < 0 ).sum() ),\n",
    "        ('구매금액표준편차',lambda x: x[x>0].std() ),\n",
    "\n",
    "        ('평균저가구매비율', lambda x: (x <= 102479.91701049241).sum() / len(x)), # 저가 구매 비율 (구매 총평균에 비례)\n",
    "        ('평균고가구매비율', lambda x: (x > 102479.91701049241).sum() / len(x))   # 고가 구매 비율 (구매 총평균에 비례)\n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"구매가격\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"구매가격\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류_수정 기준 금액 합계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 65), (12225, 65))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in train_tr['대분류_수정'].unique():\n",
    "    tmp = train_tr[train_tr['대분류_수정'] == col].groupby('ID')[\"구매가격\"].sum().reset_index()\n",
    "    tmp.rename(columns={\"구매가격\" : f\"대분류_수정_{col}_구매금액\"}, inplace = True)\n",
    "    train_ft = train_ft.merge(tmp, on= \"ID\", how= \"left\")\n",
    "    train_ft[f\"대분류_수정_{col}_구매금액\"] = train_ft[f\"대분류_수정_{col}_구매금액\"].fillna(0)\n",
    "    \n",
    "\n",
    "for col in train_tr['대분류_수정'].unique():\n",
    "    tmp = test_tr[test_tr['대분류_수정'] == col].groupby('ID')[\"구매가격\"].sum().reset_index()\n",
    "    tmp.rename(columns={\"구매가격\" : f\"대분류_수정_{col}_구매금액\"}, inplace = True)\n",
    "    test_ft = test_ft.merge(tmp, on= \"ID\", how= \"left\")\n",
    "    test_ft[f\"대분류_수정_{col}_구매금액\"] = test_ft[f\"대분류_수정_{col}_구매금액\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류_수정 기준 구입비중\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 71), (12225, 71))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft[\"대분류_수정_생활용품_구입비중\"] = train_ft[\"대분류_수정_생활용품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_아동_구입비중\"] = train_ft[\"대분류_수정_아동_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_가정용품_구입비중\"] = train_ft[\"대분류_수정_가정용품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_의류_구입비중\"] = train_ft[\"대분류_수정_의류_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_생식품_구입비중\"] = train_ft[\"대분류_수정_생식품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_명품_구입비중\"] = train_ft[\"대분류_수정_명품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "\n",
    "test_ft[\"대분류_수정_생활용품_구입비중\"] = test_ft[\"대분류_수정_생활용품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_아동_구입비중\"] = test_ft[\"대분류_수정_아동_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_가정용품_구입비중\"] = test_ft[\"대분류_수정_가정용품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_의류_구입비중\"] = test_ft[\"대분류_수정_의류_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_생식품_구입비중\"] = test_ft[\"대분류_수정_생식품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_명품_구입비중\"] = test_ft[\"대분류_수정_명품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 등급 범주 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 72), (12225, 72))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grade(x):\n",
    "    if x >= 10000000:\n",
    "        ans = 1\n",
    "    elif 5000000 <= x & x < 10000000:\n",
    "        ans = 2\n",
    "    elif 1000000 <= x & x < 5000000:\n",
    "        ans = 3\n",
    "    elif 0 <= x & x < 1000000:\n",
    "        ans = 4\n",
    "    return ans\n",
    "\n",
    "train_ft[\"등급\"] = train_ft[\"총구매액\"].apply(grade)\n",
    "test_ft[\"등급\"] = test_ft[\"총구매액\"].apply(grade)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LopLwsb3NaE0"
   },
   "source": [
    "# 항상 확인하기\n",
    "- 학습데이터와 테스트 데이터의 피처개수는 동일해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "At-Xx2XoNXDo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 71), (12225, 71))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxEi3_gLM8rh"
   },
   "source": [
    "# 추출한 피처 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "am-hCMk3M3x-"
   },
   "outputs": [],
   "source": [
    "train_ft.to_csv(f\"{DATA_PATH}train_common.csv\",index=False)\n",
    "test_ft.to_csv(f\"{DATA_PATH}test_common.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxJ1YO5gM38Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 10-30 23:41:31] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 10-30 23:41:31] {1739} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 10-30 23:41:31] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 10-30 23:41:31] {1955} INFO - List of ML learners in AutoML Run: ['catboost', 'lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 10-30 23:41:31] {2258} INFO - iteration 0, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:41:38] {2393} INFO - Estimated sufficient time budget=66241s. Estimated necessary time budget=66s.\n",
      "[flaml.automl.logger: 10-30 23:41:38] {2442} INFO -  at 6.8s,\testimator catboost's best error=0.3075,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:38] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:38] {2442} INFO -  at 7.1s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:38] {2258} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:39] {2442} INFO -  at 7.4s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:39] {2258} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:39] {2442} INFO -  at 7.7s,\testimator lgbm's best error=0.4837,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:39] {2258} INFO - iteration 4, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:41:48] {2442} INFO -  at 16.9s,\testimator catboost's best error=0.3075,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:48] {2258} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:49] {2442} INFO -  at 17.3s,\testimator lgbm's best error=0.3410,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:49] {2258} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:49] {2442} INFO -  at 17.6s,\testimator lgbm's best error=0.3410,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:49] {2258} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:50] {2442} INFO -  at 18.7s,\testimator lgbm's best error=0.3255,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:50] {2258} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:41:50] {2442} INFO -  at 19.2s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:50] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:52] {2442} INFO -  at 20.5s,\testimator lgbm's best error=0.3088,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:52] {2258} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:41:52] {2442} INFO -  at 21.0s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:52] {2258} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:41:53] {2442} INFO -  at 21.4s,\testimator xgboost's best error=0.5011,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:53] {2258} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:41:53] {2442} INFO -  at 21.9s,\testimator extra_tree's best error=0.6223,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:53] {2258} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:41:54] {2442} INFO -  at 22.4s,\testimator extra_tree's best error=0.6223,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:54] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:41:54] {2442} INFO -  at 22.9s,\testimator xgboost's best error=0.5011,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:54] {2258} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:41:55] {2442} INFO -  at 23.4s,\testimator extra_tree's best error=0.6213,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:55] {2258} INFO - iteration 16, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:41:55] {2442} INFO -  at 23.9s,\testimator rf's best error=0.4830,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:55] {2258} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:41:56] {2442} INFO -  at 24.5s,\testimator rf's best error=0.4830,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:56] {2258} INFO - iteration 18, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:41:56] {2442} INFO -  at 25.0s,\testimator extra_tree's best error=0.5012,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:56] {2258} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:41:57] {2442} INFO -  at 26.0s,\testimator lgbm's best error=0.3088,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:57] {2258} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:41:58] {2442} INFO -  at 26.5s,\testimator extra_tree's best error=0.5012,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:58] {2258} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:41:58] {2442} INFO -  at 26.9s,\testimator rf's best error=0.3856,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:58] {2258} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:41:59] {2442} INFO -  at 27.5s,\testimator xgboost's best error=0.3308,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:41:59] {2258} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:42:00] {2442} INFO -  at 28.7s,\testimator lgbm's best error=0.3088,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:00] {2258} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:00] {2442} INFO -  at 29.3s,\testimator rf's best error=0.3856,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:00] {2258} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:01] {2442} INFO -  at 29.7s,\testimator extra_tree's best error=0.5012,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:01] {2258} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:01] {2442} INFO -  at 30.2s,\testimator extra_tree's best error=0.4728,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:01] {2258} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:02] {2442} INFO -  at 30.6s,\testimator rf's best error=0.3856,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:02] {2258} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:02] {2442} INFO -  at 31.1s,\testimator xgboost's best error=0.3308,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:02] {2258} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:03] {2442} INFO -  at 31.6s,\testimator extra_tree's best error=0.4506,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:03] {2258} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:03] {2442} INFO -  at 32.0s,\testimator extra_tree's best error=0.4506,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:03] {2258} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:42:05] {2442} INFO -  at 33.4s,\testimator lgbm's best error=0.3088,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:05] {2258} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:42:07] {2442} INFO -  at 36.2s,\testimator lgbm's best error=0.3088,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:07] {2258} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:08] {2442} INFO -  at 37.1s,\testimator rf's best error=0.3856,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:08] {2258} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:09] {2442} INFO -  at 37.8s,\testimator extra_tree's best error=0.4506,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:09] {2258} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:42:10] {2442} INFO -  at 38.4s,\testimator lgbm's best error=0.3088,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:10] {2258} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:11] {2442} INFO -  at 39.3s,\testimator xgboost's best error=0.3168,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:11] {2258} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:11] {2442} INFO -  at 39.8s,\testimator extra_tree's best error=0.4085,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:11] {2258} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:13] {2442} INFO -  at 41.3s,\testimator xgboost's best error=0.3089,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:13] {2258} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:13] {2442} INFO -  at 42.2s,\testimator xgboost's best error=0.3089,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:13] {2258} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:14] {2442} INFO -  at 42.7s,\testimator rf's best error=0.3727,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:14] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:16] {2442} INFO -  at 44.4s,\testimator xgboost's best error=0.3089,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:16] {2258} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:16] {2442} INFO -  at 44.9s,\testimator extra_tree's best error=0.3804,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:16] {2258} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:42:20] {2442} INFO -  at 49.2s,\testimator catboost's best error=0.3075,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:20] {2258} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:21] {2442} INFO -  at 49.6s,\testimator extra_tree's best error=0.3804,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:21] {2258} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:21] {2442} INFO -  at 50.0s,\testimator extra_tree's best error=0.3684,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:21] {2258} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:22] {2442} INFO -  at 50.5s,\testimator extra_tree's best error=0.3684,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:22] {2258} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:22] {2442} INFO -  at 50.9s,\testimator rf's best error=0.3703,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:22] {2258} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:23] {2442} INFO -  at 51.4s,\testimator extra_tree's best error=0.3684,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:23] {2258} INFO - iteration 49, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:23] {2442} INFO -  at 52.1s,\testimator rf's best error=0.3703,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:23] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:24] {2442} INFO -  at 52.7s,\testimator rf's best error=0.3703,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:24] {2258} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:24] {2442} INFO -  at 53.1s,\testimator extra_tree's best error=0.3617,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:24] {2258} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:25] {2442} INFO -  at 53.6s,\testimator rf's best error=0.3672,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:25] {2258} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:25] {2442} INFO -  at 54.1s,\testimator rf's best error=0.3439,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:25] {2258} INFO - iteration 54, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:26] {2442} INFO -  at 54.6s,\testimator rf's best error=0.3439,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:26] {2258} INFO - iteration 55, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:42:33] {2442} INFO -  at 61.6s,\testimator catboost's best error=0.3075,\tbest estimator catboost's best error=0.3075\n",
      "[flaml.automl.logger: 10-30 23:42:33] {2258} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:36] {2442} INFO -  at 64.4s,\testimator xgboost's best error=0.3030,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:36] {2258} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:36] {2442} INFO -  at 65.0s,\testimator rf's best error=0.3376,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:36] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:37] {2442} INFO -  at 65.5s,\testimator rf's best error=0.3376,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:37] {2258} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:37] {2442} INFO -  at 66.2s,\testimator rf's best error=0.3376,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:37] {2258} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:42:38] {2442} INFO -  at 66.8s,\testimator lgbm's best error=0.3088,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:38] {2258} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:39] {2442} INFO -  at 68.3s,\testimator xgboost's best error=0.3030,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:39] {2258} INFO - iteration 62, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:40] {2442} INFO -  at 69.0s,\testimator rf's best error=0.3376,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:40] {2258} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:41] {2442} INFO -  at 69.4s,\testimator extra_tree's best error=0.3617,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:41] {2258} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:41] {2442} INFO -  at 69.8s,\testimator extra_tree's best error=0.3617,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:41] {2258} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:42:44] {2442} INFO -  at 72.6s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:44] {2258} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:42:44] {2442} INFO -  at 73.2s,\testimator rf's best error=0.3376,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:44] {2258} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:42:45] {2442} INFO -  at 73.6s,\testimator extra_tree's best error=0.3580,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:45] {2258} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:42:50] {2442} INFO -  at 79.2s,\testimator xgboost's best error=0.3030,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:42:50] {2258} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:43:00] {2442} INFO -  at 88.3s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:00] {2258} INFO - iteration 70, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:00] {2442} INFO -  at 88.9s,\testimator extra_tree's best error=0.3549,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:00] {2258} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:01] {2442} INFO -  at 89.6s,\testimator extra_tree's best error=0.3410,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:01] {2258} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:01] {2442} INFO -  at 90.1s,\testimator extra_tree's best error=0.3410,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:01] {2258} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:02] {2442} INFO -  at 90.7s,\testimator extra_tree's best error=0.3410,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:02] {2258} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:03] {2442} INFO -  at 91.7s,\testimator extra_tree's best error=0.3303,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:03] {2258} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:04] {2442} INFO -  at 92.5s,\testimator extra_tree's best error=0.3303,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:04] {2258} INFO - iteration 76, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:04] {2442} INFO -  at 93.1s,\testimator rf's best error=0.3376,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:04] {2258} INFO - iteration 77, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:05] {2442} INFO -  at 93.7s,\testimator rf's best error=0.3376,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:05] {2258} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:06] {2442} INFO -  at 95.2s,\testimator extra_tree's best error=0.3258,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:06] {2258} INFO - iteration 79, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:07] {2442} INFO -  at 96.0s,\testimator rf's best error=0.3367,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:07] {2258} INFO - iteration 80, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:08] {2442} INFO -  at 97.0s,\testimator rf's best error=0.3263,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:08] {2258} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:09] {2442} INFO -  at 97.9s,\testimator extra_tree's best error=0.3258,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:09] {2258} INFO - iteration 82, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:10] {2442} INFO -  at 98.7s,\testimator rf's best error=0.3263,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:10] {2258} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:14] {2442} INFO -  at 102.8s,\testimator extra_tree's best error=0.3159,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:14] {2258} INFO - iteration 84, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:15] {2442} INFO -  at 103.6s,\testimator rf's best error=0.3263,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:15] {2258} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:25] {2442} INFO -  at 113.4s,\testimator extra_tree's best error=0.3138,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:25] {2258} INFO - iteration 86, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:27] {2442} INFO -  at 115.8s,\testimator rf's best error=0.3208,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:27] {2258} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:43:28] {2442} INFO -  at 116.8s,\testimator xgboost's best error=0.3030,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:28] {2258} INFO - iteration 88, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:30] {2442} INFO -  at 118.4s,\testimator rf's best error=0.3208,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:30] {2258} INFO - iteration 89, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:33] {2442} INFO -  at 122.3s,\testimator rf's best error=0.3177,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:33] {2258} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:38] {2442} INFO -  at 126.5s,\testimator extra_tree's best error=0.3138,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:38] {2258} INFO - iteration 91, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:43:39] {2442} INFO -  at 128.1s,\testimator rf's best error=0.3177,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:39] {2258} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:43:54] {2442} INFO -  at 142.8s,\testimator extra_tree's best error=0.3138,\tbest estimator xgboost's best error=0.3030\n",
      "[flaml.automl.logger: 10-30 23:43:54] {2258} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:44:05] {2442} INFO -  at 154.0s,\testimator xgboost's best error=0.2988,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:05] {2258} INFO - iteration 94, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:44:13] {2442} INFO -  at 161.7s,\testimator rf's best error=0.3177,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:13] {2258} INFO - iteration 95, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:44:18] {2442} INFO -  at 166.6s,\testimator catboost's best error=0.3070,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:18] {2258} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:44:23] {2442} INFO -  at 171.7s,\testimator extra_tree's best error=0.3138,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:23] {2258} INFO - iteration 97, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:44:31] {2442} INFO -  at 179.9s,\testimator rf's best error=0.3149,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:31] {2258} INFO - iteration 98, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:44:34] {2442} INFO -  at 182.9s,\testimator rf's best error=0.3149,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:34] {2258} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:44:35] {2442} INFO -  at 184.0s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:35] {2258} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:44:36] {2442} INFO -  at 184.7s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:36] {2258} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:44:39] {2442} INFO -  at 187.8s,\testimator extra_tree's best error=0.3138,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:39] {2258} INFO - iteration 102, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:44:54] {2442} INFO -  at 202.6s,\testimator rf's best error=0.3149,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:44:54] {2258} INFO - iteration 103, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:45:02] {2442} INFO -  at 210.8s,\testimator catboost's best error=0.3046,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:45:02] {2258} INFO - iteration 104, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:45:06] {2442} INFO -  at 214.6s,\testimator rf's best error=0.3149,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:45:06] {2258} INFO - iteration 105, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:45:11] {2442} INFO -  at 219.8s,\testimator catboost's best error=0.3046,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:45:11] {2258} INFO - iteration 106, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:45:33] {2442} INFO -  at 241.8s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:45:33] {2258} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:46:04] {2442} INFO -  at 272.6s,\testimator extra_tree's best error=0.3118,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:46:04] {2258} INFO - iteration 108, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:47:26] {2442} INFO -  at 354.9s,\testimator catboost's best error=0.3046,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:47:26] {2258} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:47:41] {2442} INFO -  at 370.2s,\testimator extra_tree's best error=0.3118,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:47:41] {2258} INFO - iteration 110, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:47:52] {2442} INFO -  at 380.4s,\testimator xgboost's best error=0.2988,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:47:52] {2258} INFO - iteration 111, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:48:26] {2442} INFO -  at 414.4s,\testimator catboost's best error=0.2995,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:48:26] {2258} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:49:24] {2442} INFO -  at 472.5s,\testimator extra_tree's best error=0.3118,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:49:24] {2258} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:49:47] {2442} INFO -  at 495.3s,\testimator xgboost's best error=0.2988,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:49:47] {2258} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:50:31] {2442} INFO -  at 539.4s,\testimator extra_tree's best error=0.3118,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:50:31] {2258} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:50:46] {2442} INFO -  at 554.6s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:50:46] {2258} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:50:47] {2442} INFO -  at 555.4s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:50:47] {2258} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.automl.logger: 10-30 23:51:00] {2442} INFO -  at 568.5s,\testimator extra_tree's best error=0.3118,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:51:00] {2258} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl.logger: 10-30 23:51:57] {2442} INFO -  at 625.5s,\testimator xgboost's best error=0.2988,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:51:57] {2258} INFO - iteration 119, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:52:05] {2442} INFO -  at 633.4s,\testimator catboost's best error=0.2995,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:05] {2258} INFO - iteration 120, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:52:07] {2442} INFO -  at 635.7s,\testimator rf's best error=0.3149,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:07] {2258} INFO - iteration 121, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:52:33] {2442} INFO -  at 661.7s,\testimator rf's best error=0.3149,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:33] {2258} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:34] {2442} INFO -  at 662.3s,\testimator xgb_limitdepth's best error=0.3171,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:34] {2258} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:34] {2442} INFO -  at 663.0s,\testimator xgb_limitdepth's best error=0.3171,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:34] {2258} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:35] {2442} INFO -  at 663.6s,\testimator xgb_limitdepth's best error=0.3171,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:35] {2258} INFO - iteration 125, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:35] {2442} INFO -  at 664.2s,\testimator xgb_limitdepth's best error=0.3171,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:35] {2258} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:52:39] {2442} INFO -  at 667.4s,\testimator lgbm's best error=0.3066,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:39] {2258} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:52:41] {2442} INFO -  at 669.9s,\testimator lgbm's best error=0.3061,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:41] {2258} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:52:42] {2442} INFO -  at 670.9s,\testimator lgbm's best error=0.3061,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:42] {2258} INFO - iteration 129, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:43] {2442} INFO -  at 671.7s,\testimator xgb_limitdepth's best error=0.3171,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:43] {2258} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:43] {2442} INFO -  at 672.1s,\testimator xgb_limitdepth's best error=0.3171,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:43] {2258} INFO - iteration 131, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:45] {2442} INFO -  at 673.4s,\testimator xgb_limitdepth's best error=0.3158,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:45] {2258} INFO - iteration 132, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:47] {2442} INFO -  at 675.5s,\testimator xgb_limitdepth's best error=0.3060,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:47] {2258} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:48] {2442} INFO -  at 676.8s,\testimator xgb_limitdepth's best error=0.3060,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:48] {2258} INFO - iteration 134, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:49] {2442} INFO -  at 678.0s,\testimator xgb_limitdepth's best error=0.3060,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:49] {2258} INFO - iteration 135, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:55] {2442} INFO -  at 683.4s,\testimator xgb_limitdepth's best error=0.3002,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:55] {2258} INFO - iteration 136, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:52:58] {2442} INFO -  at 686.7s,\testimator xgb_limitdepth's best error=0.3002,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:52:58] {2258} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:53:09] {2442} INFO -  at 697.4s,\testimator xgb_limitdepth's best error=0.3002,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:53:09] {2258} INFO - iteration 138, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:53:10] {2442} INFO -  at 698.7s,\testimator xgb_limitdepth's best error=0.3002,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:53:10] {2258} INFO - iteration 139, current learner catboost\n",
      "[flaml.automl.logger: 10-30 23:53:15] {2442} INFO -  at 703.5s,\testimator catboost's best error=0.2995,\tbest estimator xgboost's best error=0.2988\n",
      "[flaml.automl.logger: 10-30 23:53:15] {2258} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:53:36] {2442} INFO -  at 725.1s,\testimator xgb_limitdepth's best error=0.2987,\tbest estimator xgb_limitdepth's best error=0.2987\n",
      "[flaml.automl.logger: 10-30 23:53:36] {2258} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 10-30 23:53:45] {2442} INFO -  at 733.4s,\testimator lgbm's best error=0.3061,\tbest estimator xgb_limitdepth's best error=0.2987\n",
      "[flaml.automl.logger: 10-30 23:53:45] {2258} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:54:04] {2442} INFO -  at 752.7s,\testimator xgb_limitdepth's best error=0.2966,\tbest estimator xgb_limitdepth's best error=0.2966\n",
      "[flaml.automl.logger: 10-30 23:54:04] {2258} INFO - iteration 143, current learner rf\n",
      "[flaml.automl.logger: 10-30 23:54:08] {2442} INFO -  at 757.2s,\testimator rf's best error=0.3149,\tbest estimator xgb_limitdepth's best error=0.2966\n",
      "[flaml.automl.logger: 10-30 23:54:08] {2258} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:54:30] {2442} INFO -  at 778.5s,\testimator xgb_limitdepth's best error=0.2966,\tbest estimator xgb_limitdepth's best error=0.2966\n",
      "[flaml.automl.logger: 10-30 23:54:30] {2258} INFO - iteration 145, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-30 23:56:18] {2442} INFO -  at 886.6s,\testimator xgb_limitdepth's best error=0.2966,\tbest estimator xgb_limitdepth's best error=0.2966\n",
      "[flaml.automl.logger: 10-30 23:56:18] {2582} INFO - [('xgb_limitdepth', {'n_jobs': -1, 'n_estimators': 755, 'max_depth': 4, 'min_child_weight': 1.154102748394056, 'learning_rate': 0.023707977141926465, 'subsample': 0.7880764116628435, 'colsample_bylevel': 0.8402781994721288, 'colsample_bytree': 0.7845890410152135, 'reg_alpha': 0.0009765625, 'reg_lambda': 31.51035233620019, 'verbosity': 0}), ('xgboost', {'n_jobs': -1, 'n_estimators': 409, 'max_leaves': 10, 'min_child_weight': 1.345689328454941, 'learning_rate': 0.03513747488591847, 'subsample': 0.8628114965887879, 'colsample_bylevel': 0.8645517069844122, 'colsample_bytree': 0.9171509896058663, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.157073940660053, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('catboost', {'early_stopping_rounds': 99, 'learning_rate': 0.03145620127626069, 'n_estimators': 370, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('lgbm', {'n_jobs': -1, 'n_estimators': 135, 'num_leaves': 4, 'min_child_samples': 10, 'learning_rate': 0.39910484041815447, 'colsample_bytree': 1.0, 'reg_alpha': 0.0018945146296456693, 'reg_lambda': 0.10892016707222783, 'max_bin': 63, 'verbose': -1}), ('extra_tree', {'n_jobs': -1, 'n_estimators': 723, 'max_features': 0.4115894587143523, 'criterion': 'entropy', 'max_leaf_nodes': 2592, 'random_state': 12032022, 'verbose': 0}), ('rf', {'n_jobs': -1, 'n_estimators': 118, 'max_features': 0.35720063855626205, 'criterion': 'entropy', 'max_leaf_nodes': 311, 'random_state': 12032022, 'verbose': 0})]\n",
      "[flaml.automl.logger: 10-30 23:56:18] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 10-30 23:58:15] {2631} INFO - ensemble: StackingClassifier(estimators=[('xgb_limitdepth',\n",
      "                                <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x0000022AF5757FD0>),\n",
      "                               ('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x0000022AF5757D30>),\n",
      "                               ('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x0000022AF5AC1BD0>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x0000022AF5AC10...\n",
      "                                                   interaction_constraints=None,\n",
      "                                                   max_bin=None,\n",
      "                                                   max_cat_threshold=None,\n",
      "                                                   max_cat_to_onehot=None,\n",
      "                                                   max_delta_step=None,\n",
      "                                                   max_depth=None,\n",
      "                                                   max_leaves=None,\n",
      "                                                   min_child_weight=None,\n",
      "                                                   missing=nan,\n",
      "                                                   monotone_constraints=None,\n",
      "                                                   multi_strategy=None,\n",
      "                                                   n_estimators=None,\n",
      "                                                   n_jobs=None,\n",
      "                                                   num_parallel_tree=None,\n",
      "                                                   objective='binary:logistic',\n",
      "                                                   random_state=None,\n",
      "                                                   reg_alpha=None, ...),\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 10-30 23:58:15] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 10-30 23:58:15] {1986} INFO - Time taken to find the best model: 752.7302968502045\n",
      "[flaml.automl.logger: 10-30 23:58:15] {1996} WARNING - Time taken to find the best model is 84% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*15,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"ensemble\" : {'final_estimator' : XGBRFClassifier() },    # 메타모델이 로지스틱 회귀!\n",
    "           \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']  }   # 앙상블에 사용할 모델 지정\n",
    "auto_ml_ens.fit(train_08, target, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3405316973415133"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = auto_ml_ens.predict(test_08)\n",
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = pred\n",
    "\n",
    "submit.to_csv(\"전현설_08_3.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
