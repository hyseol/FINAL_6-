{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "N44QYORV8wFy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1qAeLjZVWZz"
   },
   "source": [
    "- 시드값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nVyhJ6uOVVNE"
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd7JpzNBHa1"
   },
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KFGKUIWt89fZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523105, 7), (14940, 2), (441196, 7), (12225, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Data/\"\n",
    "train_tr = pd.read_csv(f\"{DATA_PATH}store_train_transactions.csv\") # 학습용 구매기록 데이터\n",
    "train_target = pd.read_csv(f\"{DATA_PATH}store_train.csv\") # 학습용 정답 데이터\n",
    "test_tr = pd.read_csv(f\"{DATA_PATH}store_test_transactions.csv\") # 테스트용 구매기록 데이터\n",
    "submit = pd.read_csv(f\"{DATA_PATH}store_submission.csv\") # 제출 양식 데이터\n",
    "\n",
    "train_tr.shape , train_target.shape , test_tr.shape , submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정답 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXinfWehVH4-"
   },
   "source": [
    "# cv 점수 확인해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 레이어 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 데이터 준비\n",
    "X_train = ...\n",
    "y_train = ...\n",
    "X_test = ...\n",
    "\n",
    "# 1단계: 기본 모델 정의\n",
    "base_models = [\n",
    "    LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=6),\n",
    "    XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, use_label_encoder=False, eval_metric='logloss'),\n",
    "    CatBoostClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, verbose=0)\n",
    "]\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "meta_model_1 = LogisticRegression()\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "meta_model_2 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# 1단계: Base models 학습 및 예측\n",
    "base_model_preds = np.zeros((X_train.shape[0], len(base_models)))\n",
    "test_preds_stage1 = np.zeros((X_test.shape[0], len(base_models)))\n",
    "\n",
    "for i, model in enumerate(base_models):\n",
    "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        base_model_preds[val_idx, i] = model.predict_proba(X_val)[:, 1]  # Class 1 확률\n",
    "        test_preds_stage1[:, i] += model.predict_proba(X_test)[:, 1] / n_folds  # Test 평균 예측\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, y_train)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), y_train)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(y_train, (meta_preds_stage2 > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 데이터 준비\n",
    "# X_train = train_ft\n",
    "# y_train = target\n",
    "# X_test = test_ft\n",
    "\n",
    "# 1단계: 기본 모델 정의\n",
    "base_models = [\n",
    "    LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=6),\n",
    "    XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, use_label_encoder=False, eval_metric='logloss'),\n",
    "    CatBoostClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, verbose=0)\n",
    "]\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "meta_model_1 = LogisticRegression()\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "meta_model_2 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# 1단계: Base models 학습 및 예측\n",
    "base_model_preds = np.zeros((train_ft.shape[0], len(base_models)))\n",
    "test_preds_stage1 = np.zeros((test_ft.shape[0], len(base_models)))\n",
    "\n",
    "for i, model in enumerate(base_models):\n",
    "    for tri, vai in cv.split(train_ft, target):\n",
    "    # 학습 데이터와 검증 데이터 분리\n",
    "        x_train = train_ft.iloc[tri]\n",
    "        y_train = target.iloc[tri]\n",
    "        x_valid = train_ft.iloc[vai]\n",
    "        y_valid = target.iloc[vai]\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        base_model_preds[vai, i] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "        test_preds_stage1[:, i] += model.predict_proba(test_ft)[:, 1] / n_folds  # Test 평균 예측\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.5).astype(int)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1단계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1471), (12225, 1471))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 3), (12225, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds = np.zeros((train_ft.shape[0], 3))\n",
    "test_preds_stage1 = np.zeros((test_ft.shape[0], 3))\n",
    "\n",
    "base_model_preds.shape, test_preds_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGB_v3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1504), (12225, 1504))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.0_1106.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.0_1106.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1503), (12225, 1503))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1507), (12225, 1507))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1509), (12225, 1509))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1506), (12225, 1506))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 0] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 0] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 0] = test_preds_stage1[:, 0] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.        , 0.        ],\n",
       "        [0.91239369, 0.        , 0.        ],\n",
       "        [0.06883854, 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.09131553, 0.        , 0.        ],\n",
       "        [0.88809782, 0.        , 0.        ],\n",
       "        [0.44763535, 0.        , 0.        ]]),\n",
       " array([[0.05952867, 0.        , 0.        ],\n",
       "        [0.3970897 , 0.        , 0.        ],\n",
       "        [0.3032796 , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03583201, 0.        , 0.        ],\n",
       "        [0.13214782, 0.        , 0.        ],\n",
       "        [0.0251264 , 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGB_v3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1471), (12225, 1471))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1470), (12225, 1470))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1474), (12225, 1474))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1476), (12225, 1476))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1473), (12225, 1473))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 1] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 1] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 1] = test_preds_stage1[:, 1] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.17354608, 0.        ],\n",
       "        [0.91239369, 0.90294158, 0.        ],\n",
       "        [0.06883854, 0.05948123, 0.        ],\n",
       "        ...,\n",
       "        [0.09131553, 0.05808163, 0.        ],\n",
       "        [0.88809782, 0.8570658 , 0.        ],\n",
       "        [0.44763535, 0.50293088, 0.        ]]),\n",
       " array([[0.05952867, 0.05414822, 0.        ],\n",
       "        [0.3970897 , 0.370909  , 0.        ],\n",
       "        [0.3032796 , 0.31456018, 0.        ],\n",
       "        ...,\n",
       "        [0.03583201, 0.03669401, 0.        ],\n",
       "        [0.13214782, 0.11258472, 0.        ],\n",
       "        [0.0251264 , 0.02188812, 0.        ]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- voting_v3.3_selection(logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>내점일수</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>평일방문비율</th>\n",
       "      <th>주말방문횟수</th>\n",
       "      <th>평일방문횟수</th>\n",
       "      <th>봄_구매비율</th>\n",
       "      <th>여름_구매비율</th>\n",
       "      <th>가을_구매비율</th>\n",
       "      <th>겨울_구매비율</th>\n",
       "      <th>주구매요일</th>\n",
       "      <th>주구매_년</th>\n",
       "      <th>주구매_월</th>\n",
       "      <th>주구매_시간대</th>\n",
       "      <th>일별평균구매횟수</th>\n",
       "      <th>거래개월수</th>\n",
       "      <th>9시_12시_구매비율</th>\n",
       "      <th>12시_15시_구매비율</th>\n",
       "      <th>15시_18시_구매비율</th>\n",
       "      <th>18시_21시_구매비율</th>\n",
       "      <th>9시_12시_구매횟수</th>\n",
       "      <th>12시_15시_구매횟수</th>\n",
       "      <th>15시_18시_구매횟수</th>\n",
       "      <th>18시_21시_구매횟수</th>\n",
       "      <th>월초_구매비율</th>\n",
       "      <th>월말_구매비율</th>\n",
       "      <th>월초_구매횟수</th>\n",
       "      <th>월말_구매횟수</th>\n",
       "      <th>웨딩성수기_구매비율</th>\n",
       "      <th>웨딩성수기_구매횟수</th>\n",
       "      <th>1월_구매비율</th>\n",
       "      <th>2월_구매비율</th>\n",
       "      <th>3월_구매비율</th>\n",
       "      <th>4월_구매비율</th>\n",
       "      <th>5월_구매비율</th>\n",
       "      <th>6월_구매비율</th>\n",
       "      <th>7월_구매비율</th>\n",
       "      <th>8월_구매비율</th>\n",
       "      <th>9월_구매비율</th>\n",
       "      <th>10월_구매비율</th>\n",
       "      <th>...</th>\n",
       "      <th>공휴일_대분류_아동문화_총구매금액</th>\n",
       "      <th>공휴일_대분류_여성의류파트_총구매금액</th>\n",
       "      <th>공휴일_대분류_여성정장_총구매금액</th>\n",
       "      <th>공휴일_대분류_여성캐쥬얼_총구매금액</th>\n",
       "      <th>공휴일_대분류_영라이브_총구매금액</th>\n",
       "      <th>공휴일_대분류_영어덜트캐쥬얼_총구매금액</th>\n",
       "      <th>공휴일_대분류_영캐릭터_총구매금액</th>\n",
       "      <th>공휴일_대분류_영플라자_총구매금액</th>\n",
       "      <th>공휴일_대분류_잡화_총구매금액</th>\n",
       "      <th>공휴일_대분류_케주얼_구두_아동_총구매금액</th>\n",
       "      <th>공휴일_대분류_패션잡화_총구매금액</th>\n",
       "      <th>공휴일_대분류_가정용품_구매횟수</th>\n",
       "      <th>공휴일_대분류_골프_유니캐쥬얼_구매횟수</th>\n",
       "      <th>공휴일_대분류_공산품_구매횟수</th>\n",
       "      <th>공휴일_대분류_남성의류_구매횟수</th>\n",
       "      <th>공휴일_대분류_남성정장스포츠_구매횟수</th>\n",
       "      <th>공휴일_대분류_로얄부틱_구매횟수</th>\n",
       "      <th>공휴일_대분류_명품잡화_구매횟수</th>\n",
       "      <th>공휴일_대분류_생식품_구매횟수</th>\n",
       "      <th>공휴일_대분류_스포츠캐쥬얼_구매횟수</th>\n",
       "      <th>공휴일_대분류_아동_구매횟수</th>\n",
       "      <th>공휴일_대분류_아동_스포츠_구매횟수</th>\n",
       "      <th>공휴일_대분류_아동문화_구매횟수</th>\n",
       "      <th>공휴일_대분류_여성의류파트_구매횟수</th>\n",
       "      <th>공휴일_대분류_여성정장_구매횟수</th>\n",
       "      <th>공휴일_대분류_여성캐쥬얼_구매횟수</th>\n",
       "      <th>공휴일_대분류_영라이브_구매횟수</th>\n",
       "      <th>공휴일_대분류_영어덜트캐쥬얼_구매횟수</th>\n",
       "      <th>공휴일_대분류_영캐릭터_구매횟수</th>\n",
       "      <th>공휴일_대분류_영플라자_구매횟수</th>\n",
       "      <th>공휴일_대분류_잡화_구매횟수</th>\n",
       "      <th>공휴일_대분류_케주얼_구두_아동_구매횟수</th>\n",
       "      <th>공휴일_대분류_패션잡화_구매횟수</th>\n",
       "      <th>cluster</th>\n",
       "      <th>주구매지점_1</th>\n",
       "      <th>주구매지점_2</th>\n",
       "      <th>주구매지점_3</th>\n",
       "      <th>주구매지점_4</th>\n",
       "      <th>주구매_중분류_cnt</th>\n",
       "      <th>주구매_대분류_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369867</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.257728</td>\n",
       "      <td>-0.257728</td>\n",
       "      <td>-0.230862</td>\n",
       "      <td>-0.390544</td>\n",
       "      <td>-1.029777</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.838272</td>\n",
       "      <td>0.338186</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>-0.482151</td>\n",
       "      <td>1.851040</td>\n",
       "      <td>-1.345509</td>\n",
       "      <td>-0.057297</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>-0.597009</td>\n",
       "      <td>0.704620</td>\n",
       "      <td>-0.413647</td>\n",
       "      <td>0.071850</td>\n",
       "      <td>-0.597009</td>\n",
       "      <td>0.704620</td>\n",
       "      <td>-0.413647</td>\n",
       "      <td>0.071850</td>\n",
       "      <td>0.567827</td>\n",
       "      <td>0.092192</td>\n",
       "      <td>-0.203556</td>\n",
       "      <td>-0.313132</td>\n",
       "      <td>-0.519468</td>\n",
       "      <td>-0.491469</td>\n",
       "      <td>-0.236981</td>\n",
       "      <td>-0.576086</td>\n",
       "      <td>-0.622120</td>\n",
       "      <td>-0.670149</td>\n",
       "      <td>-0.282014</td>\n",
       "      <td>0.421006</td>\n",
       "      <td>0.050936</td>\n",
       "      <td>-0.596434</td>\n",
       "      <td>1.047253</td>\n",
       "      <td>-0.698995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086907</td>\n",
       "      <td>-0.092340</td>\n",
       "      <td>-0.062198</td>\n",
       "      <td>-0.134168</td>\n",
       "      <td>-0.095225</td>\n",
       "      <td>-0.068361</td>\n",
       "      <td>-0.081019</td>\n",
       "      <td>-0.126840</td>\n",
       "      <td>-0.084245</td>\n",
       "      <td>-0.174285</td>\n",
       "      <td>-0.162678</td>\n",
       "      <td>-0.222962</td>\n",
       "      <td>-0.150631</td>\n",
       "      <td>-0.301801</td>\n",
       "      <td>-0.179448</td>\n",
       "      <td>-0.139182</td>\n",
       "      <td>-0.105096</td>\n",
       "      <td>-0.225863</td>\n",
       "      <td>-0.252797</td>\n",
       "      <td>-0.165962</td>\n",
       "      <td>-0.110783</td>\n",
       "      <td>-0.148917</td>\n",
       "      <td>-0.121695</td>\n",
       "      <td>-0.128685</td>\n",
       "      <td>-0.138524</td>\n",
       "      <td>-0.211595</td>\n",
       "      <td>-0.116973</td>\n",
       "      <td>-0.108769</td>\n",
       "      <td>-0.10576</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>-0.209907</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>0.270695</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.741478</td>\n",
       "      <td>-1.315250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144110</td>\n",
       "      <td>-0.356452</td>\n",
       "      <td>-1.008554</td>\n",
       "      <td>1.008554</td>\n",
       "      <td>-0.619841</td>\n",
       "      <td>0.412809</td>\n",
       "      <td>0.323951</td>\n",
       "      <td>-0.390607</td>\n",
       "      <td>0.620171</td>\n",
       "      <td>-0.552996</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>-0.482151</td>\n",
       "      <td>0.924134</td>\n",
       "      <td>1.132588</td>\n",
       "      <td>0.222706</td>\n",
       "      <td>1.176010</td>\n",
       "      <td>-0.231765</td>\n",
       "      <td>0.715412</td>\n",
       "      <td>-0.896636</td>\n",
       "      <td>0.333357</td>\n",
       "      <td>-0.231765</td>\n",
       "      <td>0.715412</td>\n",
       "      <td>-0.896636</td>\n",
       "      <td>0.333357</td>\n",
       "      <td>-0.429672</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>-0.083161</td>\n",
       "      <td>0.523032</td>\n",
       "      <td>0.601863</td>\n",
       "      <td>0.544216</td>\n",
       "      <td>-0.256440</td>\n",
       "      <td>-0.576086</td>\n",
       "      <td>0.433398</td>\n",
       "      <td>-0.383294</td>\n",
       "      <td>0.579383</td>\n",
       "      <td>-0.500985</td>\n",
       "      <td>-0.521621</td>\n",
       "      <td>0.510469</td>\n",
       "      <td>1.370221</td>\n",
       "      <td>-0.328741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086907</td>\n",
       "      <td>-0.092340</td>\n",
       "      <td>-0.062198</td>\n",
       "      <td>-0.134168</td>\n",
       "      <td>-0.095225</td>\n",
       "      <td>-0.068361</td>\n",
       "      <td>-0.081019</td>\n",
       "      <td>2.546882</td>\n",
       "      <td>-0.084245</td>\n",
       "      <td>-0.174285</td>\n",
       "      <td>3.590341</td>\n",
       "      <td>-0.222962</td>\n",
       "      <td>-0.150631</td>\n",
       "      <td>-0.301801</td>\n",
       "      <td>-0.179448</td>\n",
       "      <td>-0.139182</td>\n",
       "      <td>-0.105096</td>\n",
       "      <td>-0.225863</td>\n",
       "      <td>-0.252797</td>\n",
       "      <td>-0.165962</td>\n",
       "      <td>-0.110783</td>\n",
       "      <td>-0.148917</td>\n",
       "      <td>-0.121695</td>\n",
       "      <td>-0.128685</td>\n",
       "      <td>-0.138524</td>\n",
       "      <td>-0.211595</td>\n",
       "      <td>-0.116973</td>\n",
       "      <td>-0.108769</td>\n",
       "      <td>-0.10576</td>\n",
       "      <td>2.389509</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>-0.209907</td>\n",
       "      <td>4.161199</td>\n",
       "      <td>0.270695</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>1.604686</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.448069</td>\n",
       "      <td>-0.626416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.943028</td>\n",
       "      <td>-0.869935</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>-0.036742</td>\n",
       "      <td>1.616788</td>\n",
       "      <td>1.926821</td>\n",
       "      <td>0.798943</td>\n",
       "      <td>-0.514333</td>\n",
       "      <td>-0.304527</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>-1.643370</td>\n",
       "      <td>-0.482151</td>\n",
       "      <td>-0.620708</td>\n",
       "      <td>-0.106461</td>\n",
       "      <td>0.277707</td>\n",
       "      <td>1.465608</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.102531</td>\n",
       "      <td>0.545699</td>\n",
       "      <td>-0.371335</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.102531</td>\n",
       "      <td>0.545699</td>\n",
       "      <td>-0.371335</td>\n",
       "      <td>-0.412172</td>\n",
       "      <td>0.562013</td>\n",
       "      <td>1.180992</td>\n",
       "      <td>2.752802</td>\n",
       "      <td>0.483828</td>\n",
       "      <td>2.680316</td>\n",
       "      <td>0.214679</td>\n",
       "      <td>0.184729</td>\n",
       "      <td>0.220442</td>\n",
       "      <td>0.439526</td>\n",
       "      <td>0.579383</td>\n",
       "      <td>-0.290401</td>\n",
       "      <td>-0.239110</td>\n",
       "      <td>-0.351750</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>-0.357972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086907</td>\n",
       "      <td>-0.092340</td>\n",
       "      <td>-0.062198</td>\n",
       "      <td>-0.134168</td>\n",
       "      <td>-0.095225</td>\n",
       "      <td>-0.068361</td>\n",
       "      <td>-0.081019</td>\n",
       "      <td>-0.126840</td>\n",
       "      <td>-0.084245</td>\n",
       "      <td>-0.174285</td>\n",
       "      <td>-0.162678</td>\n",
       "      <td>-0.222962</td>\n",
       "      <td>2.490714</td>\n",
       "      <td>-0.301801</td>\n",
       "      <td>-0.179448</td>\n",
       "      <td>-0.139182</td>\n",
       "      <td>-0.105096</td>\n",
       "      <td>12.160452</td>\n",
       "      <td>-0.252797</td>\n",
       "      <td>-0.165962</td>\n",
       "      <td>-0.110783</td>\n",
       "      <td>2.274631</td>\n",
       "      <td>-0.121695</td>\n",
       "      <td>-0.128685</td>\n",
       "      <td>-0.138524</td>\n",
       "      <td>-0.211595</td>\n",
       "      <td>-0.116973</td>\n",
       "      <td>-0.108769</td>\n",
       "      <td>-0.10576</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>-0.209907</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>-3.694193</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>1.632592</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.869072</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.793345</td>\n",
       "      <td>-1.023980</td>\n",
       "      <td>-0.080558</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>3.172703</td>\n",
       "      <td>4.429574</td>\n",
       "      <td>0.420933</td>\n",
       "      <td>-0.327474</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>-0.135636</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>-0.482151</td>\n",
       "      <td>-0.620708</td>\n",
       "      <td>0.719571</td>\n",
       "      <td>0.674668</td>\n",
       "      <td>1.465608</td>\n",
       "      <td>-0.160793</td>\n",
       "      <td>-0.089151</td>\n",
       "      <td>0.227983</td>\n",
       "      <td>-0.047873</td>\n",
       "      <td>-0.160793</td>\n",
       "      <td>-0.089151</td>\n",
       "      <td>0.227983</td>\n",
       "      <td>-0.047873</td>\n",
       "      <td>0.071441</td>\n",
       "      <td>-0.178796</td>\n",
       "      <td>4.190881</td>\n",
       "      <td>3.519286</td>\n",
       "      <td>0.081055</td>\n",
       "      <td>4.428034</td>\n",
       "      <td>-0.258285</td>\n",
       "      <td>0.163815</td>\n",
       "      <td>0.393378</td>\n",
       "      <td>0.300535</td>\n",
       "      <td>-0.056313</td>\n",
       "      <td>-0.120910</td>\n",
       "      <td>-0.023856</td>\n",
       "      <td>-0.464235</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>-0.183097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086907</td>\n",
       "      <td>10.675203</td>\n",
       "      <td>-0.062198</td>\n",
       "      <td>-0.134168</td>\n",
       "      <td>-0.095225</td>\n",
       "      <td>-0.068361</td>\n",
       "      <td>-0.081019</td>\n",
       "      <td>8.611831</td>\n",
       "      <td>-0.084245</td>\n",
       "      <td>2.058189</td>\n",
       "      <td>-0.162678</td>\n",
       "      <td>-0.222962</td>\n",
       "      <td>-0.150631</td>\n",
       "      <td>-0.301801</td>\n",
       "      <td>-0.179448</td>\n",
       "      <td>5.151871</td>\n",
       "      <td>-0.105096</td>\n",
       "      <td>-0.225863</td>\n",
       "      <td>-0.252797</td>\n",
       "      <td>-0.165962</td>\n",
       "      <td>-0.110783</td>\n",
       "      <td>-0.148917</td>\n",
       "      <td>-0.121695</td>\n",
       "      <td>6.489418</td>\n",
       "      <td>-0.138524</td>\n",
       "      <td>-0.211595</td>\n",
       "      <td>-0.116973</td>\n",
       "      <td>-0.108769</td>\n",
       "      <td>-0.10576</td>\n",
       "      <td>10.044273</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>1.301424</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>-3.694193</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>1.515861</td>\n",
       "      <td>-0.248364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452496</td>\n",
       "      <td>-0.613193</td>\n",
       "      <td>0.302875</td>\n",
       "      <td>-0.302875</td>\n",
       "      <td>0.838830</td>\n",
       "      <td>0.567300</td>\n",
       "      <td>-0.752532</td>\n",
       "      <td>1.707410</td>\n",
       "      <td>-0.130285</td>\n",
       "      <td>-0.821561</td>\n",
       "      <td>0.693965</td>\n",
       "      <td>-0.482151</td>\n",
       "      <td>0.306197</td>\n",
       "      <td>0.306555</td>\n",
       "      <td>0.679008</td>\n",
       "      <td>0.886413</td>\n",
       "      <td>0.021550</td>\n",
       "      <td>-0.165379</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>-0.317880</td>\n",
       "      <td>0.021550</td>\n",
       "      <td>-0.165379</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>-0.317880</td>\n",
       "      <td>-0.182979</td>\n",
       "      <td>0.193366</td>\n",
       "      <td>0.458619</td>\n",
       "      <td>0.801753</td>\n",
       "      <td>-0.410952</td>\n",
       "      <td>0.285294</td>\n",
       "      <td>-0.513805</td>\n",
       "      <td>-0.156411</td>\n",
       "      <td>-0.383777</td>\n",
       "      <td>-0.670149</td>\n",
       "      <td>-0.055749</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>1.723587</td>\n",
       "      <td>0.603306</td>\n",
       "      <td>0.582335</td>\n",
       "      <td>-0.322770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086907</td>\n",
       "      <td>11.654988</td>\n",
       "      <td>-0.062198</td>\n",
       "      <td>-0.134168</td>\n",
       "      <td>-0.095225</td>\n",
       "      <td>-0.068361</td>\n",
       "      <td>-0.081019</td>\n",
       "      <td>-0.126840</td>\n",
       "      <td>0.292244</td>\n",
       "      <td>2.289135</td>\n",
       "      <td>-0.162678</td>\n",
       "      <td>-0.222962</td>\n",
       "      <td>-0.150631</td>\n",
       "      <td>2.623216</td>\n",
       "      <td>-0.179448</td>\n",
       "      <td>-0.139182</td>\n",
       "      <td>8.918687</td>\n",
       "      <td>-0.225863</td>\n",
       "      <td>-0.252797</td>\n",
       "      <td>-0.165962</td>\n",
       "      <td>-0.110783</td>\n",
       "      <td>-0.148917</td>\n",
       "      <td>-0.121695</td>\n",
       "      <td>9.798470</td>\n",
       "      <td>-0.138524</td>\n",
       "      <td>-0.211595</td>\n",
       "      <td>-0.116973</td>\n",
       "      <td>-0.108769</td>\n",
       "      <td>-0.10576</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>4.377687</td>\n",
       "      <td>4.324087</td>\n",
       "      <td>-0.213001</td>\n",
       "      <td>0.270695</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.847712</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       내점일수      구매주기    주말방문비율  ...   주구매지점_4  주구매_중분류_cnt  주구매_대분류_cnt\n",
       "0 -0.369867  0.002987  0.257728  ... -0.468181    -0.741478    -1.315250\n",
       "1  0.144110 -0.356452 -1.008554  ... -0.468181    -0.448069    -0.626416\n",
       "2  1.943028 -0.869935  0.036742  ... -0.468181    -0.869072     1.064726\n",
       "3  3.793345 -1.023980 -0.080558  ... -0.468181     1.515861    -0.248364\n",
       "4  0.452496 -0.613193  0.302875  ... -0.468181    -0.847712     1.064726\n",
       "\n",
       "[5 rows x 1473 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "logi = LogisticRegression(random_state=42)\n",
    "fs = SelectFromModel(logi)          # 특성 선택에 사용하기 위한 모델 객체를 전달해줘야함.\n",
    "fs.fit_transform(train_ft, target)  # 특성 선택이 완료된 입력 데이터가 ndarray 로 반환\n",
    "\n",
    "best_cols_logi = fs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "params_xgb = {'n_estimators': 1000,'learning_rate': 0.027075406407767497,'max_depth': 5,'min_child_weight': 7,\n",
    "              'subsample': 0.6789816859997232,'colsample_bytree': 0.6682531834544282,'gamma': 1.5046881781916308}\n",
    "params_lgbm = {'n_estimators': 813, 'learning_rate': 0.014757440400599073, 'num_leaves': 35, 'max_depth': 12, \n",
    "               'min_child_samples': 41, 'subsample': 0.85, 'colsample_bytree': 0.95}\n",
    "params_logi = {'C': 1.2056308154836568, 'solver': 'saga', 'max_iter': 400, 'class_weight': 'balanced', \n",
    "               'tol': 3.689794777633075e-05}            # optuna trial 30 : 0.727821596703826.\n",
    "\n",
    "estimators = [\n",
    "    (\"lgbm\", LGBMClassifier(random_state=42, **params_lgbm)),\n",
    "    (\"xgb\", XGBClassifier(random_state=42, **params_xgb) ),\n",
    "    (\"logi\", LogisticRegression(random_state=42, **params_logi) ),  ]\n",
    "\n",
    "parmas = {\n",
    "    \"estimators\": estimators,\n",
    "    \"voting\" : \"soft\",\n",
    "    \"n_jobs\" : -1   }\n",
    "\n",
    "model = VotingClassifier(**parmas)\n",
    "\n",
    "for tri, vai in cv.split(train_ft[best_cols_logi], target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft[best_cols_logi].iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft[best_cols_logi].iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 2] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 2] += model.predict_proba(test_ft[best_cols_logi])[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 2] = test_preds_stage1[:, 2] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.17354608, 0.19652221],\n",
       "        [0.91239369, 0.90294158, 0.83046801],\n",
       "        [0.06883854, 0.05948123, 0.09595352],\n",
       "        ...,\n",
       "        [0.09131553, 0.05808163, 0.09557961],\n",
       "        [0.88809782, 0.8570658 , 0.87621579],\n",
       "        [0.44763535, 0.50293088, 0.67060904]]),\n",
       " array([[0.05952867, 0.05414822, 0.09066435],\n",
       "        [0.3970897 , 0.370909  , 0.35863644],\n",
       "        [0.3032796 , 0.31456018, 0.4260002 ],\n",
       "        ...,\n",
       "        [0.03583201, 0.03669401, 0.03895556],\n",
       "        [0.13214782, 0.11258472, 0.43560855],\n",
       "        [0.0251264 , 0.02188812, 0.01153557]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-Score: 0.6603418956412781\n"
     ]
    }
   ],
   "source": [
    "# 2단계: 중간 모델 정의\n",
    "meta_model_1 = LogisticRegression()\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "meta_model_2 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-Score: 0.7173878586146775\n"
     ]
    }
   ],
   "source": [
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'n_estimators': 323, \n",
    "             'criterion': 'entropy', \n",
    "             'max_depth': 4, \n",
    "             'num_leaves': 71, \n",
    "             'min_samples_split': 17, \n",
    "             'max_features': 0.8, \n",
    "             'bagging_fraction': 0.8154571896905384, \n",
    "             'bagging_freq': 3}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "meta_model_2 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.4).astype(int)))\n",
    "\n",
    "# 0.5 : 0.695031665328695\n",
    "# 0.4 : 0.7173878586146775"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-Score: 0.7295865939451427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "meta_model_2 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.4).astype(int)))\n",
    "\n",
    "# 0.5 : 0.7068919281308662\n",
    "# 0.4 : 0.7295865939451427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = (final_preds > 0.5).astype(int)\n",
    "submit.to_csv(\"multi_layer_ensemble_03_1112.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-Score (Validation): 0.6806363989134653\n",
      "Test Predictions: [0.00664969 0.25261158 0.4467082  ... 0.01052834 0.07010135 0.00664969]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분리 (훈련 및 테스트 데이터 생성)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(base_model_preds, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "xgb_params = {'n_estimators': 1000,\n",
    "            'learning_rate': 0.027075406407767497,\n",
    "            'max_depth': 5,\n",
    "            'min_child_weight': 7,\n",
    "            'subsample': 0.6789816859997232,\n",
    "            'colsample_bytree': 0.6682531834544282,\n",
    "            'gamma': 1.5046881781916308}\n",
    "meta_model_2 = XGBClassifier(**xgb_params)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(X_train, y_train)\n",
    "meta_preds_stage2_train = meta_model_1.predict_proba(X_train)[:, 1]  # 학습 데이터 예측\n",
    "meta_preds_stage2_valid = meta_model_1.predict_proba(X_valid)[:, 1]  # 검증 데이터 예측\n",
    "meta_preds_stage2_test = meta_model_1.predict_proba(test_preds_stage1)[:, 1]  # 테스트 데이터 예측\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2_train.reshape(-1, 1), y_train)\n",
    "final_preds_valid = meta_model_2.predict_proba(meta_preds_stage2_valid.reshape(-1, 1))[:, 1]\n",
    "final_preds_test = meta_model_2.predict_proba(meta_preds_stage2_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 검증 데이터 기반 최종 F1 점수 출력\n",
    "threshold = 0.4  # 결정 임계값\n",
    "final_f1_score = f1_score(y_valid, (final_preds_valid > threshold).astype(int))\n",
    "print(\"Final F1-Score (Validation):\", final_f1_score)\n",
    "\n",
    "# 최종 테스트 예측 결과 (필요시 저장 또는 제출)\n",
    "print(\"Test Predictions:\", final_preds_test)\n",
    "\n",
    "\n",
    "# # 2단계: Meta model 1 학습 및 예측\n",
    "# meta_model_1.fit(base_model_preds, target)\n",
    "# meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "# test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# # 3단계: Meta model 2 학습 및 예측\n",
    "# meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "# final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# # 최종 예측 결과 출력\n",
    "# print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.5).astype(int)))\n",
    "\n",
    "# 0.5 : 0.6510638297872341\n",
    "# 0.4 : 0.6806363989134653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = (final_preds_test > 0.5).astype(int)\n",
    "submit.to_csv(\"multi_layer_ensemble_04_1112.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1단계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1471), (12225, 1471))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 5), (12225, 5))"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds = np.zeros((train_ft.shape[0], 5))\n",
    "test_preds_stage1 = np.zeros((test_ft.shape[0], 5))\n",
    "\n",
    "base_model_preds.shape, test_preds_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGB_v3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1504), (12225, 1504))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.0_1106.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.0_1106.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1503), (12225, 1503))"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1507), (12225, 1507))"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1509), (12225, 1509))"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1506), (12225, 1506))"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 0] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 0] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 0] = test_preds_stage1[:, 0] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.91239369, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.06883854, 0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.09131553, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.88809782, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.44763535, 0.        , 0.        , 0.        , 0.        ]]),\n",
       " array([[0.05952867, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.3970897 , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.3032796 , 0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03583201, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.13214782, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.0251264 , 0.        , 0.        , 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGB_v3.3_군집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1471), (12225, 1471))"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1470), (12225, 1470))"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1474), (12225, 1474))"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1476), (12225, 1476))"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1473), (12225, 1473))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 1] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 1] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 1] = test_preds_stage1[:, 1] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.17354608, 0.        , 0.        , 0.        ],\n",
       "        [0.91239369, 0.90294158, 0.        , 0.        , 0.        ],\n",
       "        [0.06883854, 0.05948123, 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.09131553, 0.05808163, 0.        , 0.        , 0.        ],\n",
       "        [0.88809782, 0.8570658 , 0.        , 0.        , 0.        ],\n",
       "        [0.44763535, 0.50293088, 0.        , 0.        , 0.        ]]),\n",
       " array([[0.05952867, 0.05414822, 0.        , 0.        , 0.        ],\n",
       "        [0.3970897 , 0.370909  , 0.        , 0.        , 0.        ],\n",
       "        [0.3032796 , 0.31456018, 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03583201, 0.03669401, 0.        , 0.        , 0.        ],\n",
       "        [0.13214782, 0.11258472, 0.        , 0.        , 0.        ],\n",
       "        [0.0251264 , 0.02188812, 0.        , 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비선형스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1472), (12225, 1472))"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_log_sqrt.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_log_sqrt.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 900, 'learning_rate': 0.021734683976721573, \n",
    "          'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.7039147285447092, \n",
    "          'colsample_bytree': 0.5823954097077503, 'gamma': 2.3107011128410493}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 2] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 2] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 2] = test_preds_stage1[:, 2] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 125615\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 125431\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 125558\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1151\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 125581\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1150\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4700, number of negative: 7252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 125438\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1149\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393240 -> initscore=-0.433715\n",
      "[LightGBM] [Info] Start training from score -0.433715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'num_leaves': 33, 'max_depth': 11, 'learning_rate': 0.01944354088862471, \n",
    "          'n_estimators': 800, 'min_child_samples': 65, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'reg_alpha': 3.6529269182968447e-07, 'reg_lambda': 3.3190277841665685e-07}\n",
    "\n",
    "model = LGBMClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 2] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 2] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 2] = test_preds_stage1[:, 2] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.17354608, 0.15177752, 0.14746045, 0.17505557],\n",
       "        [0.91239369, 0.90294158, 0.86739022, 0.89029574, 0.90022984],\n",
       "        [0.06883854, 0.05948123, 0.10417092, 0.10765477, 0.11742994],\n",
       "        ...,\n",
       "        [0.09131553, 0.05808163, 0.07673107, 0.06465057, 0.08587301],\n",
       "        [0.88809782, 0.8570658 , 0.8311848 , 0.85228878, 0.7996535 ],\n",
       "        [0.44763535, 0.50293088, 0.49338105, 0.50181866, 0.48827395]]),\n",
       " array([[0.05952867, 0.05414822, 0.07463105, 0.04921332, 0.07374778],\n",
       "        [0.3970897 , 0.370909  , 0.4579488 , 0.37870907, 0.40602474],\n",
       "        [0.3032796 , 0.31456018, 0.39116583, 0.3238593 , 0.33665219],\n",
       "        ...,\n",
       "        [0.03583201, 0.03669401, 0.04409213, 0.0315213 , 0.05671894],\n",
       "        [0.13214782, 0.11258472, 0.12905987, 0.09887918, 0.0998593 ],\n",
       "        [0.0251264 , 0.02188812, 0.03046445, 0.02296214, 0.02486843]]))"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGB_v3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1470), (12225, 1470))"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1469), (12225, 1469))"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1473), (12225, 1473))"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1475), (12225, 1475))"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1472), (12225, 1472))"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 3] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 3] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 3] = test_preds_stage1[:, 3] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.17354608, 0.17614941, 0.14746045, 0.        ],\n",
       "        [0.91239369, 0.90294158, 0.93359589, 0.89029574, 0.        ],\n",
       "        [0.06883854, 0.05948123, 0.09196612, 0.10765477, 0.        ],\n",
       "        ...,\n",
       "        [0.09131553, 0.05808163, 0.04763236, 0.06465057, 0.        ],\n",
       "        [0.88809782, 0.8570658 , 0.86445452, 0.85228878, 0.        ],\n",
       "        [0.44763535, 0.50293088, 0.55464757, 0.50181866, 0.        ]]),\n",
       " array([[0.05952867, 0.05414822, 0.06875836, 0.04921332, 0.        ],\n",
       "        [0.3970897 , 0.370909  , 0.35185658, 0.37870907, 0.        ],\n",
       "        [0.3032796 , 0.31456018, 0.34302501, 0.3238593 , 0.        ],\n",
       "        ...,\n",
       "        [0.03583201, 0.03669401, 0.03834657, 0.0315213 , 0.        ],\n",
       "        [0.13214782, 0.11258472, 0.0940085 , 0.09887918, 0.        ],\n",
       "        [0.0251264 , 0.02188812, 0.02210464, 0.02296214, 0.        ]]))"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1470), (12225, 1470))"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1469), (12225, 1469))"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1473), (12225, 1473))"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1475), (12225, 1475))"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1472), (12225, 1472))"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128379\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128254\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128205\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128302\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1371\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4700, number of negative: 7252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128111\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1368\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393240 -> initscore=-0.433715\n",
      "[LightGBM] [Info] Start training from score -0.433715\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "\n",
    "model = LGBMClassifier(**lg_params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 4] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 4] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 4] = test_preds_stage1[:, 4] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.17354608, 0.17614941, 0.14746045, 0.17505557],\n",
       "        [0.91239369, 0.90294158, 0.93359589, 0.89029574, 0.90022984],\n",
       "        [0.06883854, 0.05948123, 0.09196612, 0.10765477, 0.11742994],\n",
       "        ...,\n",
       "        [0.09131553, 0.05808163, 0.04763236, 0.06465057, 0.08587301],\n",
       "        [0.88809782, 0.8570658 , 0.86445452, 0.85228878, 0.7996535 ],\n",
       "        [0.44763535, 0.50293088, 0.55464757, 0.50181866, 0.48827395]]),\n",
       " array([[0.05952867, 0.05414822, 0.06875836, 0.04921332, 0.07374778],\n",
       "        [0.3970897 , 0.370909  , 0.35185658, 0.37870907, 0.40602474],\n",
       "        [0.3032796 , 0.31456018, 0.34302501, 0.3238593 , 0.33665219],\n",
       "        ...,\n",
       "        [0.03583201, 0.03669401, 0.03834657, 0.0315213 , 0.05671894],\n",
       "        [0.13214782, 0.11258472, 0.0940085 , 0.09887918, 0.0998593 ],\n",
       "        [0.0251264 , 0.02188812, 0.02210464, 0.02296214, 0.02486843]]))"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5874, number of negative: 9066\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 14940, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393173 -> initscore=-0.433995\n",
      "[LightGBM] [Info] Start training from score -0.433995\n",
      "Final F1-Score: 0.7181632108213936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "meta_model_2 = LogisticRegression(random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.5).astype(int)))\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 / LGBM -> 0.726196\n",
    "# 0.5 : 0.7201074787281684\n",
    "# 0.4 : 0.7341368026179265\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / 3.3 / LGBM ->\n",
    "# 0.5 : 0.7244472071752065\n",
    "# 0.4 : 0.7385688247880181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = final_preds\n",
    "submit.to_csv(\"multi_layer_ensemble_05_1112_proba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = (final_preds > 0.5).astype(int)\n",
    "submit.to_csv(\"multi_layer_ensemble_05_1112.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4687, number of negative: 7265\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392152 -> initscore=-0.438276\n",
      "[LightGBM] [Info] Start training from score -0.438276\n",
      "Final F1-Score (Validation): 0.6572286572286572\n",
      "Test Predictions: [0.04161772 0.25911637 0.25911401 ... 0.03302486 0.10694121 0.03278986]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분리 (훈련 및 테스트 데이터 생성)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(base_model_preds, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "meta_model_2 = LogisticRegression(random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(X_train, y_train)\n",
    "meta_preds_stage2_train = meta_model_1.predict_proba(X_train)[:, 1]  # 학습 데이터 예측\n",
    "meta_preds_stage2_valid = meta_model_1.predict_proba(X_valid)[:, 1]  # 검증 데이터 예측\n",
    "meta_preds_stage2_test = meta_model_1.predict_proba(test_preds_stage1)[:, 1]  # 테스트 데이터 예측\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2_train.reshape(-1, 1), y_train)\n",
    "final_preds_valid = meta_model_2.predict_proba(meta_preds_stage2_valid.reshape(-1, 1))[:, 1]\n",
    "final_preds_test = meta_model_2.predict_proba(meta_preds_stage2_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 검증 데이터 기반 최종 F1 점수 출력\n",
    "threshold = 0.5  # 결정 임계값\n",
    "final_f1_score = f1_score(y_valid, (final_preds_valid > threshold).astype(int))\n",
    "print(\"Final F1-Score (Validation):\", final_f1_score)\n",
    "\n",
    "# 최종 테스트 예측 결과 (필요시 저장 또는 제출)\n",
    "print(\"Test Predictions:\", final_preds_test)\n",
    "\n",
    "# 0.5 : 0.6549807610089782\n",
    "# 0.4 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5874, number of negative: 9066\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 14940, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393173 -> initscore=-0.433995\n",
      "[LightGBM] [Info] Start training from score -0.433995\n",
      "Final F1-Score: 0.724679029957204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "params_logi = {'C': 1.2056308154836568, 'solver': 'saga', 'max_iter': 400, 'class_weight': 'balanced', \n",
    "               'tol': 3.689794777633075e-05} \n",
    "meta_model_2 = LogisticRegression(random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.5).astype(int)))\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 / LGBM -> 0.732630\n",
    "# 0.5 : 0.7201074787281684\n",
    "# 0.4 : 0.7341368026179265\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / LGBM -> 0.712937\n",
    "# 0.5 : 0.7245732574679943\n",
    "# 0.4 : 0.7451820128479657\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / 3.3 / LGBM\n",
    "# multi_layer_ensemble_06_03_1113 -> 0.728199\n",
    "# 0.5 : 0.7244472071752065\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 lgbm / 3.3 / LGBM\n",
    "# multi_layer_ensemble_06_03_1113 -> \n",
    "# 0.5 : 0.7181632108213936\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 xgb / 3.3 / LGBM\n",
    "# multi_layer_ensemble_06_04_1113\n",
    "# 0.5 : 0.724679029957204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = final_preds\n",
    "submit.to_csv(\"multi_layer_ensemble_06_04_1113_proba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = (final_preds > 0.5).astype(int)\n",
    "submit.to_csv(\"multi_layer_ensemble_06_04_1113.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4687, number of negative: 7265\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392152 -> initscore=-0.438276\n",
      "[LightGBM] [Info] Start training from score -0.438276\n",
      "Final F1-Score (Validation): 0.6531492666091459\n",
      "Test Predictions: [0.05442593 0.2723833  0.27238111 ... 0.04433934 0.12514955 0.04405935]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분리 (훈련 및 테스트 데이터 생성)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(base_model_preds, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "# params_logi = {'C': 1.2056308154836568, 'solver': 'saga', 'max_iter': 400, 'class_weight': 'balanced', \n",
    "#                'tol': 3.689794777633075e-05} \n",
    "params_logi = {'solver': 'saga', 'penalty': 'l1', 'C': 0.016653660299528087}\n",
    "meta_model_2 = LogisticRegression(**params_logi, random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(X_train, y_train)\n",
    "meta_preds_stage2_train = meta_model_1.predict_proba(X_train)[:, 1]  # 학습 데이터 예측\n",
    "meta_preds_stage2_valid = meta_model_1.predict_proba(X_valid)[:, 1]  # 검증 데이터 예측\n",
    "meta_preds_stage2_test = meta_model_1.predict_proba(test_preds_stage1)[:, 1]  # 테스트 데이터 예측\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2_train.reshape(-1, 1), y_train)\n",
    "final_preds_valid = meta_model_2.predict_proba(meta_preds_stage2_valid.reshape(-1, 1))[:, 1]\n",
    "final_preds_test = meta_model_2.predict_proba(meta_preds_stage2_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 검증 데이터 기반 최종 F1 점수 출력\n",
    "threshold = 0.5  # 결정 임계값\n",
    "final_f1_score = f1_score(y_valid, (final_preds_valid > threshold).astype(int))\n",
    "print(\"Final F1-Score (Validation):\", final_f1_score)\n",
    "\n",
    "# 최종 테스트 예측 결과 (필요시 저장 또는 제출)\n",
    "print(\"Test Predictions:\", final_preds_test)\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 / LGBM -> \n",
    "# 0.5 : 0.6666666666666666\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / LGBM \n",
    "# multi_layer_ensemble_06_02_1112 -> 0.712956\n",
    "# 0.5 : 0.6706586826347305\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / 3.3 / LGBM -> \n",
    "# 0.5 : 0.676056338028169 / 0.6531492666091459\n",
    "# 0.4 : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = final_preds_test\n",
    "submit.to_csv(\"multi_layer_ensemble_06_02_1112_proba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = (final_preds_test > 0.5).astype(int)\n",
    "submit.to_csv(\"multi_layer_ensemble_06_02_1112.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb/lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1단계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1471), (12225, 1471))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 4), (12225, 4))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds = np.zeros((train_ft.shape[0], 4))\n",
    "test_preds_stage1 = np.zeros((test_ft.shape[0], 4))\n",
    "\n",
    "base_model_preds.shape, test_preds_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1504), (12225, 1504))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.0_1106.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.0_1106.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1503), (12225, 1503))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1507), (12225, 1507))"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1509), (12225, 1509))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1506), (12225, 1506))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# params = {'n_estimators': 650, 'learning_rate': 0.036607674485964255, 'max_depth': 5, 'min_child_weight': 5, \n",
    "#             'subsample': 0.5912180289877119, 'colsample_bytree': 0.5001242454444643, 'gamma': 3.7469954911481986 }\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 0] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 0] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 0] = test_preds_stage1[:, 0] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128081\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1411\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 127901\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1413\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127847\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1411\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127964\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1410\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4700, number of negative: 7252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127778\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1409\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393240 -> initscore=-0.433715\n",
      "[LightGBM] [Info] Start training from score -0.433715\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "\n",
    "model = LGBMClassifier(**lg_params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 1] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 1] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 1] = test_preds_stage1[:, 1] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.14416043, 0.        , 0.        ],\n",
       "        [0.91239369, 0.91216914, 0.        , 0.        ],\n",
       "        [0.06883854, 0.13449861, 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.09131553, 0.05647655, 0.        , 0.        ],\n",
       "        [0.88809782, 0.82385351, 0.        , 0.        ],\n",
       "        [0.44763535, 0.40929756, 0.        , 0.        ]]),\n",
       " array([[0.05952867, 0.08348683, 0.        , 0.        ],\n",
       "        [0.3970897 , 0.42039202, 0.        , 0.        ],\n",
       "        [0.3032796 , 0.33265887, 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03583201, 0.04931319, 0.        , 0.        ],\n",
       "        [0.13214782, 0.12248471, 0.        , 0.        ],\n",
       "        [0.0251264 , 0.02929046, 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v3.3_군집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1471), (12225, 1471))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_군집_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1470), (12225, 1470))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1474), (12225, 1474))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1476), (12225, 1476))"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1473), (12225, 1473))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 1] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 1] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 1] = test_preds_stage1[:, 1] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 128382\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1373\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128257\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1373\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128208\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1373\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128305\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4700, number of negative: 7252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128114\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1369\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393240 -> initscore=-0.433715\n",
      "[LightGBM] [Info] Start training from score -0.433715\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "\n",
    "model = LGBMClassifier(**lg_params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 1] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 1] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 1] = test_preds_stage1[:, 1] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.134194  , 0.17354608, 0.        ],\n",
       "        [0.88763589, 0.90294158, 0.        ],\n",
       "        [0.07531035, 0.05948123, 0.        ],\n",
       "        ...,\n",
       "        [0.1243593 , 0.05808163, 0.        ],\n",
       "        [0.80216897, 0.8570658 , 0.        ],\n",
       "        [0.4868139 , 0.50293088, 0.        ]]),\n",
       " array([[0.0644734 , 0.05414822, 0.        ],\n",
       "        [0.42672246, 0.370909  , 0.        ],\n",
       "        [0.29340607, 0.31456018, 0.        ],\n",
       "        ...,\n",
       "        [0.03889522, 0.03669401, 0.        ],\n",
       "        [0.13629637, 0.11258472, 0.        ],\n",
       "        [0.02865571, 0.02188812, 0.        ]]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1470), (12225, 1470))"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1469), (12225, 1469))"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1473), (12225, 1473))"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1475), (12225, 1475))"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1472), (12225, 1472))"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 2] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 2] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 2] = test_preds_stage1[:, 2] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128379\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128254\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128205\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128302\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1371\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4700, number of negative: 7252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128111\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1368\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393240 -> initscore=-0.433715\n",
      "[LightGBM] [Info] Start training from score -0.433715\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "\n",
    "model = LGBMClassifier(**lg_params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 3] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 3] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 3] = test_preds_stage1[:, 3] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.15832062, 0.14416043, 0.14746045, 0.17505557],\n",
       "        [0.91239369, 0.91216914, 0.89029574, 0.90022984],\n",
       "        [0.06883854, 0.13449861, 0.10765477, 0.11742994],\n",
       "        ...,\n",
       "        [0.09131553, 0.05647655, 0.06465057, 0.08587301],\n",
       "        [0.88809782, 0.82385351, 0.85228878, 0.7996535 ],\n",
       "        [0.44763535, 0.40929756, 0.50181866, 0.48827395]]),\n",
       " array([[0.05952867, 0.08348683, 0.04921332, 0.07374778],\n",
       "        [0.3970897 , 0.42039202, 0.37870907, 0.40602474],\n",
       "        [0.3032796 , 0.33265887, 0.3238593 , 0.33665219],\n",
       "        ...,\n",
       "        [0.03583201, 0.04931319, 0.0315213 , 0.05671894],\n",
       "        [0.13214782, 0.12248471, 0.09887918, 0.0998593 ],\n",
       "        [0.0251264 , 0.02929046, 0.02296214, 0.02486843]]))"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5874, number of negative: 9066\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 14940, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393173 -> initscore=-0.433995\n",
      "[LightGBM] [Info] Start training from score -0.433995\n",
      "Final F1-Score: 0.7113687026304057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "params_logi = {'C': 1.2056308154836568, 'solver': 'saga', 'max_iter': 400, 'class_weight': 'balanced', \n",
    "               'tol': 3.689794777633075e-05} \n",
    "meta_model_2 = LogisticRegression(random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.5).astype(int)))\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 / LGBM -> 0.732630\n",
    "# 0.5 : 0.7201074787281684\n",
    "# 0.4 : 0.7341368026179265\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / LGBM -> 0.712937\n",
    "# 0.5 : 0.7245732574679943\n",
    "# 0.4 : 0.7451820128479657\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / 3.3 / LGBM\n",
    "# multi_layer_ensemble_06_03_1113 -> 0.728199\n",
    "# 0.5 : 0.7244472071752065\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 * xgb / lgbm -> 0.725212\n",
    "# 0.5 : 0.7318550182563006 \n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 * xgb -> \n",
    "# 0.5 : 0.7012074247612182\n",
    "# 0.7010548900411229\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 * lgbm -> \n",
    "# 0.5 : 0.6962662194368435\n",
    "\n",
    "# 3.0 / 3.3 * xgb / lgbm \n",
    "# 0.5 : 0.7113687026304057\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 lgbm / 3.3 / LGBM\n",
    "# \n",
    "# 0.5 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = final_preds\n",
    "submit.to_csv(\"multi_layer_ensemble_07_1113_proba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = (final_preds > 0.5).astype(int)\n",
    "submit.to_csv(\"multi_layer_ensemble_07_1113.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4687, number of negative: 7265\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392152 -> initscore=-0.438276\n",
      "[LightGBM] [Info] Start training from score -0.438276\n",
      "Final F1-Score (Validation): 0.6640893470790378\n",
      "Test Predictions: [0.04172779 0.24263626 0.14030987 ... 0.04140543 0.09439931 0.0357575 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분리 (훈련 및 테스트 데이터 생성)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(base_model_preds, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "# params_logi = {'C': 1.2056308154836568, 'solver': 'saga', 'max_iter': 400, 'class_weight': 'balanced', \n",
    "#                'tol': 3.689794777633075e-05} \n",
    "params_logi = {'solver': 'saga', 'penalty': 'l1', 'C': 0.016653660299528087}\n",
    "meta_model_2 = LogisticRegression(**params_logi, random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(X_train, y_train)\n",
    "meta_preds_stage2_train = meta_model_1.predict_proba(X_train)[:, 1]  # 학습 데이터 예측\n",
    "meta_preds_stage2_valid = meta_model_1.predict_proba(X_valid)[:, 1]  # 검증 데이터 예측\n",
    "meta_preds_stage2_test = meta_model_1.predict_proba(test_preds_stage1)[:, 1]  # 테스트 데이터 예측\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2_train.reshape(-1, 1), y_train)\n",
    "final_preds_valid = meta_model_2.predict_proba(meta_preds_stage2_valid.reshape(-1, 1))[:, 1]\n",
    "final_preds_test = meta_model_2.predict_proba(meta_preds_stage2_test.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 검증 데이터 기반 최종 F1 점수 출력\n",
    "threshold = 0.5  # 결정 임계값\n",
    "final_f1_score = f1_score(y_valid, (final_preds_valid > threshold).astype(int))\n",
    "print(\"Final F1-Score (Validation):\", final_f1_score)\n",
    "\n",
    "# 최종 테스트 예측 결과 (필요시 저장 또는 제출)\n",
    "print(\"Test Predictions:\", final_preds_test)\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 / LGBM -> \n",
    "# 0.5 : 0.6666666666666666\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / LGBM \n",
    "# multi_layer_ensemble_06_02_1112 -> 0.712956\n",
    "# 0.5 : 0.6706586826347305\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / 3.3 / LGBM -> \n",
    "# 0.5 : 0.676056338028169 / 0.6531492666091459\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 * xgb / lgbm\n",
    "# 0.5 : 0.6640893470790378\n",
    "# 0.4 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v3.3 _ xgb / lgbm / logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1470), (12225, 1470))"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.3_피처삭제X_1111.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.3_피처삭제X_1111.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1469), (12225, 1469))"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1473), (12225, 1473))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1475), (12225, 1475))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1472), (12225, 1472))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 3), (12225, 3))"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds = np.zeros((train_ft.shape[0], 3))\n",
    "test_preds_stage1 = np.zeros((test_ft.shape[0], 3))\n",
    "\n",
    "base_model_preds.shape, test_preds_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# params = {'n_estimators': 650, 'learning_rate': 0.036607674485964255, 'max_depth': 5, 'min_child_weight': 5, \n",
    "#             'subsample': 0.5912180289877119, 'colsample_bytree': 0.5001242454444643, 'gamma': 3.7469954911481986 }\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 0] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 0] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 0] = test_preds_stage1[:, 0] / n_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128379\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128254\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128205\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1372\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4699, number of negative: 7253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128302\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1371\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393156 -> initscore=-0.434065\n",
      "[LightGBM] [Info] Start training from score -0.434065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4700, number of negative: 7252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128111\n",
      "[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 1368\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393240 -> initscore=-0.433715\n",
      "[LightGBM] [Info] Start training from score -0.433715\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 교차 검증 및 예측 저장\n",
    "n_folds = 5\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "\n",
    "model = LGBMClassifier(**lg_params)\n",
    "\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 1] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 1] += model.predict_proba(test_ft)[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 1] = test_preds_stage1[:, 1] / n_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- voting_v3.3_selection(logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "logi = LogisticRegression(random_state=42)\n",
    "fs = SelectFromModel(logi)          # 특성 선택에 사용하기 위한 모델 객체를 전달해줘야함.\n",
    "fs.fit_transform(train_ft, target)  # 특성 선택이 완료된 입력 데이터가 ndarray 로 반환\n",
    "\n",
    "best_cols_logi = fs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "params_xgb = {'n_estimators': 1000,'learning_rate': 0.027075406407767497,'max_depth': 5,'min_child_weight': 7,\n",
    "              'subsample': 0.6789816859997232,'colsample_bytree': 0.6682531834544282,'gamma': 1.5046881781916308}\n",
    "params_lgbm = {'n_estimators': 813, 'learning_rate': 0.014757440400599073, 'num_leaves': 35, 'max_depth': 12, \n",
    "               'min_child_samples': 41, 'subsample': 0.85, 'colsample_bytree': 0.95}\n",
    "params_logi = {'C': 1.2056308154836568, 'solver': 'saga', 'max_iter': 400, 'class_weight': 'balanced', \n",
    "               'tol': 3.689794777633075e-05}            # optuna trial 30 : 0.727821596703826.\n",
    "\n",
    "estimators = [\n",
    "    (\"lgbm\", LGBMClassifier(random_state=42, **params_lgbm)),\n",
    "    (\"xgb\", XGBClassifier(random_state=42, **params_xgb) ),\n",
    "    (\"logi\", LogisticRegression(random_state=42, **params_logi) ),  ]\n",
    "\n",
    "parmas = {\n",
    "    \"estimators\": estimators,\n",
    "    \"voting\" : \"soft\",\n",
    "    \"n_jobs\" : -1   }\n",
    "\n",
    "model = VotingClassifier(**parmas)\n",
    "\n",
    "for tri, vai in cv.split(train_ft[best_cols_logi], target):\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft[best_cols_logi].iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft[best_cols_logi].iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    base_model_preds[vai, 2] = model.predict_proba(x_valid)[:, 1]  # Class 1 확률\n",
    "    test_preds_stage1[:, 2] += model.predict_proba(test_ft[best_cols_logi])[:, 1]  \n",
    "\n",
    "test_preds_stage1[:, 2] = test_preds_stage1[:, 2] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.14746045, 0.17505557, 0.20027597],\n",
       "        [0.89029574, 0.90022984, 0.84026336],\n",
       "        [0.10765477, 0.11742994, 0.07716205],\n",
       "        ...,\n",
       "        [0.06465057, 0.08587301, 0.08808484],\n",
       "        [0.85228878, 0.7996535 , 0.86691073],\n",
       "        [0.50181866, 0.48827395, 0.69625479]]),\n",
       " array([[0.04921332, 0.07374778, 0.09127102],\n",
       "        [0.37870907, 0.40602474, 0.36580201],\n",
       "        [0.3238593 , 0.33665219, 0.42609802],\n",
       "        ...,\n",
       "        [0.0315213 , 0.05671894, 0.03878545],\n",
       "        [0.09887918, 0.0998593 , 0.42081843],\n",
       "        [0.02296214, 0.02486843, 0.01180182]]))"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_preds, test_preds_stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5874, number of negative: 9066\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 14940, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393173 -> initscore=-0.433995\n",
      "[LightGBM] [Info] Start training from score -0.433995\n",
      "Final F1-Score: 0.7062905952486876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2단계: 중간 모델 정의\n",
    "lg_params = {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, \n",
    "             'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, \n",
    "             'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n",
    "meta_model_1 = LGBMClassifier(**lg_params)\n",
    "\n",
    "# 3단계: 최종 모델 정의\n",
    "params_logi = {'C': 1.2056308154836568, 'solver': 'saga', 'max_iter': 400, 'class_weight': 'balanced', \n",
    "               'tol': 3.689794777633075e-05} \n",
    "meta_model_2 = LogisticRegression(random_state=42)\n",
    "\n",
    "# 2단계: Meta model 1 학습 및 예측\n",
    "meta_model_1.fit(base_model_preds, target)\n",
    "meta_preds_stage2 = meta_model_1.predict_proba(base_model_preds)[:, 1]\n",
    "test_preds_stage2 = meta_model_1.predict_proba(test_preds_stage1)[:, 1]\n",
    "\n",
    "# 3단계: Meta model 2 학습 및 예측\n",
    "meta_model_2.fit(meta_preds_stage2.reshape(-1, 1), target)\n",
    "final_preds = meta_model_2.predict_proba(test_preds_stage2.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 최종 예측 결과 출력\n",
    "print(\"Final F1-Score:\", f1_score(target, (meta_preds_stage2 > 0.5).astype(int)))\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 / LGBM -> 0.732630\n",
    "# 0.5 : 0.7201074787281684\n",
    "# 0.4 : 0.7341368026179265\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / LGBM -> 0.712937\n",
    "# 0.5 : 0.7245732574679943\n",
    "# 0.4 : 0.7451820128479657\n",
    "\n",
    "# 3.0 / 3.3_군집 / 비선형 / 3.3 / LGBM\n",
    "# multi_layer_ensemble_06_03_1113 -> 0.728199\n",
    "# 0.5 : 0.7244472071752065\n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 * xgb / lgbm -> 0.725212\n",
    "# 0.5 : 0.7318550182563006 \n",
    "# 0.4 : \n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 * xgb -> \n",
    "# 0.5 : 0.7012074247612182\n",
    "# 0.7010548900411229\n",
    "\n",
    "# 3.0 / 3.3_군집 / 3.3 * lgbm -> \n",
    "# 0.5 : 0.6962662194368435\n",
    "\n",
    "# 3.3 - xgb / lgbm / logistic \n",
    "# 0.5 : 0.7058718384127268\n",
    "\n",
    "# 3.0 xgb / 3.3 lgbm /  3.3 logistic \n",
    "# 0.5 : 0.7062905952486876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-13 14:28:42,372] A new study created in memory with name: no-name-c6707da3-e741-46a0-a8a1-bca3e6e84119\n",
      "[I 2024-11-13 14:30:22,573] Trial 0 finished with value: 0.6935414559744512 and parameters: {'n_estimators': 450, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'gamma': 0.2904180608409973}. Best is trial 0 with value: 0.6935414559744512.\n",
      "[I 2024-11-13 14:32:52,690] Trial 1 finished with value: 0.7158537636907446 and parameters: {'n_estimators': 900, 'learning_rate': 0.07725378389307355, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9849549260809971, 'colsample_bytree': 0.9162213204002109, 'gamma': 1.0616955533913808}. Best is trial 1 with value: 0.7158537636907446.\n",
      "[I 2024-11-13 14:33:45,795] Trial 2 finished with value: 0.7107947274742503 and parameters: {'n_estimators': 250, 'learning_rate': 0.018659959624904916, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021, 'gamma': 3.0592644736118975}. Best is trial 1 with value: 0.7158537636907446.\n",
      "[I 2024-11-13 14:34:29,779] Trial 3 finished with value: 0.7109687806999304 and parameters: {'n_estimators': 200, 'learning_rate': 0.027010527749605478, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8925879806965068, 'colsample_bytree': 0.5998368910791798, 'gamma': 2.571172192068058}. Best is trial 1 with value: 0.7158537636907446.\n",
      "[I 2024-11-13 14:37:19,399] Trial 4 finished with value: 0.7178017991294776 and parameters: {'n_estimators': 650, 'learning_rate': 0.011711509955524094, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5325257964926398, 'colsample_bytree': 0.9744427686266666, 'gamma': 4.828160165372797}. Best is trial 4 with value: 0.7178017991294776.\n",
      "[I 2024-11-13 14:39:00,266] Trial 5 finished with value: 0.7184720399243869 and parameters: {'n_estimators': 850, 'learning_rate': 0.028180680291847244, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7200762468698007, 'colsample_bytree': 0.5610191174223894, 'gamma': 2.475884550556351}. Best is trial 5 with value: 0.7184720399243869.\n",
      "[I 2024-11-13 14:39:20,243] Trial 6 finished with value: 0.7093155845820971 and parameters: {'n_estimators': 100, 'learning_rate': 0.22038218939289875, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6558555380447055, 'colsample_bytree': 0.7600340105889054, 'gamma': 2.7335513967163982}. Best is trial 5 with value: 0.7184720399243869.\n",
      "[I 2024-11-13 14:39:56,656] Trial 7 finished with value: 0.7055977932871766 and parameters: {'n_estimators': 250, 'learning_rate': 0.27051668818999286, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.9474136752138245, 'colsample_bytree': 0.7989499894055425, 'gamma': 4.609371175115584}. Best is trial 5 with value: 0.7184720399243869.\n",
      "[I 2024-11-13 14:40:32,344] Trial 8 finished with value: 0.6819899892107155 and parameters: {'n_estimators': 150, 'learning_rate': 0.01947558230629543, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.6943386448447411, 'colsample_bytree': 0.6356745158869479, 'gamma': 4.143687545759647}. Best is trial 5 with value: 0.7184720399243869.\n",
      "[I 2024-11-13 14:42:11,419] Trial 9 finished with value: 0.7167043830848456 and parameters: {'n_estimators': 400, 'learning_rate': 0.026000059117302653, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.5372753218398854, 'gamma': 4.9344346830025865}. Best is trial 5 with value: 0.7184720399243869.\n",
      "[I 2024-11-13 14:44:04,288] Trial 10 finished with value: 0.7185201647069009 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06690992453172917, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8200442512337782, 'colsample_bytree': 0.7032144299581322, 'gamma': 1.6552304085829206}. Best is trial 10 with value: 0.7185201647069009.\n",
      "[I 2024-11-13 14:45:52,708] Trial 11 finished with value: 0.7180104803080944 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06438873843712743, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8087272364965106, 'colsample_bytree': 0.7146743022617835, 'gamma': 1.461192327509932}. Best is trial 10 with value: 0.7185201647069009.\n",
      "[I 2024-11-13 14:47:23,682] Trial 12 finished with value: 0.7144991233070497 and parameters: {'n_estimators': 750, 'learning_rate': 0.10936598253341487, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7944464039018335, 'colsample_bytree': 0.5093981067629809, 'gamma': 1.667817505714271}. Best is trial 10 with value: 0.7185201647069009.\n",
      "[I 2024-11-13 14:49:00,122] Trial 13 finished with value: 0.7202942793515494 and parameters: {'n_estimators': 850, 'learning_rate': 0.04264682529953517, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.844509605917982, 'colsample_bytree': 0.6802071658056971, 'gamma': 3.5598890110670585}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 14:51:00,671] Trial 14 finished with value: 0.7176237285828103 and parameters: {'n_estimators': 1000, 'learning_rate': 0.043339221176978464, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.8400653827216455, 'colsample_bytree': 0.8317032143059913, 'gamma': 3.6433393182258595}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 14:52:28,924] Trial 15 finished with value: 0.7141597133761486 and parameters: {'n_estimators': 750, 'learning_rate': 0.12108403845393122, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.8606417081904845, 'colsample_bytree': 0.6905460748121112, 'gamma': 3.6697671882446383}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 14:54:49,239] Trial 16 finished with value: 0.7185216434724847 and parameters: {'n_estimators': 850, 'learning_rate': 0.04422447176687951, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.7897830247330324, 'colsample_bytree': 0.6859109339010632, 'gamma': 1.9732572724513355}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 14:56:34,925] Trial 17 finished with value: 0.7183186378227886 and parameters: {'n_estimators': 600, 'learning_rate': 0.039179842855348396, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.7690610183483706, 'colsample_bytree': 0.8529694011819127, 'gamma': 2.097455195336404}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 14:58:47,544] Trial 18 finished with value: 0.7178835501003168 and parameters: {'n_estimators': 800, 'learning_rate': 0.043978458139766696, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.6548503898583582, 'colsample_bytree': 0.7620262813542532, 'gamma': 3.3326781965385948}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:00:10,010] Trial 19 finished with value: 0.7170227208395039 and parameters: {'n_estimators': 650, 'learning_rate': 0.1322160441989045, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.9401768333816255, 'colsample_bytree': 0.6476297666059704, 'gamma': 0.41052452231967074}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:03:42,145] Trial 20 finished with value: 0.7180471115290532 and parameters: {'n_estimators': 900, 'learning_rate': 0.01419859035797564, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7752847229001598, 'colsample_bytree': 0.8763900252272743, 'gamma': 4.141404784749691}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:05:57,964] Trial 21 finished with value: 0.7135878979328141 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0799534710110559, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8407434980706122, 'colsample_bytree': 0.7026508257084394, 'gamma': 2.0048311882612473}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:07:46,684] Trial 22 finished with value: 0.7179174160271121 and parameters: {'n_estimators': 900, 'learning_rate': 0.05302628583589074, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8170545660467665, 'colsample_bytree': 0.6885456199689591, 'gamma': 0.8986658459582124}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:09:41,055] Trial 23 finished with value: 0.7188667998735161 and parameters: {'n_estimators': 750, 'learning_rate': 0.036643900590241744, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.8891900464733944, 'colsample_bytree': 0.745915547981481, 'gamma': 2.052346457419316}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:11:39,732] Trial 24 finished with value: 0.7189086549433229 and parameters: {'n_estimators': 700, 'learning_rate': 0.03275137141965276, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.9017641743122948, 'colsample_bytree': 0.7490382858962706, 'gamma': 2.2513254344291873}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:13:13,276] Trial 25 finished with value: 0.7175518181301637 and parameters: {'n_estimators': 500, 'learning_rate': 0.030147309977275976, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8832024801895101, 'colsample_bytree': 0.7483131420346552, 'gamma': 3.030628268473415}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:15:32,025] Trial 26 finished with value: 0.7187594543932361 and parameters: {'n_estimators': 700, 'learning_rate': 0.020493178526931555, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.9313235884212914, 'colsample_bytree': 0.7909471629201987, 'gamma': 2.42314224441964}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:17:21,661] Trial 27 finished with value: 0.7188659823404058 and parameters: {'n_estimators': 600, 'learning_rate': 0.03404827527868251, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.9911654435962245, 'colsample_bytree': 0.742453546439451, 'gamma': 1.167084731505132}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:18:59,020] Trial 28 finished with value: 0.7193510929561974 and parameters: {'n_estimators': 750, 'learning_rate': 0.05735318532813081, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.917472119257295, 'colsample_bytree': 0.802775284926078, 'gamma': 3.595462229285331}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:19:57,880] Trial 29 finished with value: 0.7132250242374333 and parameters: {'n_estimators': 400, 'learning_rate': 0.09309560592921069, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.9623944402061918, 'colsample_bytree': 0.9039414015324082, 'gamma': 3.986671874504562}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:20:57,216] Trial 30 finished with value: 0.7133571643165588 and parameters: {'n_estimators': 550, 'learning_rate': 0.18120071652782976, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.9263348861276459, 'colsample_bytree': 0.8194391005755587, 'gamma': 3.404856234810216}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:22:33,581] Trial 31 finished with value: 0.719310238407265 and parameters: {'n_estimators': 750, 'learning_rate': 0.05623266233799725, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.8708029504408795, 'colsample_bytree': 0.7852998532515021, 'gamma': 3.0007930472949615}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:24:20,235] Trial 32 finished with value: 0.7191199728397119 and parameters: {'n_estimators': 800, 'learning_rate': 0.057093967693318766, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.8645667109291274, 'colsample_bytree': 0.7909107772297429, 'gamma': 3.10487331576668}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:26:13,906] Trial 33 finished with value: 0.7178002437360066 and parameters: {'n_estimators': 850, 'learning_rate': 0.0586338780384973, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8582452035656539, 'colsample_bytree': 0.8630747059595919, 'gamma': 2.929395983610768}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:28:06,132] Trial 34 finished with value: 0.7196867534848419 and parameters: {'n_estimators': 800, 'learning_rate': 0.052777543055173154, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7398380424443641, 'colsample_bytree': 0.7940660558551162, 'gamma': 3.3929259447325513}. Best is trial 13 with value: 0.7202942793515494.\n",
      "[I 2024-11-13 15:30:02,634] Trial 35 finished with value: 0.7126234644063271 and parameters: {'n_estimators': 950, 'learning_rate': 0.09061770295035232, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.5906423685427367, 'colsample_bytree': 0.9166128135560745, 'gamma': 3.879989227720062}. Best is trial 13 with value: 0.7202942793515494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.7202942793515494\n",
      "  Params: {'n_estimators': 850, 'learning_rate': 0.04264682529953517, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.844509605917982, 'colsample_bytree': 0.6802071658056971, 'gamma': 3.5598890110670585}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 목적함수를 클래스로 만들기\n",
    "class Objective:\n",
    "    # 변수 설정\n",
    "    def __init__(self, x, y, seed):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.seed = seed\n",
    "        self.cv = StratifiedKFold(5, shuffle= True, random_state= self.seed)\n",
    "\n",
    "    def __call__(self, trial):  # 콜백함수 역할\n",
    "        hp = {  \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=50),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "                \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                \"gamma\": trial.suggest_float(\"gamma\", 0, 5)  }\n",
    "        model = XGBClassifier(**hp, random_state= self.seed)    \n",
    "        score = cross_val_score(model, self.x, self.y, cv= self.cv, scoring= \"f1_macro\", n_jobs= -1).mean()\n",
    "        return score\n",
    "\n",
    "# Sampler 객체 생성(대체모델 역할)\n",
    "sampler = optuna.samplers.TPESampler(seed= SEED)\n",
    "\n",
    "# study 객체 생성\n",
    "study = optuna.create_study(direction= \"maximize\", sampler= sampler)\n",
    "\n",
    "# optimize 매서드 실행\n",
    "objective_func = Objective(train_ft, target, SEED)\n",
    "study.optimize(objective_func, n_trials= 200, timeout=3600)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {study.best_value}\")\n",
    "print(f\"  Params: {study.best_params}\")\n",
    "\n",
    "# v3.0 : 0.7246472559306677 \n",
    "# {'n_estimators': 650, 'learning_rate': 0.036607674485964255, 'max_depth': 5, 'min_child_weight': 5, \n",
    "#  'subsample': 0.5912180289877119, 'colsample_bytree': 0.5001242454444643, 'gamma': 3.7469954911481986}\n",
    "\n",
    "# v3.3 : 0.7202942793515494\n",
    "# {'n_estimators': 850, 'learning_rate': 0.04264682529953517, 'max_depth': 3, 'min_child_weight': 10, \n",
    "#  'subsample': 0.844509605917982, 'colsample_bytree': 0.6802071658056971, 'gamma': 3.5598890110670585}\n",
    "\n",
    "# v3.3_군집 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-12 12:52:11,848] A new study created in memory with name: no-name-246ae117-5998-4fd5-8422-7e83ee5bbc6f\n",
      "[I 2024-11-12 12:53:55,714] Trial 0 finished with value: 0.7140659642306636 and parameters: {'learning_rate': 0.03574712922600244, 'max_depth': 15, 'num_leaves': 96, 'min_child_samples': 64, 'min_child_weight': 0.0029380279387035343, 'subsample': 0.5779972601681014, 'colsample_bytree': 0.5290418060840998, 'reg_alpha': 2.9154431891537547, 'reg_lambda': 0.2537815508265665, 'n_estimators': 737}. Best is trial 0 with value: 0.7140659642306636.\n",
      "[I 2024-11-12 12:55:40,143] Trial 1 finished with value: 0.716401809655533 and parameters: {'learning_rate': 0.010725209743171996, 'max_depth': 15, 'num_leaves': 108, 'min_child_samples': 29, 'min_child_weight': 0.0035113563139704067, 'subsample': 0.5917022549267169, 'colsample_bytree': 0.6521211214797689, 'reg_alpha': 0.12561043700013558, 'reg_lambda': 0.05342937261279776, 'n_estimators': 362}. Best is trial 1 with value: 0.716401809655533.\n",
      "[I 2024-11-12 12:55:53,056] Trial 2 finished with value: 0.7138650726450638 and parameters: {'learning_rate': 0.08012737503998542, 'max_depth': 4, 'num_leaves': 42, 'min_child_samples': 43, 'min_child_weight': 0.023345864076016236, 'subsample': 0.8925879806965068, 'colsample_bytree': 0.5998368910791798, 'reg_alpha': 0.11400863701127326, 'reg_lambda': 0.23423849847112907, 'n_estimators': 141}. Best is trial 1 with value: 0.716401809655533.\n",
      "[I 2024-11-12 12:56:18,567] Trial 3 finished with value: 0.7174493377505777 and parameters: {'learning_rate': 0.07896186801026692, 'max_depth': 5, 'num_leaves': 14, 'min_child_samples': 96, 'min_child_weight': 0.7886714129990487, 'subsample': 0.9041986740582306, 'colsample_bytree': 0.6523068845866853, 'reg_alpha': 0.002458603276328005, 'reg_lambda': 0.5456725485601477, 'n_estimators': 496}. Best is trial 3 with value: 0.7174493377505777.\n",
      "[I 2024-11-12 12:56:37,483] Trial 4 finished with value: 0.7026118172997077 and parameters: {'learning_rate': 0.015144860262751412, 'max_depth': 9, 'num_leaves': 11, 'min_child_samples': 92, 'min_child_weight': 0.005975027999960293, 'subsample': 0.831261142176991, 'colsample_bytree': 0.6558555380447055, 'reg_alpha': 0.12030178871154672, 'reg_lambda': 0.1537592023548176, 'n_estimators': 266}. Best is trial 3 with value: 0.7174493377505777.\n",
      "[I 2024-11-12 12:57:29,694] Trial 5 finished with value: 0.705109198154334 and parameters: {'learning_rate': 0.27051668818999286, 'max_depth': 13, 'num_leaves': 121, 'min_child_samples': 91, 'min_child_weight': 0.062187047277690755, 'subsample': 0.9609371175115584, 'colsample_bytree': 0.5442462510259598, 'reg_alpha': 0.006080390190296602, 'reg_lambda': 0.0015167330688076208, 'n_estimators': 393}. Best is trial 3 with value: 0.7174493377505777.\n",
      "[I 2024-11-12 12:58:54,852] Trial 6 finished with value: 0.720557445836983 and parameters: {'learning_rate': 0.03750796359625606, 'max_depth': 6, 'num_leaves': 108, 'min_child_samples': 42, 'min_child_weight': 0.006963114377829284, 'subsample': 0.7713480415791243, 'colsample_bytree': 0.5704621124873813, 'reg_alpha': 1.6172900811143154, 'reg_lambda': 0.0019870215385428634, 'n_estimators': 989}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 12:59:07,478] Trial 7 finished with value: 0.7169727888673949 and parameters: {'learning_rate': 0.13826083091896751, 'max_depth': 5, 'num_leaves': 7, 'min_child_samples': 84, 'min_child_weight': 0.13199942261535016, 'subsample': 0.8645035840204937, 'colsample_bytree': 0.8856351733429728, 'reg_alpha': 0.0019777828512462727, 'reg_lambda': 0.02715581955282941, 'n_estimators': 204}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:00:25,720] Trial 8 finished with value: 0.7110527710336101 and parameters: {'learning_rate': 0.18832519048593593, 'max_depth': 11, 'num_leaves': 47, 'min_child_samples': 15, 'min_child_weight': 0.008569331925053986, 'subsample': 0.6625916610133735, 'colsample_bytree': 0.864803089169032, 'reg_alpha': 0.35500125258511606, 'reg_lambda': 3.53875886477924, 'n_estimators': 525}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:01:14,202] Trial 9 finished with value: 0.7127680017675642 and parameters: {'learning_rate': 0.015019490572374374, 'max_depth': 12, 'num_leaves': 99, 'min_child_samples': 61, 'min_child_weight': 0.2055424552015074, 'subsample': 0.7468977981821954, 'colsample_bytree': 0.7613664146909971, 'reg_alpha': 0.05130551760589835, 'reg_lambda': 0.0012637946338082875, 'n_estimators': 197}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:03:25,341] Trial 10 finished with value: 0.7125567873640571 and parameters: {'learning_rate': 0.03683948850062032, 'max_depth': 8, 'num_leaves': 77, 'min_child_samples': 41, 'min_child_weight': 0.0011651789378228094, 'subsample': 0.7519439225888093, 'colsample_bytree': 0.9798853729727102, 'reg_alpha': 7.795612091139279, 'reg_lambda': 0.006934125446843665, 'n_estimators': 994}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:04:06,695] Trial 11 finished with value: 0.7142291774706383 and parameters: {'learning_rate': 0.06341843661646684, 'max_depth': 6, 'num_leaves': 66, 'min_child_samples': 78, 'min_child_weight': 0.959439130929649, 'subsample': 0.9692893212141328, 'colsample_bytree': 0.7203803375170547, 'reg_alpha': 1.176261793497446, 'reg_lambda': 1.9491991009897263, 'n_estimators': 763}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:04:38,984] Trial 12 finished with value: 0.7157164843655728 and parameters: {'learning_rate': 0.034852765279834955, 'max_depth': 3, 'num_leaves': 36, 'min_child_samples': 49, 'min_child_weight': 0.8796266250087573, 'subsample': 0.7741751130247756, 'colsample_bytree': 0.5025450343248907, 'reg_alpha': 0.020056808754759837, 'reg_lambda': 0.010466369837118256, 'n_estimators': 682}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:05:43,282] Trial 13 finished with value: 0.7131323440407817 and parameters: {'learning_rate': 0.08174043649941351, 'max_depth': 7, 'num_leaves': 78, 'min_child_samples': 70, 'min_child_weight': 0.015953938333467636, 'subsample': 0.6797670164096583, 'colsample_bytree': 0.6176862055368464, 'reg_alpha': 0.0015730247398592669, 'reg_lambda': 1.2735835567487843, 'n_estimators': 997}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:06:21,461] Trial 14 finished with value: 0.717083914727308 and parameters: {'learning_rate': 0.12178366333833116, 'max_depth': 6, 'num_leaves': 124, 'min_child_samples': 28, 'min_child_weight': 0.2893455180578684, 'subsample': 0.9016862464770321, 'colsample_bytree': 0.7194016569148899, 'reg_alpha': 0.707235174430786, 'reg_lambda': 0.6983544442062519, 'n_estimators': 572}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:07:09,387] Trial 15 finished with value: 0.7190403961249607 and parameters: {'learning_rate': 0.0247884405017788, 'max_depth': 4, 'num_leaves': 24, 'min_child_samples': 98, 'min_child_weight': 0.06640136026181519, 'subsample': 0.510456783241702, 'colsample_bytree': 0.5813642948982538, 'reg_alpha': 0.0119610048504927, 'reg_lambda': 0.004802586909778857, 'n_estimators': 874}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:07:56,124] Trial 16 finished with value: 0.7151288302932584 and parameters: {'learning_rate': 0.022328446885462167, 'max_depth': 3, 'num_leaves': 58, 'min_child_samples': 33, 'min_child_weight': 0.057267032178521166, 'subsample': 0.511847705752916, 'colsample_bytree': 0.5621243005829863, 'reg_alpha': 0.01197311651553773, 'reg_lambda': 0.005446102722652428, 'n_estimators': 872}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:09:19,895] Trial 17 finished with value: 0.719121762240181 and parameters: {'learning_rate': 0.023943480208242666, 'max_depth': 10, 'num_leaves': 31, 'min_child_samples': 16, 'min_child_weight': 0.04484441235960991, 'subsample': 0.6783519848540356, 'colsample_bytree': 0.7750687191130179, 'reg_alpha': 0.024912417260024727, 'reg_lambda': 0.0027726410695743456, 'n_estimators': 897}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:11:02,535] Trial 18 finished with value: 0.7141138514152925 and parameters: {'learning_rate': 0.04504015850921396, 'max_depth': 10, 'num_leaves': 84, 'min_child_samples': 13, 'min_child_weight': 0.013784854670306358, 'subsample': 0.6896927174856817, 'colsample_bytree': 0.8037526899029172, 'reg_alpha': 7.964872188651109, 'reg_lambda': 8.546458057168064, 'n_estimators': 882}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:12:27,934] Trial 19 finished with value: 0.7193558853544649 and parameters: {'learning_rate': 0.0201470931560648, 'max_depth': 9, 'num_leaves': 56, 'min_child_samples': 21, 'min_child_weight': 0.0011093373486981738, 'subsample': 0.7908702038802391, 'colsample_bytree': 0.8390341784995801, 'reg_alpha': 0.3115043696982335, 'reg_lambda': 0.024439674374142083, 'n_estimators': 667}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:13:42,748] Trial 20 finished with value: 0.7163124719946086 and parameters: {'learning_rate': 0.017429082404149407, 'max_depth': 8, 'num_leaves': 54, 'min_child_samples': 24, 'min_child_weight': 0.001105029776995942, 'subsample': 0.8027820048121932, 'colsample_bytree': 0.9804385584664499, 'reg_alpha': 0.49112650895540627, 'reg_lambda': 0.020847380507093345, 'n_estimators': 630}. Best is trial 6 with value: 0.720557445836983.\n",
      "[I 2024-11-12 13:15:00,295] Trial 21 finished with value: 0.7211921797396676 and parameters: {'learning_rate': 0.026106881136875384, 'max_depth': 10, 'num_leaves': 27, 'min_child_samples': 18, 'min_child_weight': 0.002208535358831827, 'subsample': 0.7114086790303651, 'colsample_bytree': 0.8172802634855206, 'reg_alpha': 1.832100412062444, 'reg_lambda': 0.002427337253616894, 'n_estimators': 796}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:16:24,092] Trial 22 finished with value: 0.7183756908101484 and parameters: {'learning_rate': 0.010642639145975791, 'max_depth': 9, 'num_leaves': 65, 'min_child_samples': 40, 'min_child_weight': 0.0025571194055799156, 'subsample': 0.7172539956595503, 'colsample_bytree': 0.8428023789280279, 'reg_alpha': 3.043732984093626, 'reg_lambda': 0.014930984415255838, 'n_estimators': 741}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:17:34,881] Trial 23 finished with value: 0.7193589694788886 and parameters: {'learning_rate': 0.028685359411783854, 'max_depth': 13, 'num_leaves': 22, 'min_child_samples': 21, 'min_child_weight': 0.0020131928934133732, 'subsample': 0.6230397737130587, 'colsample_bytree': 0.9360210418850616, 'reg_alpha': 2.0014169659563867, 'reg_lambda': 0.055390361450779656, 'n_estimators': 817}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:18:47,816] Trial 24 finished with value: 0.720447428562894 and parameters: {'learning_rate': 0.02880400661662095, 'max_depth': 14, 'num_leaves': 22, 'min_child_samples': 10, 'min_child_weight': 0.005668177694514698, 'subsample': 0.6166237682982242, 'colsample_bytree': 0.914216952910215, 'reg_alpha': 1.9657039811674786, 'reg_lambda': 0.0618716438620494, 'n_estimators': 818}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:20:15,128] Trial 25 finished with value: 0.7177223871032997 and parameters: {'learning_rate': 0.051207687910338126, 'max_depth': 14, 'num_leaves': 25, 'min_child_samples': 10, 'min_child_weight': 0.005832465164581194, 'subsample': 0.6094721980430026, 'colsample_bytree': 0.9164087998653861, 'reg_alpha': 1.4236395687460999, 'reg_lambda': 0.0021095079057852476, 'n_estimators': 947}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:21:38,323] Trial 26 finished with value: 0.7149457426878125 and parameters: {'learning_rate': 0.030438468691265833, 'max_depth': 12, 'num_leaves': 39, 'min_child_samples': 33, 'min_child_weight': 0.008682525578912399, 'subsample': 0.6411121474287371, 'colsample_bytree': 0.8005137915095021, 'reg_alpha': 4.642752481505763, 'reg_lambda': 0.0028574039767356157, 'n_estimators': 809}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:23:33,167] Trial 27 finished with value: 0.714008003884895 and parameters: {'learning_rate': 0.05078867741858803, 'max_depth': 11, 'num_leaves': 93, 'min_child_samples': 35, 'min_child_weight': 0.004666195242834275, 'subsample': 0.5582005230654945, 'colsample_bytree': 0.7225381297399198, 'reg_alpha': 0.9024120013874692, 'reg_lambda': 0.0011000027119649842, 'n_estimators': 813}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:24:59,494] Trial 28 finished with value: 0.7106881425947587 and parameters: {'learning_rate': 0.043443510245193634, 'max_depth': 7, 'num_leaves': 107, 'min_child_samples': 49, 'min_child_weight': 0.0017953870488502605, 'subsample': 0.7199924528270479, 'colsample_bytree': 0.9117373061813743, 'reg_alpha': 4.075516365632505, 'reg_lambda': 0.04111146204021369, 'n_estimators': 933}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:26:05,380] Trial 29 finished with value: 0.7178932534019464 and parameters: {'learning_rate': 0.06327303484675614, 'max_depth': 15, 'num_leaves': 19, 'min_child_samples': 58, 'min_child_weight': 0.010450129648489393, 'subsample': 0.5470465683863706, 'colsample_bytree': 0.8107371168752, 'reg_alpha': 0.2655957489517582, 'reg_lambda': 0.010537429266433855, 'n_estimators': 745}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:27:02,530] Trial 30 finished with value: 0.7194263173994504 and parameters: {'learning_rate': 0.03765740463998034, 'max_depth': 14, 'num_leaves': 32, 'min_child_samples': 18, 'min_child_weight': 0.003286004758059284, 'subsample': 0.7174695738507157, 'colsample_bytree': 0.6876328856046602, 'reg_alpha': 2.039316771791445, 'reg_lambda': 0.005488879773849254, 'n_estimators': 606}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:28:02,888] Trial 31 finished with value: 0.7182900557828937 and parameters: {'learning_rate': 0.03934911000264479, 'max_depth': 14, 'num_leaves': 30, 'min_child_samples': 19, 'min_child_weight': 0.00317620223319831, 'subsample': 0.7098928422846592, 'colsample_bytree': 0.6919518959680384, 'reg_alpha': 2.557827611516338, 'reg_lambda': 0.0033560949159206887, 'n_estimators': 607}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:29:04,330] Trial 32 finished with value: 0.7196330628163421 and parameters: {'learning_rate': 0.030519018069363177, 'max_depth': 14, 'num_leaves': 47, 'min_child_samples': 10, 'min_child_weight': 0.004114282394890025, 'subsample': 0.7500827848196114, 'colsample_bytree': 0.6811888689153198, 'reg_alpha': 1.9404346071213705, 'reg_lambda': 0.06893053018879364, 'n_estimators': 462}. Best is trial 21 with value: 0.7211921797396676.\n",
      "[I 2024-11-12 13:30:02,873] Trial 33 finished with value: 0.7220333447625727 and parameters: {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, 'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, 'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:30:50,459] Trial 34 finished with value: 0.7181251697059503 and parameters: {'learning_rate': 0.014926084764039215, 'max_depth': 15, 'num_leaves': 42, 'min_child_samples': 28, 'min_child_weight': 0.027649875791864734, 'subsample': 0.8645235778751372, 'colsample_bytree': 0.6072366281802075, 'reg_alpha': 0.6697014969097984, 'reg_lambda': 0.11576370926796581, 'n_estimators': 354}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:32:15,119] Trial 35 finished with value: 0.7169843257431491 and parameters: {'learning_rate': 0.018665862215511482, 'max_depth': 13, 'num_leaves': 117, 'min_child_samples': 25, 'min_child_weight': 0.006863102550173305, 'subsample': 0.8244954452649352, 'colsample_bytree': 0.5294517960194729, 'reg_alpha': 0.15828991110772048, 'reg_lambda': 0.22654307749588581, 'n_estimators': 441}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:32:40,376] Trial 36 finished with value: 0.7038142967751938 and parameters: {'learning_rate': 0.013017098136896362, 'max_depth': 12, 'num_leaves': 15, 'min_child_samples': 10, 'min_child_weight': 0.01495005788180059, 'subsample': 0.8660027635866279, 'colsample_bytree': 0.6283112031160207, 'reg_alpha': 5.389788074811329, 'reg_lambda': 0.36910515525134, 'n_estimators': 301}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:34:31,790] Trial 37 finished with value: 0.7168271233233099 and parameters: {'learning_rate': 0.02504647393082267, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 52, 'min_child_weight': 0.0017801297171532306, 'subsample': 0.9308027101347365, 'colsample_bytree': 0.5007250058963767, 'reg_alpha': 1.073514553300211, 'reg_lambda': 0.16893475467819308, 'n_estimators': 945}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:35:04,812] Trial 38 finished with value: 0.7180778174503749 and parameters: {'learning_rate': 0.02970459689741787, 'max_depth': 11, 'num_leaves': 8, 'min_child_samples': 67, 'min_child_weight': 0.0208366569089518, 'subsample': 0.837053299008908, 'colsample_bytree': 0.9471580810803695, 'reg_alpha': 0.17328621557365836, 'reg_lambda': 0.09126580598211452, 'n_estimators': 685}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:35:17,627] Trial 39 finished with value: 0.7115212549754814 and parameters: {'learning_rate': 0.06127269693910511, 'max_depth': 5, 'num_leaves': 17, 'min_child_samples': 37, 'min_child_weight': 0.005050381732182769, 'subsample': 0.5859357181311227, 'colsample_bytree': 0.8773511401790051, 'reg_alpha': 0.5377021488240094, 'reg_lambda': 0.04372699612213003, 'n_estimators': 108}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:36:19,662] Trial 40 finished with value: 0.7149423789445907 and parameters: {'learning_rate': 0.012340308358563316, 'max_depth': 10, 'num_leaves': 50, 'min_child_samples': 46, 'min_child_weight': 0.0023978235112449664, 'subsample': 0.9327720995860398, 'colsample_bytree': 0.585230907012158, 'reg_alpha': 0.0694227652837562, 'reg_lambda': 0.729106071908003, 'n_estimators': 386}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:37:21,411] Trial 41 finished with value: 0.721680858982224 and parameters: {'learning_rate': 0.030316908093704988, 'max_depth': 14, 'num_leaves': 44, 'min_child_samples': 13, 'min_child_weight': 0.0034183769202183164, 'subsample': 0.7595281920649337, 'colsample_bytree': 0.6412273491296374, 'reg_alpha': 1.6086754266337218, 'reg_lambda': 0.06434412755904884, 'n_estimators': 488}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:38:23,783] Trial 42 finished with value: 0.7208450134968774 and parameters: {'learning_rate': 0.027199276608361148, 'max_depth': 13, 'num_leaves': 37, 'min_child_samples': 15, 'min_child_weight': 0.007270430250904173, 'subsample': 0.7767867792441732, 'colsample_bytree': 0.644066503718653, 'reg_alpha': 1.4368995425197673, 'reg_lambda': 0.3344317674797721, 'n_estimators': 509}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:39:40,109] Trial 43 finished with value: 0.7190365611567797 and parameters: {'learning_rate': 0.020594097838032135, 'max_depth': 13, 'num_leaves': 62, 'min_child_samples': 24, 'min_child_weight': 0.008550742444111751, 'subsample': 0.7763318330074157, 'colsample_bytree': 0.6399506883257315, 'reg_alpha': 1.3485437973545926, 'reg_lambda': 0.3707025947247653, 'n_estimators': 510}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:40:30,011] Trial 44 finished with value: 0.7188702507081628 and parameters: {'learning_rate': 0.03462799713604212, 'max_depth': 12, 'num_leaves': 34, 'min_child_samples': 16, 'min_child_weight': 0.0038239427876806016, 'subsample': 0.820927211682893, 'colsample_bytree': 0.6589096524362293, 'reg_alpha': 3.4377174148936436, 'reg_lambda': 0.0016814871057284923, 'n_estimators': 426}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:41:38,109] Trial 45 finished with value: 0.7168606803520776 and parameters: {'learning_rate': 0.016380699520848432, 'max_depth': 15, 'num_leaves': 42, 'min_child_samples': 14, 'min_child_weight': 0.0014922918757532546, 'subsample': 0.7706126776519746, 'colsample_bytree': 0.5690990652092965, 'reg_alpha': 0.4666610478536468, 'reg_lambda': 0.33367025851525817, 'n_estimators': 338}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:42:24,580] Trial 46 finished with value: 0.7162169568854324 and parameters: {'learning_rate': 0.07810161926737154, 'max_depth': 8, 'num_leaves': 71, 'min_child_samples': 21, 'min_child_weight': 0.01174134424402721, 'subsample': 0.7471686256090194, 'colsample_bytree': 0.6572972161760942, 'reg_alpha': 9.30613302027021, 'reg_lambda': 1.5346072944868283, 'n_estimators': 472}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:43:12,091] Trial 47 finished with value: 0.7185263690791396 and parameters: {'learning_rate': 0.02646807597233115, 'max_depth': 6, 'num_leaves': 38, 'min_child_samples': 25, 'min_child_weight': 0.019569414000517343, 'subsample': 0.8501247520858809, 'colsample_bytree': 0.550390841165397, 'reg_alpha': 0.9233713152791612, 'reg_lambda': 0.1581909263785412, 'n_estimators': 547}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:43:48,138] Trial 48 finished with value: 0.716261290664171 and parameters: {'learning_rate': 0.044088613798960376, 'max_depth': 15, 'num_leaves': 51, 'min_child_samples': 77, 'min_child_weight': 0.007167952347052916, 'subsample': 0.8005386761334674, 'colsample_bytree': 0.602595975480032, 'reg_alpha': 5.889206752471251, 'reg_lambda': 0.8959997037585564, 'n_estimators': 217}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:45:13,916] Trial 49 finished with value: 0.716297253650535 and parameters: {'learning_rate': 0.03392059882715092, 'max_depth': 13, 'num_leaves': 72, 'min_child_samples': 29, 'min_child_weight': 0.03649722928814283, 'subsample': 0.8827384886181623, 'colsample_bytree': 0.742561859269055, 'reg_alpha': 1.3051252768462043, 'reg_lambda': 2.7339855610533736, 'n_estimators': 568}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:45:58,419] Trial 50 finished with value: 0.7033686156463842 and parameters: {'learning_rate': 0.2956713006509135, 'max_depth': 11, 'num_leaves': 26, 'min_child_samples': 16, 'min_child_weight': 0.0026559124844286854, 'subsample': 0.6565935977130417, 'colsample_bytree': 0.6257123420935314, 'reg_alpha': 0.2744750992384106, 'reg_lambda': 0.5234633008807671, 'n_estimators': 506}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:47:41,843] Trial 51 finished with value: 0.7188937555829075 and parameters: {'learning_rate': 0.022092966887679685, 'max_depth': 14, 'num_leaves': 128, 'min_child_samples': 13, 'min_child_weight': 0.005385698521086962, 'subsample': 0.7321241509221208, 'colsample_bytree': 0.5900235653968604, 'reg_alpha': 2.011120140817522, 'reg_lambda': 0.09326062045337802, 'n_estimators': 384}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:48:31,629] Trial 52 finished with value: 0.7191793132659717 and parameters: {'learning_rate': 0.028523090392621474, 'max_depth': 14, 'num_leaves': 12, 'min_child_samples': 13, 'min_child_weight': 0.003701401380430932, 'subsample': 0.6988556670364763, 'colsample_bytree': 0.5279166927450684, 'reg_alpha': 0.6929653277321223, 'reg_lambda': 0.23094222838637302, 'n_estimators': 706}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:49:50,624] Trial 53 finished with value: 0.7176420278405982 and parameters: {'learning_rate': 0.025450713073406708, 'max_depth': 13, 'num_leaves': 28, 'min_child_samples': 19, 'min_child_weight': 0.46921645065031037, 'subsample': 0.7759852594657988, 'colsample_bytree': 0.6738679176568372, 'reg_alpha': 3.130337899992346, 'reg_lambda': 0.033862486429251, 'n_estimators': 848}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:50:33,836] Trial 54 finished with value: 0.7173782220368494 and parameters: {'learning_rate': 0.033344386699629774, 'max_depth': 7, 'num_leaves': 59, 'min_child_samples': 11, 'min_child_weight': 0.10596256209736456, 'subsample': 0.7637543910688834, 'colsample_bytree': 0.7119931799662107, 'reg_alpha': 0.0029256960783407416, 'reg_lambda': 0.00861010421748542, 'n_estimators': 433}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:51:34,738] Trial 55 finished with value: 0.7199235303461421 and parameters: {'learning_rate': 0.04082447787338455, 'max_depth': 12, 'num_leaves': 37, 'min_child_samples': 17, 'min_child_weight': 0.008913149011684217, 'subsample': 0.7916258978056877, 'colsample_bytree': 0.761802170964078, 'reg_alpha': 2.4778962758748166, 'reg_lambda': 0.11803947692155983, 'n_estimators': 543}. Best is trial 33 with value: 0.7220333447625727.\n",
      "[I 2024-11-12 13:52:57,732] Trial 56 finished with value: 0.719727591390344 and parameters: {'learning_rate': 0.021541614442794857, 'max_depth': 14, 'num_leaves': 21, 'min_child_samples': 31, 'min_child_weight': 0.0014466721894931332, 'subsample': 0.9933325730023562, 'colsample_bytree': 0.8497151057099174, 'reg_alpha': 1.505161706746054, 'reg_lambda': 0.015445036017945805, 'n_estimators': 976}. Best is trial 33 with value: 0.7220333447625727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.7220333447625727\n",
      "  Params: {'learning_rate': 0.028184565982097714, 'max_depth': 15, 'num_leaves': 47, 'min_child_samples': 10, 'min_child_weight': 0.005676199103780439, 'subsample': 0.8507312415487855, 'colsample_bytree': 0.6295257518026033, 'reg_alpha': 0.6022984653308586, 'reg_lambda': 0.1113390443620029, 'n_estimators': 412}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# 목적함수를 클래스로 만들기\n",
    "class Objective:\n",
    "    # 변수 설정\n",
    "    def __init__(self, x, y, seed):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.seed = seed\n",
    "        self.cv = StratifiedKFold(5, shuffle= True, random_state= self.seed)\n",
    "\n",
    "    def __call__(self, trial):  # 콜백함수 역할\n",
    "        hp = {  \"objective\": \"binary\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"metric\": \"binary_logloss\",\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 7, 128),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 1.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000), }\n",
    "        \n",
    "        model = LGBMClassifier(**hp, random_state= self.seed)    \n",
    "        score = cross_val_score(model, self.x, self.y, cv= self.cv, scoring= \"f1_macro\", n_jobs= -1).mean()\n",
    "        return score\n",
    "\n",
    "# Sampler 객체 생성(대체모델 역할)\n",
    "sampler = optuna.samplers.TPESampler(seed= SEED)\n",
    "\n",
    "# study 객체 생성\n",
    "study = optuna.create_study(direction= \"maximize\", sampler= sampler)\n",
    "\n",
    "# optimize 매서드 실행\n",
    "objective_func = Objective(train_ft, target, SEED)\n",
    "study.optimize(objective_func, n_trials=200, timeout=3600)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {study.best_value}\")\n",
    "print(f\"  Params: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-13 09:34:12,456] A new study created in memory with name: no-name-9fc36cd7-6c72-45da-8480-067b4c90bbdf\n",
      "[I 2024-11-13 09:37:56,025] Trial 0 finished with value: 0.6968938966231715 and parameters: {'solver': 'saga', 'penalty': None, 'C': 0.10129197956845731}. Best is trial 0 with value: 0.6968938966231715.\n",
      "[I 2024-11-13 09:38:15,882] Trial 1 finished with value: 0.6905532345504748 and parameters: {'solver': 'lbfgs', 'penalty': None, 'C': 0.042051564509138675}. Best is trial 0 with value: 0.6968938966231715.\n",
      "[I 2024-11-13 09:38:34,945] Trial 2 finished with value: 0.6905532345504748 and parameters: {'solver': 'lbfgs', 'penalty': None, 'C': 0.0009962513222055108}. Best is trial 0 with value: 0.6968938966231715.\n",
      "[I 2024-11-13 09:39:31,517] Trial 3 finished with value: 0.6902737045842147 and parameters: {'solver': 'newton-cg', 'penalty': None, 'C': 1.1015056790269626}. Best is trial 0 with value: 0.6968938966231715.\n",
      "[I 2024-11-13 09:39:50,802] Trial 4 finished with value: 0.6905532345504748 and parameters: {'solver': 'lbfgs', 'penalty': None, 'C': 0.0019674328025306126}. Best is trial 0 with value: 0.6968938966231715.\n",
      "[I 2024-11-13 09:41:34,889] Trial 5 finished with value: 0.6905183231531875 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 2.9794544625913595}. Best is trial 0 with value: 0.6968938966231715.\n",
      "[I 2024-11-13 09:47:13,838] Trial 6 finished with value: 0.6979060023511805 and parameters: {'solver': 'saga', 'penalty': 'elasticnet', 'C': 1.3921548533046495, 'l1_ratio': 0.3567533266935893}. Best is trial 6 with value: 0.6979060023511805.\n",
      "[I 2024-11-13 09:47:20,428] Trial 7 finished with value: 0.6965525878291748 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.00010656401760606463}. Best is trial 6 with value: 0.6979060023511805.\n",
      "[I 2024-11-13 09:47:20,430] Trial 8 finished with value: -inf and parameters: {'solver': 'liblinear', 'penalty': None}. Best is trial 6 with value: 0.6979060023511805.\n",
      "[I 2024-11-13 09:47:20,431] Trial 9 finished with value: -inf and parameters: {'solver': 'liblinear', 'penalty': None}. Best is trial 6 with value: 0.6979060023511805.\n",
      "[I 2024-11-13 09:53:14,640] Trial 10 finished with value: 0.6969953942682335 and parameters: {'solver': 'saga', 'penalty': 'elasticnet', 'C': 7.041830285016017, 'l1_ratio': 0.3468508914066219}. Best is trial 6 with value: 0.6979060023511805.\n",
      "[I 2024-11-13 09:59:02,148] Trial 11 finished with value: 0.6969953942682335 and parameters: {'solver': 'saga', 'penalty': 'elasticnet', 'C': 8.620065237903596, 'l1_ratio': 0.34746156655418053}. Best is trial 6 with value: 0.6979060023511805.\n",
      "[I 2024-11-13 10:04:29,833] Trial 12 finished with value: 0.6985539630730742 and parameters: {'solver': 'saga', 'penalty': 'elasticnet', 'C': 0.3907526308501417, 'l1_ratio': 0.3560912233349937}. Best is trial 12 with value: 0.6985539630730742.\n",
      "[I 2024-11-13 10:09:53,403] Trial 13 finished with value: 0.7029297614214878 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.3355385386101844}. Best is trial 13 with value: 0.7029297614214878.\n",
      "[I 2024-11-13 10:15:03,737] Trial 14 finished with value: 0.7047246408000782 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.22301265966763692}. Best is trial 14 with value: 0.7047246408000782.\n",
      "[I 2024-11-13 10:20:14,474] Trial 15 finished with value: 0.7050545018171503 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.1840838974583433}. Best is trial 15 with value: 0.7050545018171503.\n",
      "[I 2024-11-13 10:23:12,341] Trial 16 finished with value: 0.6942587521474465 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.007717407396015297}. Best is trial 15 with value: 0.7050545018171503.\n",
      "[I 2024-11-13 10:28:18,854] Trial 17 finished with value: 0.7072298922766753 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.13782126519722185}. Best is trial 17 with value: 0.7072298922766753.\n",
      "[I 2024-11-13 10:28:18,857] Trial 18 finished with value: -inf and parameters: {'solver': 'newton-cg', 'penalty': 'l1'}. Best is trial 17 with value: 0.7072298922766753.\n",
      "[I 2024-11-13 10:32:07,287] Trial 19 finished with value: 0.7124359386331979 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.016653660299528087}. Best is trial 19 with value: 0.7124359386331979.\n",
      "[I 2024-11-13 10:35:13,576] Trial 20 finished with value: 0.704833448202438 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.010110667966085687}. Best is trial 19 with value: 0.7124359386331979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.7124359386331979\n",
      "  Params: {'solver': 'saga', 'penalty': 'l1', 'C': 0.016653660299528087}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 목적함수를 클래스로 만들기\n",
    "class Objective:\n",
    "    # 변수 설정\n",
    "    def __init__(self, x, y, seed):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.seed = seed\n",
    "        self.cv = StratifiedKFold(5, shuffle= True, random_state= self.seed)\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        # 탐색 가능한 하이퍼파라미터\n",
    "        solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\", \"lbfgs\", \"newton-cg\"])\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\", None])\n",
    "\n",
    "        # 유효하지 않은 조합을 걸러냄\n",
    "        if penalty == \"elasticnet\" and solver != \"saga\":\n",
    "            return float(\"-inf\")\n",
    "        if penalty == \"l1\" and solver not in [\"liblinear\", \"saga\"]:\n",
    "            return float(\"-inf\")\n",
    "        if penalty is None and solver not in [\"lbfgs\", \"saga\", \"newton-cg\"]:\n",
    "            return float(\"-inf\")\n",
    "\n",
    "        # C 값 탐색\n",
    "        C = trial.suggest_float(\"C\", 1e-4, 10.0, log=True)\n",
    "\n",
    "        # ElasticNet의 경우 l1_ratio 추가\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0) if penalty == \"elasticnet\" else None\n",
    "\n",
    "        # LogisticRegression 모델 정의\n",
    "        model = LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            l1_ratio=l1_ratio,\n",
    "            random_state=SEED,\n",
    "            max_iter=1000\n",
    "        )\n",
    "\n",
    "    # def __call__(self, trial):  # 콜백함수 역할\n",
    "    #     hp = {\n",
    "    #         \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\", None]),\n",
    "    #         \"C\": trial.suggest_float(\"C\", 1e-4, 10.0, log=True),  # Regularization strength\n",
    "    #         \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\", \"lbfgs\"]),\n",
    "    #         \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.0, 1.0) if trial.suggest_categorical(\"penalty\", [\"elasticnet\"]) else None\n",
    "    #     }\n",
    "\n",
    "    #     model = LogisticRegression(**{k: v for k, v in hp.items() if v is not None}, random_state=self.seed)\n",
    "        # model = LogisticRegression(**hp, random_state= self.seed)    \n",
    "        \n",
    "        score = cross_val_score(model, self.x, self.y, cv= self.cv, scoring= \"f1_macro\", n_jobs= -1).mean()\n",
    "        return score\n",
    "\n",
    "# Sampler 객체 생성(대체모델 역할)\n",
    "sampler = optuna.samplers.TPESampler(seed= SEED)\n",
    "\n",
    "# study 객체 생성\n",
    "study = optuna.create_study(direction= \"maximize\", sampler= sampler)\n",
    "\n",
    "# optimize 매서드 실행\n",
    "objective_func = Objective(train_ft, target, SEED)\n",
    "study.optimize(objective_func, n_trials=200, timeout=3600)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {study.best_value}\")\n",
    "print(f\"  Params: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
