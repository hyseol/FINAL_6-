{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "N44QYORV8wFy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1qAeLjZVWZz"
   },
   "source": [
    "- 시드값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nVyhJ6uOVVNE"
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd7JpzNBHa1"
   },
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KFGKUIWt89fZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523105, 7), (14940, 2), (441196, 7), (12225, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Data/\"\n",
    "train_tr = pd.read_csv(f\"{DATA_PATH}store_train_transactions.csv\") # 학습용 구매기록 데이터\n",
    "train_target = pd.read_csv(f\"{DATA_PATH}store_train.csv\") # 학습용 정답 데이터\n",
    "test_tr = pd.read_csv(f\"{DATA_PATH}store_test_transactions.csv\") # 테스트용 구매기록 데이터\n",
    "submit = pd.read_csv(f\"{DATA_PATH}store_submission.csv\") # 제출 양식 데이터\n",
    "\n",
    "train_tr.shape , train_target.shape , test_tr.shape , submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZq4x4CuP2gr"
   },
   "source": [
    "- 공통 피처 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "T3tcFrkLPv1g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1471), (12225, 1471))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.2_피처삭제X_군집분석_1108.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.2_피처삭제X_군집분석_1108.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1504), (12225, 1504))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v3.0_1106.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v3.0_1106.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r43SCHUujW-f"
   },
   "source": [
    "# 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.isnull().sum().sum(), test_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgPa4QG0RF2d"
   },
   "source": [
    "# 특성 공학(Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXuo6unbRLGm"
   },
   "source": [
    "- ID 변수 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "xfksFVguRFuZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1503), (12225, 1503))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjuSj8URRa_q"
   },
   "source": [
    "- 추가 피처 만들어 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EQaqdQSARFr4"
   },
   "outputs": [],
   "source": [
    "# cols = [ col for col in train_ft.columns if col.startswith(\"pivot_cnt_\") ]\n",
    "\n",
    "# train_ft[\"중분류별_구매횟수_std\"] = train_ft[cols].std(axis=1)\n",
    "# train_ft[\"중분류별_구매횟수_skew\"] = train_ft[cols].skew(axis=1)\n",
    "# train_ft[\"중분류별_구매횟수_kurt\"] = train_ft[cols].kurt(axis=1)\n",
    "\n",
    "# test_ft[\"중분류별_구매횟수_std\"] = test_ft[cols].std(axis=1)\n",
    "# test_ft[\"중분류별_구매횟수_skew\"] = test_ft[cols].skew(axis=1)\n",
    "# test_ft[\"중분류별_구매횟수_kurt\"] = test_ft[cols].kurt(axis=1)\n",
    "\n",
    "# train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXvdNLMtSVlW"
   },
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "0YvdL9OVSRab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점        4\n",
       "주구매_대분류     22\n",
       "주구매_중분류    246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "3d6B3II8T25p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1507), (12225, 1507))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "q0ztgmEMRFpN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1509), (12225, 1509))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.count.CountEncoder()\n",
    "# train_ft[\"주구매지점_cnt\"] = enc.fit_transform(train_ft[[\"주구매지점\"]])\n",
    "# test_ft[\"주구매지점_cnt\"] = enc.transform(test_ft[[\"주구매지점\"]])\n",
    "\n",
    "train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "train_ft[\"주구매_대분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_대분류\"]])\n",
    "test_ft[\"주구매_대분류_cnt\"] = enc.transform(test_ft[[\"주구매_대분류\"]])\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPURwRnPUj-B"
   },
   "source": [
    "- 문자열 피처 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "suLVrqBCRFmK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['주구매지점', '주구매_대분류', '주구매_중분류']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "zZlZoAMZUbGp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1506), (12225, 1506))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "1-y4-kmTUmso"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object'), Index([], dtype='object'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.select_dtypes(\"object\").columns , test_ft.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAQ-3TU5U0Pk"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "vyDpuu4OUmnO"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlmnx5QsU8_x"
   },
   "source": [
    "# 정답 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "sawXnAciUmkJ"
   },
   "outputs": [],
   "source": [
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXinfWehVH4-"
   },
   "source": [
    "# cv 점수 확인해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임계값 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-11 00:44:06,325] A new study created in memory with name: no-name-c7f03b32-9673-4955-b248-61ce53d18bac\n",
      "[I 2024-11-11 00:45:32,808] Trial 0 finished with value: 0.696949724507624 and parameters: {'n_estimators': 400, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'gamma': 0.2904180608409973}. Best is trial 0 with value: 0.696949724507624.\n",
      "[I 2024-11-11 00:47:42,017] Trial 1 finished with value: 0.7138924584313022 and parameters: {'n_estimators': 900, 'learning_rate': 0.07725378389307355, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9849549260809971, 'colsample_bytree': 0.9162213204002109, 'gamma': 1.0616955533913808}. Best is trial 1 with value: 0.7138924584313022.\n",
      "[I 2024-11-11 00:48:24,128] Trial 2 finished with value: 0.7044579517701782 and parameters: {'n_estimators': 200, 'learning_rate': 0.018659959624904916, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021, 'gamma': 3.0592644736118975}. Best is trial 1 with value: 0.7138924584313022.\n",
      "[I 2024-11-11 00:49:04,626] Trial 3 finished with value: 0.7096888247451201 and parameters: {'n_estimators': 200, 'learning_rate': 0.027010527749605478, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8925879806965068, 'colsample_bytree': 0.5998368910791798, 'gamma': 2.571172192068058}. Best is trial 1 with value: 0.7138924584313022.\n",
      "[I 2024-11-11 00:51:26,186] Trial 4 finished with value: 0.7171190921455015 and parameters: {'n_estimators': 600, 'learning_rate': 0.011711509955524094, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5325257964926398, 'colsample_bytree': 0.9744427686266666, 'gamma': 4.828160165372797}. Best is trial 4 with value: 0.7171190921455015.\n",
      "[I 2024-11-11 00:53:05,329] Trial 5 finished with value: 0.7186662395131863 and parameters: {'n_estimators': 900, 'learning_rate': 0.028180680291847244, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7200762468698007, 'colsample_bytree': 0.5610191174223894, 'gamma': 2.475884550556351}. Best is trial 5 with value: 0.7186662395131863.\n",
      "[I 2024-11-11 00:53:25,967] Trial 6 finished with value: 0.71127041909501 and parameters: {'n_estimators': 100, 'learning_rate': 0.22038218939289875, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6558555380447055, 'colsample_bytree': 0.7600340105889054, 'gamma': 2.7335513967163982}. Best is trial 5 with value: 0.7186662395131863.\n",
      "[I 2024-11-11 00:53:54,065] Trial 7 finished with value: 0.7067385759584506 and parameters: {'n_estimators': 200, 'learning_rate': 0.27051668818999286, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.9474136752138245, 'colsample_bytree': 0.7989499894055425, 'gamma': 4.609371175115584}. Best is trial 5 with value: 0.7186662395131863.\n",
      "[I 2024-11-11 00:54:13,659] Trial 8 finished with value: 0.667270714222569 and parameters: {'n_estimators': 100, 'learning_rate': 0.01947558230629543, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.6943386448447411, 'colsample_bytree': 0.6356745158869479, 'gamma': 4.143687545759647}. Best is trial 5 with value: 0.7186662395131863.\n",
      "[I 2024-11-11 00:55:39,172] Trial 9 finished with value: 0.716814261149078 and parameters: {'n_estimators': 400, 'learning_rate': 0.026000059117302653, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.5372753218398854, 'gamma': 4.9344346830025865}. Best is trial 5 with value: 0.7186662395131863.\n",
      "[I 2024-11-11 00:57:24,994] Trial 10 finished with value: 0.7194462132246893 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06690992453172917, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8200442512337782, 'colsample_bytree': 0.7032144299581322, 'gamma': 1.6552304085829206}. Best is trial 10 with value: 0.7194462132246893.\n",
      "[I 2024-11-11 00:59:11,531] Trial 11 finished with value: 0.7186393968966777 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06438873843712743, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8087272364965106, 'colsample_bytree': 0.7146743022617835, 'gamma': 1.461192327509932}. Best is trial 10 with value: 0.7194462132246893.\n",
      "[I 2024-11-11 01:00:47,048] Trial 12 finished with value: 0.7097667663554301 and parameters: {'n_estimators': 800, 'learning_rate': 0.10936598253341487, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7944464039018335, 'colsample_bytree': 0.5093981067629809, 'gamma': 1.667817505714271}. Best is trial 10 with value: 0.7194462132246893.\n",
      "[I 2024-11-11 01:02:04,899] Trial 13 finished with value: 0.7179439707730284 and parameters: {'n_estimators': 700, 'learning_rate': 0.04264682529953517, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.844509605917982, 'colsample_bytree': 0.6802071658056971, 'gamma': 3.5598890110670585}. Best is trial 10 with value: 0.7194462132246893.\n",
      "[I 2024-11-11 01:04:08,645] Trial 14 finished with value: 0.699422356082453 and parameters: {'n_estimators': 1000, 'learning_rate': 0.13361301016575639, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.622344146322471, 'colsample_bytree': 0.8317032143059913, 'gamma': 1.9496705242612362}. Best is trial 10 with value: 0.7194462132246893.\n",
      "[I 2024-11-11 01:07:28,318] Trial 15 finished with value: 0.7128362766062455 and parameters: {'n_estimators': 800, 'learning_rate': 0.036847914818836085, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.7522385470087106, 'colsample_bytree': 0.8426321221817463, 'gamma': 0.7048653423126672}. Best is trial 10 with value: 0.7194462132246893.\n",
      "[I 2024-11-11 01:09:25,920] Trial 16 finished with value: 0.7138009565696428 and parameters: {'n_estimators': 900, 'learning_rate': 0.09419893498624986, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.7540645647855486, 'colsample_bytree': 0.7189377837103056, 'gamma': 2.0585841380760748}. Best is trial 10 with value: 0.7194462132246893.\n",
      "[I 2024-11-11 01:10:41,016] Trial 17 finished with value: 0.7208011932435112 and parameters: {'n_estimators': 600, 'learning_rate': 0.051413873657647435, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8340914134891353, 'colsample_bytree': 0.5474863513918804, 'gamma': 3.237269006701002}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:11:49,505] Trial 18 finished with value: 0.7183569549072164 and parameters: {'n_estimators': 500, 'learning_rate': 0.05192095924630255, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8609727402803516, 'colsample_bytree': 0.6407071297894797, 'gamma': 3.626263406829886}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:12:58,219] Trial 19 finished with value: 0.7102419788387266 and parameters: {'n_estimators': 600, 'learning_rate': 0.18181869153175959, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8091347157493435, 'colsample_bytree': 0.8979387218009913, 'gamma': 3.3545584522017013}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:13:42,710] Trial 20 finished with value: 0.7146357702010985 and parameters: {'n_estimators': 400, 'learning_rate': 0.15013971957309122, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.931055430850214, 'colsample_bytree': 0.5005221621716414, 'gamma': 4.095336881172505}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:15:18,862] Trial 21 finished with value: 0.7191562640418786 and parameters: {'n_estimators': 900, 'learning_rate': 0.050629738465911255, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7020358933404531, 'colsample_bytree': 0.5670700169696827, 'gamma': 2.2135798431668077}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:16:45,195] Trial 22 finished with value: 0.7181604496589706 and parameters: {'n_estimators': 800, 'learning_rate': 0.060327132170655384, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7794556992044196, 'colsample_bytree': 0.6027690837382809, 'gamma': 2.220700096712316}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:18:42,985] Trial 23 finished with value: 0.7181463273027295 and parameters: {'n_estimators': 1000, 'learning_rate': 0.04370494888072622, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.845980536515349, 'colsample_bytree': 0.542131785797641, 'gamma': 1.38980062423156}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:20:16,784] Trial 24 finished with value: 0.7112042039328028 and parameters: {'n_estimators': 700, 'learning_rate': 0.08518655823690709, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6675750049451707, 'colsample_bytree': 0.6955946045943742, 'gamma': 3.0322236171823147}. Best is trial 17 with value: 0.7208011932435112.\n",
      "[I 2024-11-11 01:21:34,326] Trial 25 finished with value: 0.721684715424385 and parameters: {'n_estimators': 700, 'learning_rate': 0.06793915590422454, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.6120195154305907, 'colsample_bytree': 0.7642894267862355, 'gamma': 0.847950196119279}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:22:39,851] Trial 26 finished with value: 0.7207722888097648 and parameters: {'n_estimators': 500, 'learning_rate': 0.07155281711398265, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.535321557171029, 'colsample_bytree': 0.7616267218363161, 'gamma': 0.3684212022173423}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:24:08,295] Trial 27 finished with value: 0.7027256366168075 and parameters: {'n_estimators': 500, 'learning_rate': 0.12142141495551786, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.501204673601028, 'colsample_bytree': 0.7600110785783976, 'gamma': 0.15289441296143602}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:25:40,499] Trial 28 finished with value: 0.7210245073199291 and parameters: {'n_estimators': 700, 'learning_rate': 0.03482160280738541, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.5806882452352471, 'colsample_bytree': 0.7932603006929972, 'gamma': 0.5855330059864033}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:27:32,967] Trial 29 finished with value: 0.7186290397160212 and parameters: {'n_estimators': 700, 'learning_rate': 0.03813134522121036, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.595293697022201, 'colsample_bytree': 0.813481537480198, 'gamma': 0.7169672486122578}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:28:53,856] Trial 30 finished with value: 0.7216639915056184 and parameters: {'n_estimators': 600, 'learning_rate': 0.03168663091963664, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.5965133063127513, 'colsample_bytree': 0.8726274389951029, 'gamma': 1.0163989555415336}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:30:14,302] Trial 31 finished with value: 0.7186434424634607 and parameters: {'n_estimators': 600, 'learning_rate': 0.03246146259132291, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.5933961247511886, 'colsample_bytree': 0.8653085503216602, 'gamma': 0.9129693476431344}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:32:03,824] Trial 32 finished with value: 0.7201865340881641 and parameters: {'n_estimators': 700, 'learning_rate': 0.019359326941725458, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.5548483068162521, 'colsample_bytree': 0.8899191850587589, 'gamma': 0.015703895754862085}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:33:32,647] Trial 33 finished with value: 0.7169695740270058 and parameters: {'n_estimators': 600, 'learning_rate': 0.01555575257859021, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.6290740840240777, 'colsample_bytree': 0.9387819652570567, 'gamma': 0.4180957777935186}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:35:20,886] Trial 34 finished with value: 0.7185602606192405 and parameters: {'n_estimators': 700, 'learning_rate': 0.0493888049052074, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5780080148118145, 'colsample_bytree': 0.7893711345219008, 'gamma': 1.17602394642851}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:36:43,718] Trial 35 finished with value: 0.7182784007163443 and parameters: {'n_estimators': 300, 'learning_rate': 0.022577918288179042, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.6293658178326302, 'colsample_bytree': 0.8650338321823047, 'gamma': 0.6607940136048758}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:38:15,659] Trial 36 finished with value: 0.7205086767720044 and parameters: {'n_estimators': 800, 'learning_rate': 0.031262480955702776, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.5043629781013477, 'colsample_bytree': 0.9322720171024577, 'gamma': 1.040520041169129}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:39:33,928] Trial 37 finished with value: 0.7149138045351545 and parameters: {'n_estimators': 500, 'learning_rate': 0.08160883624839269, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.563199683424047, 'colsample_bytree': 0.9991417930830018, 'gamma': 0.5107509550545639}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:41:34,802] Trial 38 finished with value: 0.7177505055652457 and parameters: {'n_estimators': 600, 'learning_rate': 0.014332218564622709, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.657966585054881, 'colsample_bytree': 0.7394172048053667, 'gamma': 1.2375950106930458}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:43:17,338] Trial 39 finished with value: 0.7121795751730586 and parameters: {'n_estimators': 700, 'learning_rate': 0.01056628905027901, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.6143002086322177, 'colsample_bytree': 0.6693391816938952, 'gamma': 3.070897284734884}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:44:30,508] Trial 40 finished with value: 0.7139778093580199 and parameters: {'n_estimators': 600, 'learning_rate': 0.023436016706451283, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6750770905273858, 'colsample_bytree': 0.7875093422672456, 'gamma': 0.8502227764190529}. Best is trial 25 with value: 0.721684715424385.\n",
      "[I 2024-11-11 01:45:35,958] Trial 41 finished with value: 0.7231132809732224 and parameters: {'n_estimators': 500, 'learning_rate': 0.06896711485572204, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.5278507450144855, 'colsample_bytree': 0.7400570330809504, 'gamma': 0.39618577713606257}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:46:31,787] Trial 42 finished with value: 0.7196984322182913 and parameters: {'n_estimators': 400, 'learning_rate': 0.05816619506082475, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.5233958159502429, 'colsample_bytree': 0.8211033335201977, 'gamma': 0.26378004201570926}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:47:51,765] Trial 43 finished with value: 0.7207872880789781 and parameters: {'n_estimators': 500, 'learning_rate': 0.03550570140861774, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.5543732181904989, 'colsample_bytree': 0.7379805876223173, 'gamma': 0.5506592963227546}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:48:55,966] Trial 44 finished with value: 0.7178768576736994 and parameters: {'n_estimators': 300, 'learning_rate': 0.04206423473116904, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.9993204662796429, 'colsample_bytree': 0.5960279646929405, 'gamma': 0.011055972884267629}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:50:03,102] Trial 45 finished with value: 0.7153050086766999 and parameters: {'n_estimators': 600, 'learning_rate': 0.1015707991316879, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.5862705612409971, 'colsample_bytree': 0.8557184824942542, 'gamma': 1.673690358235039}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:52:46,283] Trial 46 finished with value: 0.7188557785108939 and parameters: {'n_estimators': 700, 'learning_rate': 0.02940092092745973, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.5340639245919216, 'colsample_bytree': 0.7733286425947719, 'gamma': 2.6916512905130547}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:54:29,078] Trial 47 finished with value: 0.7147250742181762 and parameters: {'n_estimators': 800, 'learning_rate': 0.070300325634653, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.5686503139404443, 'colsample_bytree': 0.8061994033429173, 'gamma': 0.9691860965418106}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:55:08,840] Trial 48 finished with value: 0.7134583853079385 and parameters: {'n_estimators': 300, 'learning_rate': 0.046086614608617904, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.6374276470681828, 'colsample_bytree': 0.8940381887604467, 'gamma': 1.3645414977733115}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:56:09,126] Trial 49 finished with value: 0.7179391487768461 and parameters: {'n_estimators': 400, 'learning_rate': 0.05733478348004333, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.7253565701299766, 'colsample_bytree': 0.6682212233458045, 'gamma': 4.073344175427853}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:57:17,861] Trial 50 finished with value: 0.7163140093462588 and parameters: {'n_estimators': 500, 'learning_rate': 0.025989906774999766, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.6024776821070421, 'colsample_bytree': 0.9611638269038137, 'gamma': 0.252426614361952}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 01:58:39,699] Trial 51 finished with value: 0.7215967525383851 and parameters: {'n_estimators': 500, 'learning_rate': 0.03576548718267923, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.556622613598355, 'colsample_bytree': 0.7326566657485608, 'gamma': 0.546844924166915}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:00:01,380] Trial 52 finished with value: 0.7209487454908949 and parameters: {'n_estimators': 600, 'learning_rate': 0.03642920135840018, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.5447040012585264, 'colsample_bytree': 0.7232383309029838, 'gamma': 0.8097747717781945}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:01:11,503] Trial 53 finished with value: 0.7173244890368503 and parameters: {'n_estimators': 500, 'learning_rate': 0.035335593391333416, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.5203688318256026, 'colsample_bytree': 0.7233535389605762, 'gamma': 0.8278402655999936}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:02:50,449] Trial 54 finished with value: 0.7202456523045936 and parameters: {'n_estimators': 600, 'learning_rate': 0.022344248494581748, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5415672021871941, 'colsample_bytree': 0.6929575004414061, 'gamma': 0.4467479927984481}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:04:24,867] Trial 55 finished with value: 0.7207760101728029 and parameters: {'n_estimators': 700, 'learning_rate': 0.02712305182875661, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.5733546789204806, 'colsample_bytree': 0.7428063370624219, 'gamma': 0.6236573416312874}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:05:17,382] Trial 56 finished with value: 0.7142464025177542 and parameters: {'n_estimators': 400, 'learning_rate': 0.03762900373235812, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6439486292242544, 'colsample_bytree': 0.778326148241323, 'gamma': 1.1348409132772423}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:07:00,205] Trial 57 finished with value: 0.7230420481002843 and parameters: {'n_estimators': 800, 'learning_rate': 0.04111341723413565, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6079618372775271, 'colsample_bytree': 0.7129462976040147, 'gamma': 1.5692517987263805}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:09:15,264] Trial 58 finished with value: 0.7185114511138916 and parameters: {'n_estimators': 800, 'learning_rate': 0.04187692855054781, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6094916497447789, 'colsample_bytree': 0.6586629811675976, 'gamma': 1.605426933286986}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:10:52,742] Trial 59 finished with value: 0.7159253659610118 and parameters: {'n_estimators': 900, 'learning_rate': 0.07934100052486977, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6854310779992767, 'colsample_bytree': 0.762187989912046, 'gamma': 1.8438566157387815}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:12:57,466] Trial 60 finished with value: 0.7065001889904419 and parameters: {'n_estimators': 800, 'learning_rate': 0.09309690541607256, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.5180371957597569, 'colsample_bytree': 0.7085140328968516, 'gamma': 1.0216541065862224}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:14:20,003] Trial 61 finished with value: 0.7192032071202128 and parameters: {'n_estimators': 600, 'learning_rate': 0.032522800552213724, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.5477168150552444, 'colsample_bytree': 0.7312217209599581, 'gamma': 0.7918484525913297}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:15:49,587] Trial 62 finished with value: 0.719885048893907 and parameters: {'n_estimators': 700, 'learning_rate': 0.06522781469900912, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.5848712078695419, 'colsample_bytree': 0.6873272158918284, 'gamma': 1.2556746548199038}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:16:57,523] Trial 63 finished with value: 0.7203852001491613 and parameters: {'n_estimators': 500, 'learning_rate': 0.04580242516999303, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.610256894261703, 'colsample_bytree': 0.6237860604538199, 'gamma': 1.5008404421722572}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:18:41,339] Trial 64 finished with value: 0.7224336213932586 and parameters: {'n_estimators': 700, 'learning_rate': 0.03970586488292649, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.557211800929164, 'colsample_bytree': 0.7148246632282153, 'gamma': 0.19089160467075245}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:20:37,981] Trial 65 finished with value: 0.7206091845949482 and parameters: {'n_estimators': 800, 'learning_rate': 0.04073538695710525, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.647131445719043, 'colsample_bytree': 0.7501831631819412, 'gamma': 0.18719431954060917}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:22:37,052] Trial 66 finished with value: 0.7126433967784744 and parameters: {'n_estimators': 700, 'learning_rate': 0.05415788823779162, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.5640950323384584, 'colsample_bytree': 0.7051654521594481, 'gamma': 0.3966168262659521}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:24:45,249] Trial 67 finished with value: 0.6907714747912598 and parameters: {'n_estimators': 900, 'learning_rate': 0.2956713006509135, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.599070068408225, 'colsample_bytree': 0.7946610200737546, 'gamma': 0.5692841009720695}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:26:06,270] Trial 68 finished with value: 0.7185574137557309 and parameters: {'n_estimators': 700, 'learning_rate': 0.047595989115983756, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.512635454181686, 'colsample_bytree': 0.8392550153864659, 'gamma': 0.12265345151626939}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:27:58,816] Trial 69 finished with value: 0.72127594752926 and parameters: {'n_estimators': 800, 'learning_rate': 0.025175310867180223, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.5738946905986895, 'colsample_bytree': 0.77373205466602, 'gamma': 0.33857626498151855}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:29:55,819] Trial 70 finished with value: 0.7219491685186751 and parameters: {'n_estimators': 800, 'learning_rate': 0.025492406052409856, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6228151823357745, 'colsample_bytree': 0.6504316906243913, 'gamma': 0.2791669274506834}. Best is trial 41 with value: 0.7231132809732224.\n",
      "[I 2024-11-11 02:31:52,738] Trial 71 finished with value: 0.7245423313347741 and parameters: {'n_estimators': 800, 'learning_rate': 0.02447919067458159, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.619919679548186, 'colsample_bytree': 0.628927421441943, 'gamma': 0.31510152650661194}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:34:06,895] Trial 72 finished with value: 0.7213965696122958 and parameters: {'n_estimators': 900, 'learning_rate': 0.01736186702279555, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6192890090387525, 'colsample_bytree': 0.6364447385540201, 'gamma': 0.06664502727423066}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:36:16,638] Trial 73 finished with value: 0.7224928780298052 and parameters: {'n_estimators': 800, 'learning_rate': 0.028361495118374047, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.6567567454091497, 'colsample_bytree': 0.6136267558887972, 'gamma': 0.2173501053635365}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:38:47,750] Trial 74 finished with value: 0.7205765958163454 and parameters: {'n_estimators': 800, 'learning_rate': 0.020904289053576955, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.66879024513288, 'colsample_bytree': 0.5959898187179803, 'gamma': 0.27785976577984384}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:40:59,806] Trial 75 finished with value: 0.7212238861476937 and parameters: {'n_estimators': 800, 'learning_rate': 0.02417412819493757, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.7150059846108652, 'colsample_bytree': 0.6313906075712516, 'gamma': 0.1686790524339006}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:43:48,729] Trial 76 finished with value: 0.7229622289957729 and parameters: {'n_estimators': 900, 'learning_rate': 0.02949228683828776, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.6595016251611394, 'colsample_bytree': 0.6158999661421335, 'gamma': 0.7131820373224842}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:46:34,903] Trial 77 finished with value: 0.7215690450337937 and parameters: {'n_estimators': 900, 'learning_rate': 0.029608941703849753, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6312743694782371, 'colsample_bytree': 0.6164789104092021, 'gamma': 0.7265469139866713}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:49:39,945] Trial 78 finished with value: 0.723321041858753 and parameters: {'n_estimators': 1000, 'learning_rate': 0.018258804684084577, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.6567432138612913, 'colsample_bytree': 0.5837812953575827, 'gamma': 0.38556640931091607}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:53:00,029] Trial 79 finished with value: 0.7222388046772715 and parameters: {'n_estimators': 900, 'learning_rate': 0.017113905821526325, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.655530509622046, 'colsample_bytree': 0.5738749850553089, 'gamma': 0.3612332303925145}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:56:35,738] Trial 80 finished with value: 0.7193921391966661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.014202038948203181, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6980805723042646, 'colsample_bytree': 0.5675877696825087, 'gamma': 2.4575710210007515}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 02:59:51,868] Trial 81 finished with value: 0.7226426192220811 and parameters: {'n_estimators': 1000, 'learning_rate': 0.017178754897642683, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6512380598062412, 'colsample_bytree': 0.5259236953786199, 'gamma': 0.4525130635958442}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:03:03,014] Trial 82 finished with value: 0.7199098569095105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.017896991042917993, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6576737001856745, 'colsample_bytree': 0.6086103522002705, 'gamma': 0.49107793639756997}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:06:46,119] Trial 83 finished with value: 0.7209262253220752 and parameters: {'n_estimators': 1000, 'learning_rate': 0.016475439520263455, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6794041750073003, 'colsample_bytree': 0.5784850736386633, 'gamma': 0.001583082643547673}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:09:42,101] Trial 84 finished with value: 0.7222794037718918 and parameters: {'n_estimators': 900, 'learning_rate': 0.013111226219948365, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7118622239799666, 'colsample_bytree': 0.5172711567899296, 'gamma': 0.3606938256641792}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:13:06,150] Trial 85 finished with value: 0.719711828061123 and parameters: {'n_estimators': 1000, 'learning_rate': 0.012679751312030856, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7384076903391845, 'colsample_bytree': 0.5217213370041054, 'gamma': 0.16463057738559514}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:15:56,061] Trial 86 finished with value: 0.7211859183942682 and parameters: {'n_estimators': 900, 'learning_rate': 0.020494773811671235, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7735867411774885, 'colsample_bytree': 0.5270572642837966, 'gamma': 0.6525642268168375}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:18:54,192] Trial 87 finished with value: 0.7203333192720289 and parameters: {'n_estimators': 900, 'learning_rate': 0.011797781419541522, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.7012869895682676, 'colsample_bytree': 0.5496462990443879, 'gamma': 0.4553497423076762}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:22:02,388] Trial 88 finished with value: 0.721224324261702 and parameters: {'n_estimators': 1000, 'learning_rate': 0.014728791695963259, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7101092077692441, 'colsample_bytree': 0.5534925004716913, 'gamma': 0.3639082083701486}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:24:47,634] Trial 89 finished with value: 0.7194699511874258 and parameters: {'n_estimators': 900, 'learning_rate': 0.010228934207932194, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.6641233408636845, 'colsample_bytree': 0.5877896177697052, 'gamma': 0.7014710239728008}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:28:04,067] Trial 90 finished with value: 0.7201542618231921 and parameters: {'n_estimators': 1000, 'learning_rate': 0.013308136347577326, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.6915782934499302, 'colsample_bytree': 0.5208808312880442, 'gamma': 0.12225083283774385}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:31:14,699] Trial 91 finished with value: 0.7201600515288084 and parameters: {'n_estimators': 900, 'learning_rate': 0.019125155417755214, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.6475273573622916, 'colsample_bytree': 0.5092637552412655, 'gamma': 0.3435258621040142}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:34:37,322] Trial 92 finished with value: 0.7227507232568464 and parameters: {'n_estimators': 900, 'learning_rate': 0.01630296044338363, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.7327244462626124, 'colsample_bytree': 0.5786507841826579, 'gamma': 0.4699509983427424}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:38:11,728] Trial 93 finished with value: 0.7201846079370967 and parameters: {'n_estimators': 900, 'learning_rate': 0.020204285598164725, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7573735388671142, 'colsample_bytree': 0.584881021236315, 'gamma': 0.5032924591457656}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:40:59,871] Trial 94 finished with value: 0.7217593952571184 and parameters: {'n_estimators': 1000, 'learning_rate': 0.015619670325855229, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.7336379506636358, 'colsample_bytree': 0.5374401803154366, 'gamma': 0.9360540353167668}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:44:51,841] Trial 95 finished with value: 0.7180784474496253 and parameters: {'n_estimators': 1000, 'learning_rate': 0.027933376806747453, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.6795947440621093, 'colsample_bytree': 0.5617437415311927, 'gamma': 0.24992393224250942}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:47:41,419] Trial 96 finished with value: 0.7221865417369783 and parameters: {'n_estimators': 900, 'learning_rate': 0.02228622141896151, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6351832720004146, 'colsample_bytree': 0.6490240404378893, 'gamma': 0.6176170140965614}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:50:15,243] Trial 97 finished with value: 0.7193663214905547 and parameters: {'n_estimators': 800, 'learning_rate': 0.011197847336089932, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6711541031316812, 'colsample_bytree': 0.6176698722894458, 'gamma': 0.7380421290063521}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:53:13,856] Trial 98 finished with value: 0.7213387724907279 and parameters: {'n_estimators': 800, 'learning_rate': 0.018265669930751252, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.7105075348482338, 'colsample_bytree': 0.5311406963637106, 'gamma': 0.4402946545419782}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:57:26,201] Trial 99 finished with value: 0.7202090701531049 and parameters: {'n_estimators': 900, 'learning_rate': 0.012719347669457986, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.7256053385829291, 'colsample_bytree': 0.675872719434468, 'gamma': 0.08271764370024759}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 03:59:47,304] Trial 100 finished with value: 0.7167692000399661 and parameters: {'n_estimators': 800, 'learning_rate': 0.01618345696938352, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.9564071848480931, 'colsample_bytree': 0.5012432396094813, 'gamma': 0.5760693010615932}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:03:03,704] Trial 101 finished with value: 0.7190425518947474 and parameters: {'n_estimators': 900, 'learning_rate': 0.02136697250193336, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6523520891497367, 'colsample_bytree': 0.5712056840137525, 'gamma': 0.22115588733355843}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:06:24,167] Trial 102 finished with value: 0.7209254472551642 and parameters: {'n_estimators': 900, 'learning_rate': 0.017404570884743, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6411453660652151, 'colsample_bytree': 0.5943803009122868, 'gamma': 0.33922995511545484}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:09:50,562] Trial 103 finished with value: 0.7151979805192571 and parameters: {'n_estimators': 1000, 'learning_rate': 0.030122318695968653, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6593620229935439, 'colsample_bytree': 0.6046762544046399, 'gamma': 0.4122638008723597}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:12:33,211] Trial 104 finished with value: 0.7215839742359919 and parameters: {'n_estimators': 900, 'learning_rate': 0.03276732181065616, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6837746114809994, 'colsample_bytree': 0.5551280941055358, 'gamma': 0.8711407435704989}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:16:00,952] Trial 105 finished with value: 0.7196059228830235 and parameters: {'n_estimators': 1000, 'learning_rate': 0.014225110923790694, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.7624268815322641, 'colsample_bytree': 0.5761080093623498, 'gamma': 0.21713905348309015}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:18:15,431] Trial 106 finished with value: 0.7201608318957853 and parameters: {'n_estimators': 800, 'learning_rate': 0.02409363794961855, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6055071587936585, 'colsample_bytree': 0.5425383249568303, 'gamma': 4.547301016209615}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:20:57,207] Trial 107 finished with value: 0.7149912494721334 and parameters: {'n_estimators': 900, 'learning_rate': 0.03904111382698132, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.6254832670669563, 'colsample_bytree': 0.6107823833033205, 'gamma': 0.08861576497920973}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:23:49,050] Trial 108 finished with value: 0.7221385065756621 and parameters: {'n_estimators': 1000, 'learning_rate': 0.016598457507913188, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.7967998425644343, 'colsample_bytree': 0.6261002444137853, 'gamma': 0.5116796518167077}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:27:01,772] Trial 109 finished with value: 0.7105276118534922 and parameters: {'n_estimators': 800, 'learning_rate': 0.07447885516451377, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.5871034882947865, 'colsample_bytree': 0.6582196956042208, 'gamma': 0.3430115100624468}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:27:40,174] Trial 110 finished with value: 0.6986322413052679 and parameters: {'n_estimators': 100, 'learning_rate': 0.019347304299285432, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.5284722994899212, 'colsample_bytree': 0.5863537294591551, 'gamma': 1.0732701304440455}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:30:34,445] Trial 111 finished with value: 0.7204001420007429 and parameters: {'n_estimators': 900, 'learning_rate': 0.022622661206581646, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6351307821786525, 'colsample_bytree': 0.6452851470290466, 'gamma': 0.5728769488765427}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:33:21,125] Trial 112 finished with value: 0.720505487253779 and parameters: {'n_estimators': 900, 'learning_rate': 0.027229617990542583, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6430178241795654, 'colsample_bytree': 0.6553226981736462, 'gamma': 0.6616113589459028}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:36:07,827] Trial 113 finished with value: 0.7206526980138017 and parameters: {'n_estimators': 900, 'learning_rate': 0.021854491894278294, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.7423421814755558, 'colsample_bytree': 0.6364970223797861, 'gamma': 0.7822016020039637}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:39:04,173] Trial 114 finished with value: 0.7217448548346191 and parameters: {'n_estimators': 900, 'learning_rate': 0.015151110702177902, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.6637524653569047, 'colsample_bytree': 0.7132542738821943, 'gamma': 0.4397276508076937}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:41:30,787] Trial 115 finished with value: 0.7143274831023427 and parameters: {'n_estimators': 800, 'learning_rate': 0.06099964188043139, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6893878518987706, 'colsample_bytree': 0.6200582789338559, 'gamma': 0.6229329000750827}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:44:58,379] Trial 116 finished with value: 0.7198800126959937 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02386078905531451, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6352407187408712, 'colsample_bytree': 0.7521594443642892, 'gamma': 2.0310135912771052}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:47:33,880] Trial 117 finished with value: 0.6960781052214425 and parameters: {'n_estimators': 900, 'learning_rate': 0.21812532139548993, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.6178264858397224, 'colsample_bytree': 0.6967591829903169, 'gamma': 0.2693667840247583}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:50:40,203] Trial 118 finished with value: 0.7205883007141545 and parameters: {'n_estimators': 1000, 'learning_rate': 0.018262773769821165, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.6259920791032276, 'colsample_bytree': 0.6685291174393019, 'gamma': 0.20721740694820218}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:53:05,251] Trial 119 finished with value: 0.7201160851445779 and parameters: {'n_estimators': 800, 'learning_rate': 0.03340785237579505, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.5913971250766537, 'colsample_bytree': 0.6815019838990873, 'gamma': 2.36463582377065}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:55:41,779] Trial 120 finished with value: 0.7210458091932522 and parameters: {'n_estimators': 900, 'learning_rate': 0.013522104507178678, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.6703659178822626, 'colsample_bytree': 0.5976871244306338, 'gamma': 1.7678641023109656}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 04:58:32,909] Trial 121 finished with value: 0.7190463895186011 and parameters: {'n_estimators': 1000, 'learning_rate': 0.016703125430967646, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.8692894498174273, 'colsample_bytree': 0.6255120138528416, 'gamma': 0.5283327805131267}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:01:28,316] Trial 122 finished with value: 0.7206210031503171 and parameters: {'n_estimators': 1000, 'learning_rate': 0.019521662696435647, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6453710784972709, 'colsample_bytree': 0.6312603762061171, 'gamma': 0.4578501159875874}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:04:23,760] Trial 123 finished with value: 0.7212548077860556 and parameters: {'n_estimators': 1000, 'learning_rate': 0.016368018651485062, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.8092675087007557, 'colsample_bytree': 0.6109118453063259, 'gamma': 0.3075132459788563}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:07:35,501] Trial 124 finished with value: 0.7191237928555119 and parameters: {'n_estimators': 900, 'learning_rate': 0.012372737893732033, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.7973850438073449, 'colsample_bytree': 0.5611932934381306, 'gamma': 0.007160871176531469}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:09:59,651] Trial 125 finished with value: 0.7223262542760709 and parameters: {'n_estimators': 1000, 'learning_rate': 0.025867743577207475, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6519587919112321, 'colsample_bytree': 0.6398150778245422, 'gamma': 0.6398807218293476}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:12:08,074] Trial 126 finished with value: 0.7223976081963397 and parameters: {'n_estimators': 900, 'learning_rate': 0.025919688884555828, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6541266918681055, 'colsample_bytree': 0.6476798179108423, 'gamma': 0.8856274260980451}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:14:00,266] Trial 127 finished with value: 0.7212797510804265 and parameters: {'n_estimators': 800, 'learning_rate': 0.028029296609336132, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7053335208688166, 'colsample_bytree': 0.5125405702522484, 'gamma': 0.9714051879954042}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:16:24,801] Trial 128 finished with value: 0.72326350768902 and parameters: {'n_estimators': 1000, 'learning_rate': 0.026213272033558388, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6570622388160251, 'colsample_bytree': 0.5798832769659188, 'gamma': 1.3331723365292645}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:18:45,184] Trial 129 finished with value: 0.7239595038834798 and parameters: {'n_estimators': 1000, 'learning_rate': 0.025946382536092043, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6748517586087464, 'colsample_bytree': 0.6442731825181105, 'gamma': 1.2182460608266077}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:21:04,819] Trial 130 finished with value: 0.7221296621778788 and parameters: {'n_estimators': 1000, 'learning_rate': 0.030803673942450597, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6530358755656936, 'colsample_bytree': 0.6379767559770978, 'gamma': 1.3394818026972863}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:23:25,302] Trial 131 finished with value: 0.7235119367898116 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02624102458132135, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6756225216617014, 'colsample_bytree': 0.6615782152223957, 'gamma': 1.1932963846362838}. Best is trial 71 with value: 0.7245423313347741.\n",
      "[I 2024-11-11 05:25:46,168] Trial 132 finished with value: 0.7252440006884955 and parameters: {'n_estimators': 1000, 'learning_rate': 0.027075406407767497, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6789816859997232, 'colsample_bytree': 0.6682531834544282, 'gamma': 1.5046881781916308}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:28:05,752] Trial 133 finished with value: 0.7216636095987925 and parameters: {'n_estimators': 1000, 'learning_rate': 0.029079328317244735, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6904156730172616, 'colsample_bytree': 0.6634508829480975, 'gamma': 1.4737139162174093}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:30:27,053] Trial 134 finished with value: 0.7230368420322384 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02532629705133005, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6676626792839813, 'colsample_bytree': 0.6823893851066153, 'gamma': 1.1427423104421996}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:32:53,390] Trial 135 finished with value: 0.7240295674158927 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024044687971065192, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6749517871730653, 'colsample_bytree': 0.6867903228786824, 'gamma': 1.1851097397318324}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:35:13,680] Trial 136 finished with value: 0.7237355353273491 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024364862440572635, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6745798308076213, 'colsample_bytree': 0.687268332057131, 'gamma': 1.26773241347282}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:37:33,388] Trial 137 finished with value: 0.7238189135999915 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024719819992630357, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6763435401859468, 'colsample_bytree': 0.6853379765141354, 'gamma': 1.2606604870022606}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:39:53,405] Trial 138 finished with value: 0.7221006060105409 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024935902631649767, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6716645613139532, 'colsample_bytree': 0.6808355348973594, 'gamma': 1.2575917807782966}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:42:13,832] Trial 139 finished with value: 0.7218758386624171 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022995748947878373, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6951483498709032, 'colsample_bytree': 0.690381642823056, 'gamma': 1.6135241936456755}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:44:35,869] Trial 140 finished with value: 0.7215974609405025 and parameters: {'n_estimators': 1000, 'learning_rate': 0.020705344271979734, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6751618747502041, 'colsample_bytree': 0.6745579729387651, 'gamma': 1.1429297583316251}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:47:01,215] Trial 141 finished with value: 0.7234856947801844 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024684754541048442, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6654073342649576, 'colsample_bytree': 0.6913556980537838, 'gamma': 1.4047913335011462}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:49:21,954] Trial 142 finished with value: 0.7230846277644961 and parameters: {'n_estimators': 1000, 'learning_rate': 0.026561596844534817, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6772398135296628, 'colsample_bytree': 0.703655510116067, 'gamma': 1.4002329320337348}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:51:42,536] Trial 143 finished with value: 0.7224625677089251 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02679865657388534, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6695656085155637, 'colsample_bytree': 0.7256937551525107, 'gamma': 1.4187619085285947}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:54:03,285] Trial 144 finished with value: 0.7234792509994982 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024275468360390275, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6810106108805747, 'colsample_bytree': 0.6960884579618235, 'gamma': 1.3100682407937974}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:56:24,595] Trial 145 finished with value: 0.7221311621632553 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024158398290271426, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6990021638695284, 'colsample_bytree': 0.7034114455465856, 'gamma': 1.3317808192354799}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 05:58:44,920] Trial 146 finished with value: 0.7219345442469249 and parameters: {'n_estimators': 1000, 'learning_rate': 0.026592385300754976, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6785034198043013, 'colsample_bytree': 0.6917705473629547, 'gamma': 1.5444728045373974}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:01:06,924] Trial 147 finished with value: 0.724614017086582 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02329447410383919, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6841672455041489, 'colsample_bytree': 0.7074922245302604, 'gamma': 1.2606428078036485}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:03:33,618] Trial 148 finished with value: 0.7216926912628846 and parameters: {'n_estimators': 1000, 'learning_rate': 0.021594487608610803, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.685141416074395, 'colsample_bytree': 0.6988989845643124, 'gamma': 1.7117809803805726}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:05:56,662] Trial 149 finished with value: 0.7224772936259125 and parameters: {'n_estimators': 1000, 'learning_rate': 0.023299729727482756, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.679827859798324, 'colsample_bytree': 0.7145666690118079, 'gamma': 1.2509538763441672}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:08:00,154] Trial 150 finished with value: 0.7194405408266558 and parameters: {'n_estimators': 1000, 'learning_rate': 0.031580217365409405, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.7192635296687909, 'colsample_bytree': 0.7388612369105219, 'gamma': 1.831104762131103}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:10:21,114] Trial 151 finished with value: 0.7209758060344319 and parameters: {'n_estimators': 1000, 'learning_rate': 0.025324438472712468, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6937318657203513, 'colsample_bytree': 0.6831038068481434, 'gamma': 1.1249877607436376}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:12:40,528] Trial 152 finished with value: 0.7223335996244822 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02813211944876138, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.665900942036217, 'colsample_bytree': 0.705097096497968, 'gamma': 1.5313301069172809}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:15:01,004] Trial 153 finished with value: 0.7225318998779976 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02426672530622801, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.7046297801669981, 'colsample_bytree': 0.673549628341797, 'gamma': 1.21028026238419}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:17:22,372] Trial 154 finished with value: 0.7232810832110774 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02232929698386301, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6847676611667556, 'colsample_bytree': 0.7259990158394776, 'gamma': 1.363445527778057}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:19:50,508] Trial 155 finished with value: 0.7226882155989811 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022004061352899236, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6782501030686066, 'colsample_bytree': 0.7222747678802237, 'gamma': 1.3999284437282253}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:21:56,714] Trial 156 finished with value: 0.7225797760402738 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02065005811246026, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.6870357496356029, 'colsample_bytree': 0.7300537081335798, 'gamma': 1.2878053611723166}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:24:16,508] Trial 157 finished with value: 0.722311440305131 and parameters: {'n_estimators': 1000, 'learning_rate': 0.027119381823936056, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6944973337557352, 'colsample_bytree': 0.7116051801384996, 'gamma': 1.4536760520381478}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:26:40,964] Trial 158 finished with value: 0.7238366718165767 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022793556774280518, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6641349773637237, 'colsample_bytree': 0.6635257036046011, 'gamma': 1.0458172095025322}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:29:02,570] Trial 159 finished with value: 0.7237581931321081 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02304462680188725, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6771244736763266, 'colsample_bytree': 0.6637948680512019, 'gamma': 1.0278098966554108}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:31:25,174] Trial 160 finished with value: 0.7224509073967076 and parameters: {'n_estimators': 1000, 'learning_rate': 0.019866996809527016, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6600447393792823, 'colsample_bytree': 0.6632501687426838, 'gamma': 1.0388280230891211}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:33:51,730] Trial 161 finished with value: 0.7224526208384283 and parameters: {'n_estimators': 1000, 'learning_rate': 0.023833379493054647, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6807062066111185, 'colsample_bytree': 0.6904824656028121, 'gamma': 1.3354397258681638}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:36:13,026] Trial 162 finished with value: 0.7216839719830257 and parameters: {'n_estimators': 1000, 'learning_rate': 0.021188912060231938, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6662062564560655, 'colsample_bytree': 0.6562667230094018, 'gamma': 1.1014194016925904}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:38:33,430] Trial 163 finished with value: 0.7225040596008712 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02306441825912718, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6850971396644094, 'colsample_bytree': 0.6731759343722274, 'gamma': 1.2112581815306456}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:40:52,861] Trial 164 finished with value: 0.7220525687936928 and parameters: {'n_estimators': 1000, 'learning_rate': 0.028945100557297408, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6725427138706027, 'colsample_bytree': 0.6967468361728687, 'gamma': 1.4138569788805495}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:43:14,459] Trial 165 finished with value: 0.7202268087549845 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022171571766394324, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.702326100049214, 'colsample_bytree': 0.666409368049857, 'gamma': 1.203887852935092}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:45:33,101] Trial 166 finished with value: 0.7214831785405715 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02597697809060618, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.7166542070531079, 'colsample_bytree': 0.6872998822399463, 'gamma': 1.0252132313764373}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:47:57,168] Trial 167 finished with value: 0.7212824432001395 and parameters: {'n_estimators': 1000, 'learning_rate': 0.018766893539754997, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6430475113232967, 'colsample_bytree': 0.701951695573082, 'gamma': 1.2945633206111893}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:50:24,571] Trial 168 finished with value: 0.7220724761681948 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024411557102046167, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6636430092751752, 'colsample_bytree': 0.7457700177496532, 'gamma': 1.6339316986312007}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:52:42,683] Trial 169 finished with value: 0.7109965789098415 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08772795337013284, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6907295643699264, 'colsample_bytree': 0.6661632858163999, 'gamma': 1.487637536800643}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:55:02,482] Trial 170 finished with value: 0.7238473301820533 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022483795736646613, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6749221287804794, 'colsample_bytree': 0.6500505481865225, 'gamma': 0.9855759449225586}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:57:23,284] Trial 171 finished with value: 0.7230383311455684 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02289964129218822, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6760366029810068, 'colsample_bytree': 0.654047652423193, 'gamma': 0.9609113532311038}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 06:59:42,442] Trial 172 finished with value: 0.72211310498319 and parameters: {'n_estimators': 1000, 'learning_rate': 0.026988527400105308, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6584056790881959, 'colsample_bytree': 0.6465008837917703, 'gamma': 1.1136723976183331}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:01:02,972] Trial 173 finished with value: 0.7180580985713508 and parameters: {'n_estimators': 500, 'learning_rate': 0.020292578180636192, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6840245832875971, 'colsample_bytree': 0.680609764238291, 'gamma': 1.3430047220513464}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:03:23,542] Trial 174 finished with value: 0.7240401130552674 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02490226788537737, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.700663590868069, 'colsample_bytree': 0.7197796709100962, 'gamma': 1.2196997727306707}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:04:11,506] Trial 175 finished with value: 0.7074567204688093 and parameters: {'n_estimators': 200, 'learning_rate': 0.02177630292403933, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6960892851959253, 'colsample_bytree': 0.71870017959749, 'gamma': 1.0603598673528964}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:06:31,238] Trial 176 finished with value: 0.7201890063771355 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024599441598818363, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.7083541170732615, 'colsample_bytree': 0.6605658875967523, 'gamma': 1.1834417312453096}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:08:50,901] Trial 177 finished with value: 0.723115617395304 and parameters: {'n_estimators': 1000, 'learning_rate': 0.03043102738863264, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6512511198706945, 'colsample_bytree': 0.675705138135851, 'gamma': 0.9201502286137532}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:11:09,820] Trial 178 finished with value: 0.7206043800514582 and parameters: {'n_estimators': 1000, 'learning_rate': 0.031131305865794896, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6472316466636456, 'colsample_bytree': 0.6784310163895565, 'gamma': 0.9678480187365089}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:13:29,416] Trial 179 finished with value: 0.7220513496234815 and parameters: {'n_estimators': 1000, 'learning_rate': 0.028428414551954894, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.669637608028216, 'colsample_bytree': 0.689920739433893, 'gamma': 0.8965048325402554}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:15:50,385] Trial 180 finished with value: 0.7228893912168651 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024006794175860654, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6359427212567267, 'colsample_bytree': 0.6696777123294285, 'gamma': 1.2452339766012677}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:18:13,048] Trial 181 finished with value: 0.7235746737868747 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022917229513893387, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6507965906389029, 'colsample_bytree': 0.7307764181169168, 'gamma': 1.1610039510356858}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:20:40,560] Trial 182 finished with value: 0.7242751019949396 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022727009890450088, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6583627137962974, 'colsample_bytree': 0.7304040844489952, 'gamma': 1.153913149752889}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:23:03,425] Trial 183 finished with value: 0.7221303474306155 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022295552116044896, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6606249740248713, 'colsample_bytree': 0.7322950496417395, 'gamma': 1.0825369443326818}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:25:23,118] Trial 184 finished with value: 0.7248533882369161 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02081102469202751, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6633756326808657, 'colsample_bytree': 0.7210899002875849, 'gamma': 1.1696327947085383}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:27:47,196] Trial 185 finished with value: 0.7237307623786166 and parameters: {'n_estimators': 1000, 'learning_rate': 0.018668559827687194, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6737283788483268, 'colsample_bytree': 0.7499092425390249, 'gamma': 1.1783165172417995}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[I 2024-11-11 07:30:08,608] Trial 186 finished with value: 0.7227359519728955 and parameters: {'n_estimators': 1000, 'learning_rate': 0.018952388904076193, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6716654424282298, 'colsample_bytree': 0.7143625872246199, 'gamma': 1.1635950447801873}. Best is trial 132 with value: 0.7252440006884955.\n",
      "[W 2024-11-11 07:31:30,835] Trial 187 failed with parameters: {'n_estimators': 1000, 'learning_rate': 0.01975582512367924, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6424926443015238, 'colsample_bytree': 0.7629228029961233, 'gamma': 1.0195201271895287} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_10352\\2126418380.py\", line 24, in __call__\n",
      "    score = cross_val_score(model, self.x, self.y, cv= self.cv, scoring= \"f1_macro\", n_jobs= -1).mean()\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 712, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 423, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-11 07:31:30,838] Trial 187 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# optimize 매서드 실행\u001b[39;00m\n\u001b[0;32m     34\u001b[0m objective_func \u001b[38;5;241m=\u001b[39m Objective(train_ft, target, SEED)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m, in \u001b[0;36mObjective.__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     16\u001b[0m hp \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m)  }\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhp, random_state\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)    \n\u001b[1;32m---> 24\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1_macro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 목적함수를 클래스로 만들기\n",
    "class Objective:\n",
    "    # 변수 설정\n",
    "    def __init__(self, x, y, seed):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.seed = seed\n",
    "        self.cv = StratifiedKFold(5, shuffle= True, random_state= self.seed)\n",
    "\n",
    "    def __call__(self, trial):  # 콜백함수 역할\n",
    "        hp = {  \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "                \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                \"gamma\": trial.suggest_float(\"gamma\", 0, 5)  }\n",
    "        model = XGBClassifier(**hp, random_state= self.seed)    \n",
    "        score = cross_val_score(model, self.x, self.y, cv= self.cv, scoring= \"f1_macro\", n_jobs= -1).mean()\n",
    "        return score\n",
    "\n",
    "# Sampler 객체 생성(대체모델 역할)\n",
    "sampler = optuna.samplers.TPESampler(seed= SEED)\n",
    "\n",
    "# study 객체 생성\n",
    "study = optuna.create_study(direction= \"maximize\", sampler= sampler)\n",
    "\n",
    "# optimize 매서드 실행\n",
    "objective_func = Objective(train_ft, target, SEED)\n",
    "study.optimize(objective_func, n_trials= 500) \n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'learning_rate': 0.027075406407767497,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 7,\n",
       " 'subsample': 0.6789816859997232,\n",
       " 'colsample_bytree': 0.6682531834544282,\n",
       " 'gamma': 1.5046881781916308}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params #0.7252440006884955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Macro Score: 0.7216530444546538\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "# F1 매크로 스코어와 모델을 저장할 리스트\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "# Stratified K-Fold 교차 검증 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 루프\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "    # 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "\n",
    "    # 모델 초기화 및 학습\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)   \n",
    "    \n",
    "    # 모델 저장\n",
    "    models.append(model)\n",
    "\n",
    "    # 예측 및 F1 매크로 스코어 계산\n",
    "    pred = model.predict(x_valid)\n",
    "    score = f1_score(y_valid, pred, average='macro')\n",
    "    scores.append(score)\n",
    "\n",
    "# F1 매크로 스코어의 평균 출력\n",
    "print(\"Mean F1 Macro Score:\", np.mean(scores))\n",
    "\n",
    "\n",
    "# v3.0 : 0.7211477612229629\n",
    "# v3.2_피처삭제X_군집분석 : 0.7216530444546538\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "pred_proba = []\n",
    "models = []\n",
    "\n",
    "# Stratified K-Fold 교차 검증 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 루프\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "    # 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "\n",
    "    # 모델 초기화 및 학습\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)   \n",
    "    \n",
    "    # 모델 저장\n",
    "    models.append(model)\n",
    "\n",
    "    # 예측 및 F1 매크로 스코어 계산\n",
    "    pred_proba.append(model.predict_proba(x_valid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2988, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.mean(\n",
    "        [   pred_proba[0],\n",
    "            pred_proba[1],\n",
    "            pred_proba[2],\n",
    "            pred_proba[3],\n",
    "            pred_proba[4],\n",
    "            \n",
    "            ],axis=0)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 임계값: 0.41\n",
      "F1 Score (최적): 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.288499</td>\n",
       "      <td>0.393950</td>\n",
       "      <td>0.998296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.290155</td>\n",
       "      <td>0.394143</td>\n",
       "      <td>0.997445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.293806</td>\n",
       "      <td>0.394941</td>\n",
       "      <td>0.997445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.299846</td>\n",
       "      <td>0.396277</td>\n",
       "      <td>0.997445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.302662</td>\n",
       "      <td>0.396745</td>\n",
       "      <td>0.996593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.307839</td>\n",
       "      <td>0.397754</td>\n",
       "      <td>0.995741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.314142</td>\n",
       "      <td>0.399043</td>\n",
       "      <td>0.994889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.320761</td>\n",
       "      <td>0.399794</td>\n",
       "      <td>0.990630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.325344</td>\n",
       "      <td>0.399931</td>\n",
       "      <td>0.985520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.333791</td>\n",
       "      <td>0.401045</td>\n",
       "      <td>0.980409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.345904</td>\n",
       "      <td>0.403169</td>\n",
       "      <td>0.975298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.357356</td>\n",
       "      <td>0.404635</td>\n",
       "      <td>0.966780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.374973</td>\n",
       "      <td>0.408894</td>\n",
       "      <td>0.963373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.412605</td>\n",
       "      <td>0.959114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.408123</td>\n",
       "      <td>0.416511</td>\n",
       "      <td>0.949744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.422031</td>\n",
       "      <td>0.418543</td>\n",
       "      <td>0.934412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.433979</td>\n",
       "      <td>0.419821</td>\n",
       "      <td>0.916525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.448155</td>\n",
       "      <td>0.422400</td>\n",
       "      <td>0.899489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.458890</td>\n",
       "      <td>0.423409</td>\n",
       "      <td>0.878194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.478175</td>\n",
       "      <td>0.429839</td>\n",
       "      <td>0.866269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.491290</td>\n",
       "      <td>0.431838</td>\n",
       "      <td>0.836457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.512657</td>\n",
       "      <td>0.440895</td>\n",
       "      <td>0.822828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.527308</td>\n",
       "      <td>0.446036</td>\n",
       "      <td>0.795571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.765758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.549634</td>\n",
       "      <td>0.455729</td>\n",
       "      <td>0.745315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.560905</td>\n",
       "      <td>0.462171</td>\n",
       "      <td>0.718058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.474048</td>\n",
       "      <td>0.700170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.591204</td>\n",
       "      <td>0.486834</td>\n",
       "      <td>0.677172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.598006</td>\n",
       "      <td>0.494758</td>\n",
       "      <td>0.643101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.598733</td>\n",
       "      <td>0.497914</td>\n",
       "      <td>0.609881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.597726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.578365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.600844</td>\n",
       "      <td>0.508274</td>\n",
       "      <td>0.549404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.600178</td>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.512777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.598250</td>\n",
       "      <td>0.523005</td>\n",
       "      <td>0.474446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.593620</td>\n",
       "      <td>0.530083</td>\n",
       "      <td>0.435264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.588068</td>\n",
       "      <td>0.537931</td>\n",
       "      <td>0.398637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.579623</td>\n",
       "      <td>0.538653</td>\n",
       "      <td>0.367973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.569874</td>\n",
       "      <td>0.538881</td>\n",
       "      <td>0.336457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.560762</td>\n",
       "      <td>0.544073</td>\n",
       "      <td>0.304940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.556201</td>\n",
       "      <td>0.562607</td>\n",
       "      <td>0.279387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.547915</td>\n",
       "      <td>0.568998</td>\n",
       "      <td>0.256388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.538875</td>\n",
       "      <td>0.582796</td>\n",
       "      <td>0.230835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.530227</td>\n",
       "      <td>0.600985</td>\n",
       "      <td>0.207836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.509860</td>\n",
       "      <td>0.589080</td>\n",
       "      <td>0.174617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.497743</td>\n",
       "      <td>0.589577</td>\n",
       "      <td>0.154174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.485123</td>\n",
       "      <td>0.592453</td>\n",
       "      <td>0.133731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.472753</td>\n",
       "      <td>0.594714</td>\n",
       "      <td>0.114991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.467307</td>\n",
       "      <td>0.610837</td>\n",
       "      <td>0.105622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.458583</td>\n",
       "      <td>0.622857</td>\n",
       "      <td>0.092845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.451028</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.081772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.439646</td>\n",
       "      <td>0.678261</td>\n",
       "      <td>0.066440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.433710</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.058773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.426930</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.050256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.420131</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.042589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.410655</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.033220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.406912</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.028961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.401187</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.393283</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.015332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.390856</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.012777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.388409</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.010221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.387772</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.009370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.386857</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.008518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.385158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.382394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.380544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.379617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.378689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.378689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.378689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold        F1  Precision    Recall\n",
       "0        0.10  0.288499   0.393950  0.998296\n",
       "1        0.11  0.290155   0.394143  0.997445\n",
       "2        0.12  0.293806   0.394941  0.997445\n",
       "3        0.13  0.299846   0.396277  0.997445\n",
       "4        0.14  0.302662   0.396745  0.996593\n",
       "5        0.15  0.307839   0.397754  0.995741\n",
       "6        0.16  0.314142   0.399043  0.994889\n",
       "7        0.17  0.320761   0.399794  0.990630\n",
       "8        0.18  0.325344   0.399931  0.985520\n",
       "9        0.19  0.333791   0.401045  0.980409\n",
       "10       0.20  0.345904   0.403169  0.975298\n",
       "11       0.21  0.357356   0.404635  0.966780\n",
       "12       0.22  0.374973   0.408894  0.963373\n",
       "13       0.23  0.390281   0.412605  0.959114\n",
       "14       0.24  0.408123   0.416511  0.949744\n",
       "15       0.25  0.422031   0.418543  0.934412\n",
       "16       0.26  0.433979   0.419821  0.916525\n",
       "17       0.27  0.448155   0.422400  0.899489\n",
       "18       0.28  0.458890   0.423409  0.878194\n",
       "19       0.29  0.478175   0.429839  0.866269\n",
       "20       0.30  0.491290   0.431838  0.836457\n",
       "21       0.31  0.512657   0.440895  0.822828\n",
       "22       0.32  0.527308   0.446036  0.795571\n",
       "23       0.33  0.537700   0.449500  0.765758\n",
       "24       0.34  0.549634   0.455729  0.745315\n",
       "25       0.35  0.560905   0.462171  0.718058\n",
       "26       0.36  0.576671   0.474048  0.700170\n",
       "27       0.37  0.591204   0.486834  0.677172\n",
       "28       0.38  0.598006   0.494758  0.643101\n",
       "29       0.39  0.598733   0.497914  0.609881\n",
       "30       0.40  0.597726   0.500000  0.578365\n",
       "31       0.41  0.600844   0.508274  0.549404\n",
       "32       0.42  0.600178   0.514970  0.512777\n",
       "33       0.43  0.598250   0.523005  0.474446\n",
       "34       0.44  0.593620   0.530083  0.435264\n",
       "35       0.45  0.588068   0.537931  0.398637\n",
       "36       0.46  0.579623   0.538653  0.367973\n",
       "37       0.47  0.569874   0.538881  0.336457\n",
       "38       0.48  0.560762   0.544073  0.304940\n",
       "39       0.49  0.556201   0.562607  0.279387\n",
       "40       0.50  0.547915   0.568998  0.256388\n",
       "41       0.51  0.538875   0.582796  0.230835\n",
       "42       0.52  0.530227   0.600985  0.207836\n",
       "43       0.53  0.509860   0.589080  0.174617\n",
       "44       0.54  0.497743   0.589577  0.154174\n",
       "45       0.55  0.485123   0.592453  0.133731\n",
       "46       0.56  0.472753   0.594714  0.114991\n",
       "47       0.57  0.467307   0.610837  0.105622\n",
       "48       0.58  0.458583   0.622857  0.092845\n",
       "49       0.59  0.451028   0.644295  0.081772\n",
       "50       0.60  0.439646   0.678261  0.066440\n",
       "51       0.61  0.433710   0.704082  0.058773\n",
       "52       0.62  0.426930   0.746835  0.050256\n",
       "53       0.63  0.420131   0.769231  0.042589\n",
       "54       0.64  0.410655   0.722222  0.033220\n",
       "55       0.65  0.406912   0.755556  0.028961\n",
       "56       0.66  0.401187   0.771429  0.022998\n",
       "57       0.67  0.393283   0.720000  0.015332\n",
       "58       0.68  0.390856   0.750000  0.012777\n",
       "59       0.69  0.388409   0.800000  0.010221\n",
       "60       0.70  0.387772   0.916667  0.009370\n",
       "61       0.71  0.386857   0.909091  0.008518\n",
       "62       0.72  0.385158   1.000000  0.006814\n",
       "63       0.73  0.382394   1.000000  0.004259\n",
       "64       0.74  0.380544   1.000000  0.002555\n",
       "65       0.75  0.379617   1.000000  0.001704\n",
       "66       0.76  0.378689   1.000000  0.000852\n",
       "67       0.77  0.378689   1.000000  0.000852\n",
       "68       0.78  0.378689   1.000000  0.000852\n",
       "69       0.79  0.377759   0.000000  0.000000\n",
       "70       0.80  0.377759   0.000000  0.000000\n",
       "71       0.81  0.377759   0.000000  0.000000\n",
       "72       0.82  0.377759   0.000000  0.000000\n",
       "73       0.83  0.377759   0.000000  0.000000\n",
       "74       0.84  0.377759   0.000000  0.000000\n",
       "75       0.85  0.377759   0.000000  0.000000\n",
       "76       0.86  0.377759   0.000000  0.000000\n",
       "77       0.87  0.377759   0.000000  0.000000\n",
       "78       0.88  0.377759   0.000000  0.000000\n",
       "79       0.89  0.377759   0.000000  0.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# 모델 예측 확률값 (예: predict_proba 결과)\n",
    "proba = pred[:, 1]  # 양성 클래스의 확률값\n",
    "y_true = y_valid  # 실제 타겟값\n",
    "\n",
    "# 임계값 범위 설정\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# 각 임계값에서의 성능 저장\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # 확률값 기반으로 예측 생성\n",
    "    y_pred = (proba >= threshold).astype(int)\n",
    "    \n",
    "    # 성능 지표 계산 (F1, Precision, Recall)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    results.append((threshold, f1, precision, recall))\n",
    "\n",
    "# 최적 임계값 찾기 (F1 기준)\n",
    "best_threshold, best_f1, _, _ = max(results, key=lambda x: x[1])\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"최적 임계값: {best_threshold:.2f}\")\n",
    "print(f\"F1 Score (최적): {best_f1:.4f}\")\n",
    "\n",
    "# 결과를 데이터프레임으로 정리 (선택사항)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "results_df = pd.DataFrame(results, columns=['Threshold', 'F1', 'Precision', 'Recall'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 1000,\n",
    " 'learning_rate': 0.027075406407767497,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.6789816859997232,\n",
    " 'colsample_bytree': 0.6682531834544282,\n",
    " 'gamma': 1.5046881781916308}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "model.fit(train_ft, target)\n",
    "pred = model.predict(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test_ft)[:,1]\n",
    "submit[\"target\"] = pred\n",
    "submit.to_csv(\"v3.0_XGB_cluster_proba.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_proba(test_ft)[:,1]\n",
    "pred = (pred >= 0.41).astype(int)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = pred\n",
    "submit.to_csv(\"v3.0_XGB_cluster_0.41.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
