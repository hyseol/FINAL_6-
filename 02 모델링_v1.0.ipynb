{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1qAeLjZVWZz"
   },
   "source": [
    "- 시드값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nVyhJ6uOVVNE"
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd7JpzNBHa1"
   },
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KFGKUIWt89fZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523105, 7), (14940, 2), (441196, 7), (12225, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Data/\"\n",
    "\n",
    "train_tr = pd.read_csv(f\"{DATA_PATH}store_train_transactions.csv\") # 학습용 구매기록 데이터\n",
    "train_target = pd.read_csv(f\"{DATA_PATH}store_train.csv\") # 학습용 정답 데이터\n",
    "test_tr = pd.read_csv(f\"{DATA_PATH}store_test_transactions.csv\") # 테스트용 구매기록 데이터\n",
    "submit = pd.read_csv(f\"{DATA_PATH}store_submission.csv\") # 제출 양식 데이터\n",
    "\n",
    "train_tr.shape , train_target.shape , test_tr.shape , submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZq4x4CuP2gr"
   },
   "source": [
    "- 공통 피처 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NfX2HPof87FT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 465), (12225, 465))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv/\"\n",
    "\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v2.0_1101.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v2.0_1101.csv\")\n",
    "\n",
    "train_ft.shape , test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r43SCHUujW-f"
   },
   "source": [
    "# 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.isnull().sum().sum(), test_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgPa4QG0RF2d"
   },
   "source": [
    "# 특성 공학(Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXuo6unbRLGm"
   },
   "source": [
    "- ID 변수 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xfksFVguRFuZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 464), (12225, 464))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.iloc[:,1:]\n",
    "test_ft = test_ft.iloc[:,1:]\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjuSj8URRa_q"
   },
   "source": [
    "- 추가 피처 만들어 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXvdNLMtSVlW"
   },
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0YvdL9OVSRab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주구매지점              4\n",
       "주구매_중분류          246\n",
       "주구매_대분류_수정         7\n",
       "대분류_수정_평균금액최대      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KBjgGRGESRTl"
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3d6B3II8T25p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 728), (12225, 728))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = ce.one_hot.OneHotEncoder()\n",
    "tmp = enc.fit_transform(train_ft[cols])\n",
    "train_ft = pd.concat([train_ft,tmp],axis =1)\n",
    "\n",
    "tmp = enc.transform(test_ft[cols])\n",
    "test_ft = pd.concat([test_ft,tmp],axis =1)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0ztgmEMRFpN"
   },
   "outputs": [],
   "source": [
    "# enc = ce.count.CountEncoder()\n",
    "# train_ft[\"주구매_중분류_cnt\"] = enc.fit_transform(train_ft[[\"주구매_중분류\"]])\n",
    "# test_ft[\"주구매_중분류_cnt\"] = enc.transform(test_ft[[\"주구매_중분류\"]])\n",
    "\n",
    "# train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPURwRnPUj-B"
   },
   "source": [
    "- 문자열 피처 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "suLVrqBCRFmK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['주구매지점', '주구매_중분류', '주구매_대분류_수정', '대분류_수정_평균금액최대']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zZlZoAMZUbGp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 724), (12225, 724))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_ft.drop(columns=cols)\n",
    "test_ft = test_ft.drop(columns=cols)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1-y4-kmTUmso"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object'), Index([], dtype='object'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.select_dtypes(\"object\").columns , test_ft.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAQ-3TU5U0Pk"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2_ywU--RUmp7"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vyDpuu4OUmnO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>내점일수</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>봄_구매비율</th>\n",
       "      <th>여름_구매비율</th>\n",
       "      <th>가을_구매비율</th>\n",
       "      <th>겨울_구매비율</th>\n",
       "      <th>주구매요일</th>\n",
       "      <th>일별평균구매건수</th>\n",
       "      <th>거래개월수</th>\n",
       "      <th>...</th>\n",
       "      <th>주구매_대분류_수정_5</th>\n",
       "      <th>주구매_대분류_수정_6</th>\n",
       "      <th>주구매_대분류_수정_7</th>\n",
       "      <th>대분류_수정_평균금액최대_1</th>\n",
       "      <th>대분류_수정_평균금액최대_2</th>\n",
       "      <th>대분류_수정_평균금액최대_3</th>\n",
       "      <th>대분류_수정_평균금액최대_4</th>\n",
       "      <th>대분류_수정_평균금액최대_5</th>\n",
       "      <th>대분류_수정_평균금액최대_6</th>\n",
       "      <th>대분류_수정_평균금액최대_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369867</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.257728</td>\n",
       "      <td>-1.029777</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.838272</td>\n",
       "      <td>0.338186</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>-0.057297</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154203</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.187997</td>\n",
       "      <td>2.553208</td>\n",
       "      <td>-0.443004</td>\n",
       "      <td>-0.816155</td>\n",
       "      <td>-0.341822</td>\n",
       "      <td>-0.345596</td>\n",
       "      <td>-0.274521</td>\n",
       "      <td>-0.149122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144110</td>\n",
       "      <td>-0.356452</td>\n",
       "      <td>-1.008554</td>\n",
       "      <td>0.323951</td>\n",
       "      <td>-0.390607</td>\n",
       "      <td>0.620171</td>\n",
       "      <td>-0.552996</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>0.222706</td>\n",
       "      <td>1.176010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154203</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.187997</td>\n",
       "      <td>-0.391664</td>\n",
       "      <td>2.257315</td>\n",
       "      <td>-0.816155</td>\n",
       "      <td>-0.341822</td>\n",
       "      <td>-0.345596</td>\n",
       "      <td>-0.274521</td>\n",
       "      <td>-0.149122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.943028</td>\n",
       "      <td>-0.869935</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.798943</td>\n",
       "      <td>-0.514333</td>\n",
       "      <td>-0.304527</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>-1.643370</td>\n",
       "      <td>0.277707</td>\n",
       "      <td>1.465608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154203</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.187997</td>\n",
       "      <td>-0.391664</td>\n",
       "      <td>2.257315</td>\n",
       "      <td>-0.816155</td>\n",
       "      <td>-0.341822</td>\n",
       "      <td>-0.345596</td>\n",
       "      <td>-0.274521</td>\n",
       "      <td>-0.149122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.793345</td>\n",
       "      <td>-1.023980</td>\n",
       "      <td>-0.080558</td>\n",
       "      <td>0.420933</td>\n",
       "      <td>-0.327474</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>-0.135636</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>0.674668</td>\n",
       "      <td>1.465608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154203</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.187997</td>\n",
       "      <td>-0.391664</td>\n",
       "      <td>-0.443004</td>\n",
       "      <td>1.225257</td>\n",
       "      <td>-0.341822</td>\n",
       "      <td>-0.345596</td>\n",
       "      <td>-0.274521</td>\n",
       "      <td>-0.149122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452496</td>\n",
       "      <td>-0.613193</td>\n",
       "      <td>0.302875</td>\n",
       "      <td>-0.752532</td>\n",
       "      <td>1.707410</td>\n",
       "      <td>-0.130285</td>\n",
       "      <td>-0.821561</td>\n",
       "      <td>0.693965</td>\n",
       "      <td>0.679008</td>\n",
       "      <td>0.886413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154203</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.187997</td>\n",
       "      <td>-0.391664</td>\n",
       "      <td>2.257315</td>\n",
       "      <td>-0.816155</td>\n",
       "      <td>-0.341822</td>\n",
       "      <td>-0.345596</td>\n",
       "      <td>-0.274521</td>\n",
       "      <td>-0.149122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       내점일수      구매주기    주말방문비율    봄_구매비율   여름_구매비율   가을_구매비율   겨울_구매비율  \\\n",
       "0 -0.369867  0.002987  0.257728 -1.029777  0.001191  0.838272  0.338186   \n",
       "1  0.144110 -0.356452 -1.008554  0.323951 -0.390607  0.620171 -0.552996   \n",
       "2  1.943028 -0.869935  0.036742  0.798943 -0.514333 -0.304527 -0.059266   \n",
       "3  3.793345 -1.023980 -0.080558  0.420933 -0.327474  0.008592 -0.135636   \n",
       "4  0.452496 -0.613193  0.302875 -0.752532  1.707410 -0.130285 -0.821561   \n",
       "\n",
       "      주구매요일  일별평균구매건수     거래개월수  ...  주구매_대분류_수정_5  주구매_대분류_수정_6  \\\n",
       "0  0.109631 -0.057297  0.017620  ...     -0.154203     -0.378716   \n",
       "1  0.109631  0.222706  1.176010  ...     -0.154203     -0.378716   \n",
       "2 -1.643370  0.277707  1.465608  ...     -0.154203     -0.378716   \n",
       "3  0.109631  0.674668  1.465608  ...     -0.154203     -0.378716   \n",
       "4  0.693965  0.679008  0.886413  ...     -0.154203     -0.378716   \n",
       "\n",
       "   주구매_대분류_수정_7  대분류_수정_평균금액최대_1  대분류_수정_평균금액최대_2  대분류_수정_평균금액최대_3  \\\n",
       "0     -0.187997         2.553208        -0.443004        -0.816155   \n",
       "1     -0.187997        -0.391664         2.257315        -0.816155   \n",
       "2     -0.187997        -0.391664         2.257315        -0.816155   \n",
       "3     -0.187997        -0.391664        -0.443004         1.225257   \n",
       "4     -0.187997        -0.391664         2.257315        -0.816155   \n",
       "\n",
       "   대분류_수정_평균금액최대_4  대분류_수정_평균금액최대_5  대분류_수정_평균금액최대_6  대분류_수정_평균금액최대_7  \n",
       "0        -0.341822        -0.345596        -0.274521        -0.149122  \n",
       "1        -0.341822        -0.345596        -0.274521        -0.149122  \n",
       "2        -0.341822        -0.345596        -0.274521        -0.149122  \n",
       "3        -0.341822        -0.345596        -0.274521        -0.149122  \n",
       "4        -0.341822        -0.345596        -0.274521        -0.149122  \n",
       "\n",
       "[5 rows x 724 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)\n",
    "train_ft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlmnx5QsU8_x"
   },
   "source": [
    "# 정답 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sawXnAciUmkJ"
   },
   "outputs": [],
   "source": [
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXinfWehVH4-"
   },
   "source": [
    "# cv 점수 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rY6xQ68PVGwP"
   },
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# model = LGBMClassifier(random_state=SEED)\n",
    "# scores = cross_val_score(model,train_ft,target,cv = cv ,scoring='f1_macro',n_jobs = -1)\n",
    "# np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUfajgtxVdte"
   },
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Macro Score: 0.7166578765340972\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 파라미터 설정\n",
    "params = {\n",
    "    \"random_state\": 42,\n",
    "    \"learning_rate\": 0.1,  # 학습률\n",
    "    \"n_estimators\": 500,   # 트리 개수\n",
    "    \"max_depth\": 5,        # 최대 깊이\n",
    "    \"min_child_weight\": 3, # 최소 자식 가중치\n",
    "    \"subsample\": 0.8,      # 샘플링 비율\n",
    "    \"colsample_bytree\": 0.8, # 특성 샘플링 비율\n",
    "    \"gamma\": 0.1,           # 최소 손실 감소\n",
    "    \"n_jobs\": -1,\n",
    "    \"early_stopping_rounds\": 50,  \n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "\n",
    "# F1 매크로 스코어와 모델을 저장할 리스트\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "# Stratified K-Fold 교차 검증 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 루프\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "    # 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "\n",
    "    # 모델 초기화 및 학습\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)   \n",
    "    \n",
    "    # 모델 저장\n",
    "    models.append(model)\n",
    "\n",
    "    # 예측 및 F1 매크로 스코어 계산\n",
    "    pred = model.predict(x_valid)\n",
    "    score = f1_score(y_valid, pred, average='macro')\n",
    "    scores.append(score)\n",
    "\n",
    "# F1 매크로 스코어의 평균 출력\n",
    "print(\"Mean F1 Macro Score:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 19:52:04,432] A new study created in memory with name: no-name-9fd4df1a-45d5-493a-bf3b-3b4400081050\n",
      "[I 2024-11-01 19:52:40,836] Trial 0 finished with value: 0.6912295212558891 and parameters: {'n_estimators': 400, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'gamma': 0.05808361216819946}. Best is trial 0 with value: 0.6912295212558891.\n",
      "[I 2024-11-01 19:53:49,906] Trial 1 finished with value: 0.710595762870085 and parameters: {'n_estimators': 900, 'learning_rate': 0.07725378389307355, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9849549260809971, 'colsample_bytree': 0.9162213204002109, 'gamma': 0.21233911067827616}. Best is trial 1 with value: 0.710595762870085.\n",
      "[I 2024-11-01 19:54:06,875] Trial 2 finished with value: 0.6991820134892603 and parameters: {'n_estimators': 200, 'learning_rate': 0.018659959624904916, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021, 'gamma': 0.6118528947223795}. Best is trial 1 with value: 0.710595762870085.\n",
      "[I 2024-11-01 19:54:23,112] Trial 3 finished with value: 0.7056841068190524 and parameters: {'n_estimators': 200, 'learning_rate': 0.027010527749605478, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8925879806965068, 'colsample_bytree': 0.5998368910791798, 'gamma': 0.5142344384136116}. Best is trial 1 with value: 0.710595762870085.\n",
      "[I 2024-11-01 19:55:17,388] Trial 4 finished with value: 0.7147711298513587 and parameters: {'n_estimators': 600, 'learning_rate': 0.011711509955524094, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5325257964926398, 'colsample_bytree': 0.9744427686266666, 'gamma': 0.9656320330745594}. Best is trial 4 with value: 0.7147711298513587.\n",
      "[I 2024-11-01 19:55:59,103] Trial 5 finished with value: 0.7167621788478858 and parameters: {'n_estimators': 900, 'learning_rate': 0.028180680291847244, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7200762468698007, 'colsample_bytree': 0.5610191174223894, 'gamma': 0.4951769101112702}. Best is trial 5 with value: 0.7167621788478858.\n",
      "[I 2024-11-01 19:56:09,103] Trial 6 finished with value: 0.7086007867272102 and parameters: {'n_estimators': 100, 'learning_rate': 0.22038218939289875, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6558555380447055, 'colsample_bytree': 0.7600340105889054, 'gamma': 0.5467102793432796}. Best is trial 5 with value: 0.7167621788478858.\n",
      "[I 2024-11-01 19:56:25,669] Trial 7 finished with value: 0.6973300391420411 and parameters: {'n_estimators': 200, 'learning_rate': 0.27051668818999286, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.9474136752138245, 'colsample_bytree': 0.7989499894055425, 'gamma': 0.9218742350231168}. Best is trial 5 with value: 0.7167621788478858.\n",
      "[I 2024-11-01 19:56:35,083] Trial 8 finished with value: 0.6658317486354578 and parameters: {'n_estimators': 100, 'learning_rate': 0.01947558230629543, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.6943386448447411, 'colsample_bytree': 0.6356745158869479, 'gamma': 0.8287375091519293}. Best is trial 5 with value: 0.7167621788478858.\n",
      "[I 2024-11-01 19:57:12,485] Trial 9 finished with value: 0.7140388759855025 and parameters: {'n_estimators': 400, 'learning_rate': 0.026000059117302653, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.5372753218398854, 'gamma': 0.9868869366005173}. Best is trial 5 with value: 0.7167621788478858.\n",
      "[I 2024-11-01 19:57:59,113] Trial 10 finished with value: 0.7179621364871921 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06690992453172917, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8200442512337782, 'colsample_bytree': 0.7032144299581322, 'gamma': 0.3310460817165841}. Best is trial 10 with value: 0.7179621364871921.\n",
      "[I 2024-11-01 19:58:45,291] Trial 11 finished with value: 0.7185958462991818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06438873843712743, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8087272364965106, 'colsample_bytree': 0.7146743022617835, 'gamma': 0.2922384655019864}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 19:59:35,847] Trial 12 finished with value: 0.7143640961560156 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07497377129280611, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.8262949376468329, 'colsample_bytree': 0.6937971020319804, 'gamma': 0.29369471910200906}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 20:00:09,929] Trial 13 finished with value: 0.7115144942394165 and parameters: {'n_estimators': 700, 'learning_rate': 0.13798805957047916, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7788706153624542, 'colsample_bytree': 0.7828849146381794, 'gamma': 0.34279928826631634}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 20:00:51,610] Trial 14 finished with value: 0.7160347685664494 and parameters: {'n_estimators': 800, 'learning_rate': 0.047246527645281526, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.818347963953445, 'colsample_bytree': 0.8317032143059913, 'gamma': 0.08835785888093173}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 20:02:12,286] Trial 15 finished with value: 0.7111234894046403 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05069048828776055, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.8666550582441659, 'colsample_bytree': 0.7019003902676995, 'gamma': 0.39266822275937296}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 20:03:02,671] Trial 16 finished with value: 0.7052008159603298 and parameters: {'n_estimators': 800, 'learning_rate': 0.11821089796829498, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.7897830247330324, 'colsample_bytree': 0.701889798766719, 'gamma': 0.21794048383692277}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 20:03:55,575] Trial 17 finished with value: 0.7090242569211351 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07769073288681376, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.6367232460716616, 'colsample_bytree': 0.865692097533926, 'gamma': 0.6473126265061112}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 20:04:28,989] Trial 18 finished with value: 0.704160800014057 and parameters: {'n_estimators': 500, 'learning_rate': 0.12367070593573347, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.8609727402803516, 'colsample_bytree': 0.7088854312246894, 'gamma': 0.2114651497763769}. Best is trial 11 with value: 0.7185958462991818.\n",
      "[I 2024-11-01 20:05:06,860] Trial 19 finished with value: 0.719794744241646 and parameters: {'n_estimators': 800, 'learning_rate': 0.03753266716490016, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7537458820696782, 'colsample_bytree': 0.6308106484878193, 'gamma': 0.4194273700195608}. Best is trial 19 with value: 0.719794744241646.\n",
      "[I 2024-11-01 20:05:47,793] Trial 20 finished with value: 0.7203311513561246 and parameters: {'n_estimators': 800, 'learning_rate': 0.036284362390569945, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.751016330441914, 'colsample_bytree': 0.5008412707773715, 'gamma': 0.6719070064416731}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:06:29,180] Trial 21 finished with value: 0.7192954376530214 and parameters: {'n_estimators': 800, 'learning_rate': 0.04016388782916413, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7560994041929563, 'colsample_bytree': 0.5061279588967587, 'gamma': 0.7428439518185582}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:07:05,650] Trial 22 finished with value: 0.718281016513151 and parameters: {'n_estimators': 700, 'learning_rate': 0.03999301967629461, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7550494224952119, 'colsample_bytree': 0.5101850435063138, 'gamma': 0.7577358407097541}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:07:46,591] Trial 23 finished with value: 0.7175173243150013 and parameters: {'n_estimators': 700, 'learning_rate': 0.033553883529905876, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6593712979980785, 'colsample_bytree': 0.5067707236654875, 'gamma': 0.7272487561047222}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:08:29,846] Trial 24 finished with value: 0.715250477407402 and parameters: {'n_estimators': 800, 'learning_rate': 0.017817518860284196, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7449149245882852, 'colsample_bytree': 0.6110200882217193, 'gamma': 0.8506171326413021}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:09:08,708] Trial 25 finished with value: 0.7172465651590176 and parameters: {'n_estimators': 600, 'learning_rate': 0.03928525601759813, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.6107962269646287, 'colsample_bytree': 0.5459760355649804, 'gamma': 0.6752145414328711}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:09:56,249] Trial 26 finished with value: 0.7142209540047576 and parameters: {'n_estimators': 900, 'learning_rate': 0.015210633629150911, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.6876385015510251, 'colsample_bytree': 0.6407765816216827, 'gamma': 0.5814498734892647}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:10:41,357] Trial 27 finished with value: 0.7178304965290107 and parameters: {'n_estimators': 800, 'learning_rate': 0.03324070951374116, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.7232370802546445, 'colsample_bytree': 0.5021410856808042, 'gamma': 0.4376528511613119}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:11:07,099] Trial 28 finished with value: 0.7173386924122578 and parameters: {'n_estimators': 500, 'learning_rate': 0.046928005475898954, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.7658416533242244, 'colsample_bytree': 0.5878119227440495, 'gamma': 0.7634177212680952}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:11:44,387] Trial 29 finished with value: 0.70993444767909 and parameters: {'n_estimators': 700, 'learning_rate': 0.09191138746846152, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.5617104625598868, 'colsample_bytree': 0.5531565820531346, 'gamma': 0.4625875033533618}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:13:00,263] Trial 30 finished with value: 0.7158753812893589 and parameters: {'n_estimators': 900, 'learning_rate': 0.02166556281851711, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.5888285058456352, 'colsample_bytree': 0.5806439181506531, 'gamma': 0.82843390582043}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:13:42,410] Trial 31 finished with value: 0.7184056998087235 and parameters: {'n_estimators': 900, 'learning_rate': 0.061763108850993995, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8084450291281993, 'colsample_bytree': 0.6580737413999652, 'gamma': 0.09246303193983671}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:14:20,281] Trial 32 finished with value: 0.7184191309897547 and parameters: {'n_estimators': 800, 'learning_rate': 0.054358634219154246, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8526008055698349, 'colsample_bytree': 0.7456201364961349, 'gamma': 0.6885126859519601}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:14:50,349] Trial 33 finished with value: 0.7166901501053656 and parameters: {'n_estimators': 600, 'learning_rate': 0.038649953026478605, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7444279838388365, 'colsample_bytree': 0.6725368819630277, 'gamma': 0.2647171998046792}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:15:36,061] Trial 34 finished with value: 0.7088843561982393 and parameters: {'n_estimators': 900, 'learning_rate': 0.09605098414356457, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.7817758945243517, 'colsample_bytree': 0.6079918300789846, 'gamma': 0.39284653274065884}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:16:17,374] Trial 35 finished with value: 0.7176086588653138 and parameters: {'n_estimators': 700, 'learning_rate': 0.02374668059496688, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6899727677857044, 'colsample_bytree': 0.5269773325208702, 'gamma': 0.6183164382125167}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:17:00,372] Trial 36 finished with value: 0.7167945020563011 and parameters: {'n_estimators': 900, 'learning_rate': 0.031262480955702776, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7192470356011066, 'colsample_bytree': 0.5672986355370525, 'gamma': 0.5356194488767594}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:17:46,722] Trial 37 finished with value: 0.7022227032899782 and parameters: {'n_estimators': 800, 'learning_rate': 0.1780158006112051, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.890698832746088, 'colsample_bytree': 0.9991417930830018, 'gamma': 0.014056742300753267}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:18:40,979] Trial 38 finished with value: 0.7105432447826476 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01130792245465436, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.965946308365782, 'colsample_bytree': 0.7320294585823423, 'gamma': 0.1349402156933884}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:19:07,925] Trial 39 finished with value: 0.713131782198223 and parameters: {'n_estimators': 300, 'learning_rate': 0.05970638037333741, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.9164840858358919, 'colsample_bytree': 0.6239579195798053, 'gamma': 0.9079984777232772}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:19:38,272] Trial 40 finished with value: 0.7169810965535646 and parameters: {'n_estimators': 600, 'learning_rate': 0.04195801009241162, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.7968040439865084, 'colsample_bytree': 0.9303037842964206, 'gamma': 0.5870623844749026}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:20:16,248] Trial 41 finished with value: 0.7161514458285424 and parameters: {'n_estimators': 800, 'learning_rate': 0.05619790657156803, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8441613832646218, 'colsample_bytree': 0.7528952573149507, 'gamma': 0.6882295164157395}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:20:55,147] Trial 42 finished with value: 0.7175163054291047 and parameters: {'n_estimators': 800, 'learning_rate': 0.0292493900561728, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8417045798634377, 'colsample_bytree': 0.7952705731230834, 'gamma': 0.7280454786795728}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:21:29,339] Trial 43 finished with value: 0.7129172807063167 and parameters: {'n_estimators': 700, 'learning_rate': 0.07110898375032756, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7321257874824553, 'colsample_bytree': 0.7358202855240257, 'gamma': 0.7834271971507479}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:22:13,748] Trial 44 finished with value: 0.7150271795060117 and parameters: {'n_estimators': 900, 'learning_rate': 0.052548795163276506, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.9993204662796429, 'colsample_bytree': 0.837250064579441, 'gamma': 0.4947866358218592}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:22:39,786] Trial 45 finished with value: 0.714271354720254 and parameters: {'n_estimators': 500, 'learning_rate': 0.09034059937595826, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.5020346162094567, 'colsample_bytree': 0.6722662667659365, 'gamma': 0.4050431151244302}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:23:31,683] Trial 46 finished with value: 0.7134703629954261 and parameters: {'n_estimators': 900, 'learning_rate': 0.04467417171419114, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.7667763363188523, 'colsample_bytree': 0.7699106907254678, 'gamma': 0.3484963768054106}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:24:23,082] Trial 47 finished with value: 0.7161155830256453 and parameters: {'n_estimators': 1000, 'learning_rate': 0.03499012325918152, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7041305387874344, 'colsample_bytree': 0.5257784701937932, 'gamma': 0.5598921059147015}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:25:02,237] Trial 48 finished with value: 0.7154449128406155 and parameters: {'n_estimators': 800, 'learning_rate': 0.02538481087343306, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8694666509118347, 'colsample_bytree': 0.8196781314627358, 'gamma': 0.8749413679702635}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:25:25,154] Trial 49 finished with value: 0.7185408830993553 and parameters: {'n_estimators': 400, 'learning_rate': 0.06637962100675424, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8341614871101932, 'colsample_bytree': 0.7297941645661415, 'gamma': 0.6386791168195567}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:25:50,331] Trial 50 finished with value: 0.711946568927115 and parameters: {'n_estimators': 400, 'learning_rate': 0.07833532955832602, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6608583747057708, 'colsample_bytree': 0.5935845602380843, 'gamma': 0.6311311350481918}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:26:09,138] Trial 51 finished with value: 0.7149919671396674 and parameters: {'n_estimators': 300, 'learning_rate': 0.05292317951805275, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8330213647522554, 'colsample_bytree': 0.7307592678250944, 'gamma': 0.6908612939881195}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:26:26,352] Trial 52 finished with value: 0.7145477962316887 and parameters: {'n_estimators': 300, 'learning_rate': 0.06773353559764123, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8135833078822334, 'colsample_bytree': 0.6726429396386959, 'gamma': 0.6638313460209735}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:27:02,324] Trial 53 finished with value: 0.7150661602868877 and parameters: {'n_estimators': 700, 'learning_rate': 0.05943601359282356, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.9223007015747162, 'colsample_bytree': 0.7735854383561267, 'gamma': 0.7985649673215358}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:27:49,622] Trial 54 finished with value: 0.7138714563058182 and parameters: {'n_estimators': 600, 'learning_rate': 0.04761824594643517, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.7952591106902009, 'colsample_bytree': 0.7201119309382443, 'gamma': 0.5002903594795354}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:28:17,870] Trial 55 finished with value: 0.7164773382548022 and parameters: {'n_estimators': 500, 'learning_rate': 0.03716178029204978, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8786778976056439, 'colsample_bytree': 0.7493582007981688, 'gamma': 0.7082106770821334}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:28:40,280] Trial 56 finished with value: 0.7075634458587633 and parameters: {'n_estimators': 400, 'learning_rate': 0.029063082101455875, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8550448619663953, 'colsample_bytree': 0.6841217782438633, 'gamma': 0.2595352234664401}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:29:37,225] Trial 57 finished with value: 0.7066960492407117 and parameters: {'n_estimators': 1000, 'learning_rate': 0.10485722109969667, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.7595530282423018, 'colsample_bytree': 0.6500948453275059, 'gamma': 0.5945876010498287}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:29:53,471] Trial 58 finished with value: 0.7149724174672293 and parameters: {'n_estimators': 200, 'learning_rate': 0.07964817076575717, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.7799887919488396, 'colsample_bytree': 0.5662946238337685, 'gamma': 0.7433583681805697}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:30:34,322] Trial 59 finished with value: 0.7187899079427995 and parameters: {'n_estimators': 800, 'learning_rate': 0.042266585649973355, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7435676064851693, 'colsample_bytree': 0.5282116926663798, 'gamma': 0.4379515956110597}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:31:15,027] Trial 60 finished with value: 0.7199731979883323 and parameters: {'n_estimators': 800, 'learning_rate': 0.0428460872129124, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7414508504828805, 'colsample_bytree': 0.530509361293347, 'gamma': 0.4612592899842217}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:31:56,352] Trial 61 finished with value: 0.7167961506815976 and parameters: {'n_estimators': 800, 'learning_rate': 0.04286434775977002, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7071823458605881, 'colsample_bytree': 0.5269305118654687, 'gamma': 0.46883569177470874}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:32:36,037] Trial 62 finished with value: 0.7165614722243113 and parameters: {'n_estimators': 700, 'learning_rate': 0.03490937542032425, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.7411976152046617, 'colsample_bytree': 0.5415583811682193, 'gamma': 0.3580396195552172}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:33:16,903] Trial 63 finished with value: 0.716823531753532 and parameters: {'n_estimators': 800, 'learning_rate': 0.06564707175232314, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7712684263643129, 'colsample_bytree': 0.513346932934174, 'gamma': 0.4375023091422915}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:33:53,415] Trial 64 finished with value: 0.7175175616230609 and parameters: {'n_estimators': 700, 'learning_rate': 0.047805030363049394, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.8085474127381794, 'colsample_bytree': 0.5465922683991428, 'gamma': 0.2937679299168208}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:34:44,311] Trial 65 finished with value: 0.7157722042944504 and parameters: {'n_estimators': 900, 'learning_rate': 0.041877479453149985, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6824924078115979, 'colsample_bytree': 0.5013397698863981, 'gamma': 0.5350415555525977}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:35:30,698] Trial 66 finished with value: 0.7165955399302577 and parameters: {'n_estimators': 900, 'learning_rate': 0.030994613992429074, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.7298926991121835, 'colsample_bytree': 0.5695385645302129, 'gamma': 0.18427473574354755}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:36:02,614] Trial 67 finished with value: 0.6933895015127532 and parameters: {'n_estimators': 600, 'learning_rate': 0.2956713006509135, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7490389549255697, 'colsample_bytree': 0.5330027677650375, 'gamma': 0.43839613691542256}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:36:47,879] Trial 68 finished with value: 0.7176869791313436 and parameters: {'n_estimators': 800, 'learning_rate': 0.026782951288748226, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7948923591085547, 'colsample_bytree': 0.6192077118659348, 'gamma': 0.30694395435105803}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:37:35,185] Trial 69 finished with value: 0.7159433685374624 and parameters: {'n_estimators': 1000, 'learning_rate': 0.022392576772889073, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8254029977864717, 'colsample_bytree': 0.5146563482794497, 'gamma': 0.47571881049584186}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:38:49,741] Trial 70 finished with value: 0.7115401376776832 and parameters: {'n_estimators': 800, 'learning_rate': 0.036034788142196746, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.6741756005025845, 'colsample_bytree': 0.5545720332769657, 'gamma': 0.37974907151503456}. Best is trial 20 with value: 0.7203311513561246.\n",
      "[I 2024-11-01 20:39:27,878] Trial 71 finished with value: 0.7203389554320888 and parameters: {'n_estimators': 800, 'learning_rate': 0.05512842330799347, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7552452169082876, 'colsample_bytree': 0.7068522077945619, 'gamma': 0.6504671666557214}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:40:10,761] Trial 72 finished with value: 0.7170337568562283 and parameters: {'n_estimators': 900, 'learning_rate': 0.05208147412929289, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7082019105018255, 'colsample_bytree': 0.719097171238952, 'gamma': 0.6005610599441126}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:40:48,353] Trial 73 finished with value: 0.7177511313118263 and parameters: {'n_estimators': 700, 'learning_rate': 0.060245628582546985, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7576543834000987, 'colsample_bytree': 0.692246419366208, 'gamma': 0.5593133836279907}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:41:25,445] Trial 74 finished with value: 0.7176595869889246 and parameters: {'n_estimators': 800, 'learning_rate': 0.04033088168459329, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7334433352271081, 'colsample_bytree': 0.5193828115097066, 'gamma': 0.6459283924894977}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:42:11,129] Trial 75 finished with value: 0.7175325578190641 and parameters: {'n_estimators': 900, 'learning_rate': 0.04532446069815667, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.781600549997935, 'colsample_bytree': 0.5800162019791437, 'gamma': 0.41519132035846407}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:42:52,391] Trial 76 finished with value: 0.7187198848876613 and parameters: {'n_estimators': 800, 'learning_rate': 0.04908442162701263, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7197920681283119, 'colsample_bytree': 0.5390777208348574, 'gamma': 0.5167525804330088}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:43:26,721] Trial 77 finished with value: 0.7169668160613394 and parameters: {'n_estimators': 800, 'learning_rate': 0.03291781914029906, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.7197947216045314, 'colsample_bytree': 0.5006275777473188, 'gamma': 0.5155199257727834}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:43:59,717] Trial 78 finished with value: 0.7183606834301625 and parameters: {'n_estimators': 800, 'learning_rate': 0.048974261764950545, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.6428087579152704, 'colsample_bytree': 0.601261606592486, 'gamma': 0.4527411868949863}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:44:39,046] Trial 79 finished with value: 0.715099825310819 and parameters: {'n_estimators': 700, 'learning_rate': 0.03789006347416344, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.7454292101665232, 'colsample_bytree': 0.6282411893138997, 'gamma': 0.37885557884031046}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:45:08,683] Trial 80 finished with value: 0.7129404904708547 and parameters: {'n_estimators': 700, 'learning_rate': 0.0843543731900644, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.6972943660563172, 'colsample_bytree': 0.5571648666716897, 'gamma': 0.4153533300653628}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:45:44,596] Trial 81 finished with value: 0.7174720754337894 and parameters: {'n_estimators': 800, 'learning_rate': 0.07009685657163363, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7688554386048496, 'colsample_bytree': 0.5381004428910193, 'gamma': 0.655515217743986}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:46:22,046] Trial 82 finished with value: 0.7162964825789861 and parameters: {'n_estimators': 800, 'learning_rate': 0.06422805418341582, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8053490431450554, 'colsample_bytree': 0.714794445393255, 'gamma': 0.6256967783112277}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:46:58,578] Trial 83 finished with value: 0.7184073588230466 and parameters: {'n_estimators': 900, 'learning_rate': 0.05721395323377235, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7550216308966893, 'colsample_bytree': 0.5211658934634856, 'gamma': 0.5680484185289651}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:47:40,345] Trial 84 finished with value: 0.717860186738361 and parameters: {'n_estimators': 900, 'learning_rate': 0.04515156470146928, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.7167875571208632, 'colsample_bytree': 0.6613315644180425, 'gamma': 0.7163999566894326}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:48:08,613] Trial 85 finished with value: 0.714020332555649 and parameters: {'n_estimators': 400, 'learning_rate': 0.05427279451551027, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.734834071866041, 'colsample_bytree': 0.536952562070323, 'gamma': 0.32780440322338505}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:48:41,619] Trial 86 finished with value: 0.7161376100807251 and parameters: {'n_estimators': 700, 'learning_rate': 0.030955670940528302, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.7824613827488045, 'colsample_bytree': 0.5746215651426873, 'gamma': 0.8055986571730215}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:49:44,494] Trial 87 finished with value: 0.7086465504795456 and parameters: {'n_estimators': 800, 'learning_rate': 0.03958792115161022, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.6744320797381517, 'colsample_bytree': 0.7030844999444007, 'gamma': 0.4923663641059151}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:49:52,060] Trial 88 finished with value: 0.7028694452378857 and parameters: {'n_estimators': 100, 'learning_rate': 0.07232856791706278, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7693656373277848, 'colsample_bytree': 0.7650669908781422, 'gamma': 0.5216719041340714}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:50:21,801] Trial 89 finished with value: 0.7170349096838345 and parameters: {'n_estimators': 700, 'learning_rate': 0.051141251336308, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.8307365317341739, 'colsample_bytree': 0.7829699180564617, 'gamma': 0.7729883467582674}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:51:05,765] Trial 90 finished with value: 0.7174039841798623 and parameters: {'n_estimators': 900, 'learning_rate': 0.042956422453884036, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7266977041581387, 'colsample_bytree': 0.5861929439823169, 'gamma': 0.7402928496915064}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:51:44,179] Trial 91 finished with value: 0.7177191201389842 and parameters: {'n_estimators': 800, 'learning_rate': 0.06284294468695514, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8440683441502022, 'colsample_bytree': 0.8014425154997358, 'gamma': 0.6933415550875566}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:52:26,467] Trial 92 finished with value: 0.717719588791969 and parameters: {'n_estimators': 800, 'learning_rate': 0.05633008630555487, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8783195584908836, 'colsample_bytree': 0.7510540846979764, 'gamma': 0.6196901100497749}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:53:06,668] Trial 93 finished with value: 0.7189293086438674 and parameters: {'n_estimators': 800, 'learning_rate': 0.048047149415421396, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8519472211391693, 'colsample_bytree': 0.6899461835275523, 'gamma': 0.675319663225432}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:53:45,298] Trial 94 finished with value: 0.7189171162785692 and parameters: {'n_estimators': 800, 'learning_rate': 0.049089098594993344, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8025367350824091, 'colsample_bytree': 0.6833058758842665, 'gamma': 0.6437938219511005}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:54:23,583] Trial 95 finished with value: 0.7179968309837471 and parameters: {'n_estimators': 800, 'learning_rate': 0.04861447137997357, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.790418857374535, 'colsample_bytree': 0.6859860824524101, 'gamma': 0.6607162299188949}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:55:06,570] Trial 96 finished with value: 0.7185753592570853 and parameters: {'n_estimators': 900, 'learning_rate': 0.03729860004995664, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8036129992431735, 'colsample_bytree': 0.6412172425743091, 'gamma': 0.26543699704320944}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:55:41,051] Trial 97 finished with value: 0.7157566051895905 and parameters: {'n_estimators': 700, 'learning_rate': 0.033148119011599204, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7531178196531609, 'colsample_bytree': 0.6563118707519433, 'gamma': 0.584613836026508}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:56:19,709] Trial 98 finished with value: 0.7198186867792137 and parameters: {'n_estimators': 800, 'learning_rate': 0.04363813160550437, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7733623695470501, 'colsample_bytree': 0.6683810839388803, 'gamma': 0.6714598580595169}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:56:58,229] Trial 99 finished with value: 0.7185305449170235 and parameters: {'n_estimators': 800, 'learning_rate': 0.041192265383432076, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7424840862999709, 'colsample_bytree': 0.6666661170524024, 'gamma': 0.6768103110947742}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:57:36,469] Trial 100 finished with value: 0.719232993484385 and parameters: {'n_estimators': 800, 'learning_rate': 0.04457540254159553, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7633994881353875, 'colsample_bytree': 0.6842548243698086, 'gamma': 0.708774988845349}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:58:20,267] Trial 101 finished with value: 0.7189648230592602 and parameters: {'n_estimators': 800, 'learning_rate': 0.04435065424726594, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7727431223392622, 'colsample_bytree': 0.6803445859723877, 'gamma': 0.7543440992390945}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:58:59,332] Trial 102 finished with value: 0.7177028625202155 and parameters: {'n_estimators': 800, 'learning_rate': 0.043938261792585274, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7760015411858996, 'colsample_bytree': 0.6800574078211595, 'gamma': 0.7110141099738899}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 20:59:38,222] Trial 103 finished with value: 0.7201479748087329 and parameters: {'n_estimators': 800, 'learning_rate': 0.03889184065593831, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7626814562044834, 'colsample_bytree': 0.6920102312362286, 'gamma': 0.7554372274332384}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:00:12,986] Trial 104 finished with value: 0.7170688413330542 and parameters: {'n_estimators': 700, 'learning_rate': 0.035034646102091664, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7643489464204628, 'colsample_bytree': 0.6994177835356898, 'gamma': 0.8540402877250814}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:00:51,109] Trial 105 finished with value: 0.7185085366230274 and parameters: {'n_estimators': 800, 'learning_rate': 0.038279985343450194, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7923838914193178, 'colsample_bytree': 0.6477223165502098, 'gamma': 0.742268620475291}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:01:29,600] Trial 106 finished with value: 0.7159073544127402 and parameters: {'n_estimators': 800, 'learning_rate': 0.045404783649521746, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8173305997716653, 'colsample_bytree': 0.6929080017569355, 'gamma': 0.7934554303462897}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:02:12,523] Trial 107 finished with value: 0.7193188894708576 and parameters: {'n_estimators': 900, 'learning_rate': 0.030618473343050866, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.76007606901711, 'colsample_bytree': 0.6319847543979695, 'gamma': 0.7677481467151717}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:02:55,803] Trial 108 finished with value: 0.7174686083575429 and parameters: {'n_estimators': 900, 'learning_rate': 0.02898454517664376, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7609596820796977, 'colsample_bytree': 0.6318532880965747, 'gamma': 0.7589401563744822}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:03:39,320] Trial 109 finished with value: 0.7166733966320413 and parameters: {'n_estimators': 900, 'learning_rate': 0.024693597043486365, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7846304884431037, 'colsample_bytree': 0.6151712198003274, 'gamma': 0.7740943133967862}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:04:22,226] Trial 110 finished with value: 0.7171387315260936 and parameters: {'n_estimators': 900, 'learning_rate': 0.031887906877804156, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7392199065446895, 'colsample_bytree': 0.6754097274410173, 'gamma': 0.8184547242779124}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:05:01,107] Trial 111 finished with value: 0.7188691561417503 and parameters: {'n_estimators': 800, 'learning_rate': 0.03558061153699771, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7545353045055612, 'colsample_bytree': 0.7068124275751901, 'gamma': 0.7200930204276123}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:05:40,282] Trial 112 finished with value: 0.7168814516635622 and parameters: {'n_estimators': 800, 'learning_rate': 0.027640935021198184, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7706078418502293, 'colsample_bytree': 0.6385154817458133, 'gamma': 0.681565105188592}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:06:18,345] Trial 113 finished with value: 0.7177228513680811 and parameters: {'n_estimators': 800, 'learning_rate': 0.03969043604769327, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8011032182273514, 'colsample_bytree': 0.6582856509123052, 'gamma': 0.8412090132275}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:06:59,017] Trial 114 finished with value: 0.7073742547698906 and parameters: {'n_estimators': 800, 'learning_rate': 0.013175664018665618, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7759134982030519, 'colsample_bytree': 0.685854385095466, 'gamma': 0.6967280793191949}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:07:36,530] Trial 115 finished with value: 0.7172684639494818 and parameters: {'n_estimators': 700, 'learning_rate': 0.050175624241256614, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7513193199450607, 'colsample_bytree': 0.7247896966874807, 'gamma': 0.7479135538202576}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:08:19,163] Trial 116 finished with value: 0.7180088265323418 and parameters: {'n_estimators': 900, 'learning_rate': 0.04637980771639318, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7284759287638984, 'colsample_bytree': 0.6678147489403687, 'gamma': 0.6385675791098575}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:08:57,734] Trial 117 finished with value: 0.7036976126922151 and parameters: {'n_estimators': 800, 'learning_rate': 0.21812532139548993, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7626116967279591, 'colsample_bytree': 0.7369196597658397, 'gamma': 0.7260379969447359}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:09:40,005] Trial 118 finished with value: 0.7184072829360162 and parameters: {'n_estimators': 800, 'learning_rate': 0.03697110322883283, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7106974634131565, 'colsample_bytree': 0.6497700877750174, 'gamma': 0.6632398420783946}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:10:14,434] Trial 119 finished with value: 0.7162021958261576 and parameters: {'n_estimators': 700, 'learning_rate': 0.040667828088622265, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.785838483857394, 'colsample_bytree': 0.7085996676141575, 'gamma': 0.9132043429688048}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:11:01,306] Trial 120 finished with value: 0.7173948707682511 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05324400893389794, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8213806142204286, 'colsample_bytree': 0.695351124472507, 'gamma': 0.8867270685948193}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:11:40,295] Trial 121 finished with value: 0.7177725862845481 and parameters: {'n_estimators': 800, 'learning_rate': 0.033435879446995435, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7540994478604265, 'colsample_bytree': 0.7132076544825081, 'gamma': 0.7213333614636935}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:12:19,589] Trial 122 finished with value: 0.7165534165387545 and parameters: {'n_estimators': 800, 'learning_rate': 0.03019247827689989, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7470448131920578, 'colsample_bytree': 0.6783010679078227, 'gamma': 0.7050940983653571}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:12:58,775] Trial 123 finished with value: 0.7181289771979686 and parameters: {'n_estimators': 800, 'learning_rate': 0.03577586791338093, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7373789856850781, 'colsample_bytree': 0.7057495035320451, 'gamma': 0.7321417567472954}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:13:42,530] Trial 124 finished with value: 0.7158263446261174 and parameters: {'n_estimators': 800, 'learning_rate': 0.03414748917600412, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7738442895946289, 'colsample_bytree': 0.6890935548507542, 'gamma': 0.7698833010746492}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:14:31,044] Trial 125 finished with value: 0.7156386001442563 and parameters: {'n_estimators': 700, 'learning_rate': 0.042812775815670966, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.7560826493328888, 'colsample_bytree': 0.6053346002875235, 'gamma': 0.603911614386235}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:15:17,747] Trial 126 finished with value: 0.7181303140488315 and parameters: {'n_estimators': 900, 'learning_rate': 0.03770869066699754, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7640163916718365, 'colsample_bytree': 0.6653006151701419, 'gamma': 0.8165734429995753}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:15:57,228] Trial 127 finished with value: 0.7135217108805065 and parameters: {'n_estimators': 800, 'learning_rate': 0.019248824589611076, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.6996547502562184, 'colsample_bytree': 0.5125405702522484, 'gamma': 0.7836350556336829}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:16:35,265] Trial 128 finished with value: 0.7176234477770166 and parameters: {'n_estimators': 800, 'learning_rate': 0.04677609432966059, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7915920316396927, 'colsample_bytree': 0.7008490591486998, 'gamma': 0.6649637337100779}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:17:21,781] Trial 129 finished with value: 0.7163105716663608 and parameters: {'n_estimators': 900, 'learning_rate': 0.057163863711630944, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.9028127925801501, 'colsample_bytree': 0.7407158826367217, 'gamma': 0.7610824819584774}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:17:56,936] Trial 130 finished with value: 0.7139605218458005 and parameters: {'n_estimators': 700, 'learning_rate': 0.026210314679022604, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7312279926100194, 'colsample_bytree': 0.6776245099449949, 'gamma': 0.6808826856758504}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:18:37,216] Trial 131 finished with value: 0.7197279846858973 and parameters: {'n_estimators': 800, 'learning_rate': 0.04408469027849722, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7452231532038283, 'colsample_bytree': 0.527346651454561, 'gamma': 0.7051617128962796}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:19:15,843] Trial 132 finished with value: 0.7174770615962638 and parameters: {'n_estimators': 800, 'learning_rate': 0.044061848519939155, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7473073103750786, 'colsample_bytree': 0.8855265181171716, 'gamma': 0.7046262173358511}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:19:52,062] Trial 133 finished with value: 0.7186146696932403 and parameters: {'n_estimators': 800, 'learning_rate': 0.039400176962051905, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7227961809305997, 'colsample_bytree': 0.5057432835430182, 'gamma': 0.6401543411236714}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:20:27,671] Trial 134 finished with value: 0.7165156655316183 and parameters: {'n_estimators': 800, 'learning_rate': 0.051497577820365, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.7747203671857436, 'colsample_bytree': 0.54906645370244, 'gamma': 0.7272714908877272}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:21:07,826] Trial 135 finished with value: 0.7167827238586597 and parameters: {'n_estimators': 800, 'learning_rate': 0.042182245236800545, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.7607888015255685, 'colsample_bytree': 0.7208608953826813, 'gamma': 0.7466569091850921}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:21:40,455] Trial 136 finished with value: 0.7186312470861532 and parameters: {'n_estimators': 800, 'learning_rate': 0.04809868214122105, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7369718558386767, 'colsample_bytree': 0.6534989339852106, 'gamma': 0.7954691245085332}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:22:16,780] Trial 137 finished with value: 0.7184069336231264 and parameters: {'n_estimators': 900, 'learning_rate': 0.03573272376093862, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7835245295826616, 'colsample_bytree': 0.5162545617394546, 'gamma': 0.6203551110551481}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:22:50,067] Trial 138 finished with value: 0.7187725082209149 and parameters: {'n_estimators': 800, 'learning_rate': 0.04443091271555653, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.7144705347913538, 'colsample_bytree': 0.6866430696366235, 'gamma': 0.6832629982255009}. Best is trial 71 with value: 0.7203389554320888.\n",
      "[I 2024-11-01 21:23:25,753] Trial 139 finished with value: 0.7211720735858024 and parameters: {'n_estimators': 800, 'learning_rate': 0.04036413044768581, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7505214930635562, 'colsample_bytree': 0.6290102054237857, 'gamma': 0.648553153047272}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:23:57,415] Trial 140 finished with value: 0.7190210793899598 and parameters: {'n_estimators': 700, 'learning_rate': 0.03922437547584248, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7444509910989927, 'colsample_bytree': 0.6237098880449912, 'gamma': 0.6494680936278386}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:24:29,427] Trial 141 finished with value: 0.7167520786302374 and parameters: {'n_estimators': 700, 'learning_rate': 0.04089403916988484, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7436080277896424, 'colsample_bytree': 0.6203892873635859, 'gamma': 0.6461434135953164}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:25:05,490] Trial 142 finished with value: 0.7162391519543042 and parameters: {'n_estimators': 800, 'learning_rate': 0.038212329231952356, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7679960253152754, 'colsample_bytree': 0.5950264018586489, 'gamma': 0.6105834144037844}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:25:37,490] Trial 143 finished with value: 0.718318975235227 and parameters: {'n_estimators': 700, 'learning_rate': 0.03191352102576385, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7285644741307631, 'colsample_bytree': 0.6318143306940099, 'gamma': 0.6494314375643352}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:26:05,156] Trial 144 finished with value: 0.7163981700965507 and parameters: {'n_estimators': 600, 'learning_rate': 0.04947084022019008, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.749286821641596, 'colsample_bytree': 0.6129226338108573, 'gamma': 0.6976330054377485}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:26:40,886] Trial 145 finished with value: 0.7186349399077537 and parameters: {'n_estimators': 800, 'learning_rate': 0.05485960900868238, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7998898868326041, 'colsample_bytree': 0.6254419267444593, 'gamma': 0.6564984073786467}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:27:24,675] Trial 146 finished with value: 0.7159289665282577 and parameters: {'n_estimators': 900, 'learning_rate': 0.046052592821158936, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.777709475765319, 'colsample_bytree': 0.6418786775671034, 'gamma': 0.6771994304862684}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:28:01,251] Trial 147 finished with value: 0.7187038347599864 and parameters: {'n_estimators': 800, 'learning_rate': 0.04078214962590523, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7622812365947079, 'colsample_bytree': 0.6642217741583949, 'gamma': 0.7566568521478693}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:28:42,076] Trial 148 finished with value: 0.7169527390255307 and parameters: {'n_estimators': 800, 'learning_rate': 0.060638588410723414, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7399669215369816, 'colsample_bytree': 0.5299454348613484, 'gamma': 0.6253551952994347}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:29:14,724] Trial 149 finished with value: 0.7176879343418242 and parameters: {'n_estimators': 700, 'learning_rate': 0.033474343228911206, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.7688304564949738, 'colsample_bytree': 0.5010552864301588, 'gamma': 0.5819444706958409}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:29:59,381] Trial 150 finished with value: 0.7167456760745066 and parameters: {'n_estimators': 900, 'learning_rate': 0.0507857724547328, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8116151002927117, 'colsample_bytree': 0.6730368875052645, 'gamma': 0.7104497113898512}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:30:32,446] Trial 151 finished with value: 0.7169959237000167 and parameters: {'n_estimators': 800, 'learning_rate': 0.03528941526313426, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7539507948191919, 'colsample_bytree': 0.6947127097867283, 'gamma': 0.9454983375650894}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:31:05,490] Trial 152 finished with value: 0.7180925943179546 and parameters: {'n_estimators': 800, 'learning_rate': 0.037773962265373544, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7529872080078834, 'colsample_bytree': 0.6465679823830247, 'gamma': 0.7327600504232533}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:31:38,410] Trial 153 finished with value: 0.718404613065281 and parameters: {'n_estimators': 800, 'learning_rate': 0.0424404281524389, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7385395118935867, 'colsample_bytree': 0.7096132337681827, 'gamma': 0.7155920711196566}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:32:11,977] Trial 154 finished with value: 0.7186636052383726 and parameters: {'n_estimators': 800, 'learning_rate': 0.02966435508294961, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7857662450609071, 'colsample_bytree': 0.6548779441418612, 'gamma': 0.6715178323229746}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:32:45,707] Trial 155 finished with value: 0.7169280247340465 and parameters: {'n_estimators': 800, 'learning_rate': 0.04525846924132531, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7221967582671005, 'colsample_bytree': 0.6712497785383611, 'gamma': 0.6967797070011827}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:33:19,172] Trial 156 finished with value: 0.7191603510522192 and parameters: {'n_estimators': 800, 'learning_rate': 0.04011699936401867, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7577014664547707, 'colsample_bytree': 0.6863702973329129, 'gamma': 0.7848407677542742}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:33:53,062] Trial 157 finished with value: 0.7185971789570554 and parameters: {'n_estimators': 800, 'learning_rate': 0.04029767491246122, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7617985152717494, 'colsample_bytree': 0.6809201430958427, 'gamma': 0.8247508572176346}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:34:22,757] Trial 158 finished with value: 0.7193108411094802 and parameters: {'n_estimators': 700, 'learning_rate': 0.04651420978536056, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.772755666512924, 'colsample_bytree': 0.5626147234739993, 'gamma': 0.7831600049134093}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:34:55,102] Trial 159 finished with value: 0.7198897291530526 and parameters: {'n_estimators': 700, 'learning_rate': 0.038362323631817206, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7735482038790913, 'colsample_bytree': 0.5614780778078073, 'gamma': 0.7814710001926517}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:35:23,155] Trial 160 finished with value: 0.7194270914327738 and parameters: {'n_estimators': 600, 'learning_rate': 0.03876832001460929, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7738904010101664, 'colsample_bytree': 0.5617997205265394, 'gamma': 0.7817530088251347}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:35:51,047] Trial 161 finished with value: 0.7159712571571738 and parameters: {'n_estimators': 600, 'learning_rate': 0.03859051890869177, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7765137744793766, 'colsample_bytree': 0.5645795011103862, 'gamma': 0.8011204190247447}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:36:18,617] Trial 162 finished with value: 0.7195625018319312 and parameters: {'n_estimators': 600, 'learning_rate': 0.042797520295400016, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7698700870803872, 'colsample_bytree': 0.5474873182007887, 'gamma': 0.7866093037704506}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:36:47,004] Trial 163 finished with value: 0.7203215784033759 and parameters: {'n_estimators': 600, 'learning_rate': 0.03653076037434821, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7468237751971156, 'colsample_bytree': 0.5581238762098124, 'gamma': 0.8387199910081166}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:37:15,284] Trial 164 finished with value: 0.7168146976757199 and parameters: {'n_estimators': 600, 'learning_rate': 0.03205768504052131, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.764265912856881, 'colsample_bytree': 0.5570208489275191, 'gamma': 0.8642779236425542}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:37:39,342] Trial 165 finished with value: 0.7153359319852497 and parameters: {'n_estimators': 500, 'learning_rate': 0.03590534794757899, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7917070584241299, 'colsample_bytree': 0.5437538260563124, 'gamma': 0.8332243502606914}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:38:07,648] Trial 166 finished with value: 0.7188953712917958 and parameters: {'n_estimators': 600, 'learning_rate': 0.04306310986067451, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7562633690459566, 'colsample_bytree': 0.5775543088406658, 'gamma': 0.7797720727967334}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:38:33,157] Trial 167 finished with value: 0.7158142179099058 and parameters: {'n_estimators': 500, 'learning_rate': 0.03374117268924913, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.781140549459409, 'colsample_bytree': 0.5665303220680922, 'gamma': 0.8170594178031297}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:39:01,569] Trial 168 finished with value: 0.7168991978754511 and parameters: {'n_estimators': 600, 'learning_rate': 0.02845323778006164, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7691285146857265, 'colsample_bytree': 0.5518984719470764, 'gamma': 0.7985726146903793}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:39:29,659] Trial 169 finished with value: 0.7183618667122238 and parameters: {'n_estimators': 600, 'learning_rate': 0.037477697097116285, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7473134678089968, 'colsample_bytree': 0.5237543842701032, 'gamma': 0.8473472441583337}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:39:57,934] Trial 170 finished with value: 0.7177111820300264 and parameters: {'n_estimators': 600, 'learning_rate': 0.04057674557118049, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7339396309385033, 'colsample_bytree': 0.5320400640467587, 'gamma': 0.878563612150665}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:40:26,366] Trial 171 finished with value: 0.7162136581192893 and parameters: {'n_estimators': 600, 'learning_rate': 0.0391975737008424, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7430194975510424, 'colsample_bytree': 0.5887430730794958, 'gamma': 0.7764318646248103}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:40:58,003] Trial 172 finished with value: 0.7182454909840795 and parameters: {'n_estimators': 700, 'learning_rate': 0.043397503140378504, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7589641621471941, 'colsample_bytree': 0.5451720055589372, 'gamma': 0.7670183397258307}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:41:29,775] Trial 173 finished with value: 0.7178293689862961 and parameters: {'n_estimators': 700, 'learning_rate': 0.03642795363344619, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7487116869720393, 'colsample_bytree': 0.573437859064422, 'gamma': 0.7870161244319694}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:41:54,172] Trial 174 finished with value: 0.7179560674224504 and parameters: {'n_estimators': 500, 'learning_rate': 0.04680711332152223, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7302511632068613, 'colsample_bytree': 0.5120234356742287, 'gamma': 0.8114363993454077}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:42:29,046] Trial 175 finished with value: 0.720191217161873 and parameters: {'n_estimators': 700, 'learning_rate': 0.041150046131529776, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.7717470354499063, 'colsample_bytree': 0.5599094667895289, 'gamma': 0.7462406499693012}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:43:00,145] Trial 176 finished with value: 0.7180532549063322 and parameters: {'n_estimators': 600, 'learning_rate': 0.03126505415014705, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.7738315921190644, 'colsample_bytree': 0.5590717386779215, 'gamma': 0.7442250956683815}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:43:30,929] Trial 177 finished with value: 0.717415358215377 and parameters: {'n_estimators': 600, 'learning_rate': 0.041727642882187235, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7885754799068729, 'colsample_bytree': 0.5395820939506584, 'gamma': 0.7598866204671351}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:44:09,776] Trial 178 finished with value: 0.7186403531924127 and parameters: {'n_estimators': 700, 'learning_rate': 0.0334947256776717, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.759438215546062, 'colsample_bytree': 0.5844532155655788, 'gamma': 0.795183904965944}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:44:48,281] Trial 179 finished with value: 0.7178469656031167 and parameters: {'n_estimators': 700, 'learning_rate': 0.04503524538123294, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.7698357302243548, 'colsample_bytree': 0.5290749687381079, 'gamma': 0.46491212082183925}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:45:23,219] Trial 180 finished with value: 0.7182329002888417 and parameters: {'n_estimators': 700, 'learning_rate': 0.03824325728456982, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7806660044244448, 'colsample_bytree': 0.5600724167064575, 'gamma': 0.8323247140289265}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:45:55,473] Trial 181 finished with value: 0.7170144741154679 and parameters: {'n_estimators': 700, 'learning_rate': 0.04045251360758129, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.747821660893704, 'colsample_bytree': 0.5977801217803265, 'gamma': 0.7388790073800663}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:46:27,733] Trial 182 finished with value: 0.7184429478472267 and parameters: {'n_estimators': 700, 'learning_rate': 0.0355504541822017, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7607500400184131, 'colsample_bytree': 0.5201984686759331, 'gamma': 0.41792813309495463}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:46:59,530] Trial 183 finished with value: 0.718217089090384 and parameters: {'n_estimators': 700, 'learning_rate': 0.042392558522014685, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7381923657226803, 'colsample_bytree': 0.549709176885394, 'gamma': 0.7796664410996677}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:47:27,554] Trial 184 finished with value: 0.7191354880342712 and parameters: {'n_estimators': 600, 'learning_rate': 0.037833230656620837, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7529936831671132, 'colsample_bytree': 0.6074364708441224, 'gamma': 0.7572825708909703}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:47:55,468] Trial 185 finished with value: 0.7180635215131672 and parameters: {'n_estimators': 600, 'learning_rate': 0.04651808725037494, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7689884466842426, 'colsample_bytree': 0.5673351521076649, 'gamma': 0.7598800295246163}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:48:23,753] Trial 186 finished with value: 0.7187121082300296 and parameters: {'n_estimators': 600, 'learning_rate': 0.0370355718881225, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.7534899425649922, 'colsample_bytree': 0.6060078288171533, 'gamma': 0.7312301915397003}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:48:51,628] Trial 187 finished with value: 0.7191594020901729 and parameters: {'n_estimators': 600, 'learning_rate': 0.051558844776393796, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7841260433181497, 'colsample_bytree': 0.5734261084659136, 'gamma': 0.7793601791181691}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:49:21,567] Trial 188 finished with value: 0.7191222906369105 and parameters: {'n_estimators': 600, 'learning_rate': 0.05191557723300175, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.7978607337856822, 'colsample_bytree': 0.5482012007920233, 'gamma': 0.8136014427102508}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:49:45,263] Trial 189 finished with value: 0.7178371377280933 and parameters: {'n_estimators': 500, 'learning_rate': 0.0553199933423173, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.783077795665849, 'colsample_bytree': 0.5734180580057027, 'gamma': 0.4837164856383266}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:50:33,464] Trial 190 finished with value: 0.7145389035565065 and parameters: {'n_estimators': 800, 'learning_rate': 0.048877010509718294, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.7917365741152662, 'colsample_bytree': 0.5381279304619292, 'gamma': 0.7903226968087781}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:51:01,718] Trial 191 finished with value: 0.7169155672612976 and parameters: {'n_estimators': 600, 'learning_rate': 0.04452364530672302, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7669316894162599, 'colsample_bytree': 0.5882606945105986, 'gamma': 0.7536036745616258}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:51:29,866] Trial 192 finished with value: 0.7165916841311881 and parameters: {'n_estimators': 600, 'learning_rate': 0.040947427313860085, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.778204607841694, 'colsample_bytree': 0.556161954210405, 'gamma': 0.7717065035396041}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:51:58,502] Trial 193 finished with value: 0.7164887251210333 and parameters: {'n_estimators': 600, 'learning_rate': 0.034891685090727445, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7554006424867069, 'colsample_bytree': 0.578590535608635, 'gamma': 0.7371108496199793}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:52:26,384] Trial 194 finished with value: 0.7185875391089013 and parameters: {'n_estimators': 600, 'learning_rate': 0.038802897299928765, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7739414597294451, 'colsample_bytree': 0.5106162917604201, 'gamma': 0.7083607718063407}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:52:54,289] Trial 195 finished with value: 0.7179128417147111 and parameters: {'n_estimators': 600, 'learning_rate': 0.043146832741837456, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7634317996993742, 'colsample_bytree': 0.6362167616155312, 'gamma': 0.801304870015848}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:53:27,507] Trial 196 finished with value: 0.7190235766327369 and parameters: {'n_estimators': 800, 'learning_rate': 0.04658452715136688, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7372324138100297, 'colsample_bytree': 0.5638401888375056, 'gamma': 0.762775767543712}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:54:00,868] Trial 197 finished with value: 0.7180701375442053 and parameters: {'n_estimators': 800, 'learning_rate': 0.05227169602761511, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.7556972049184656, 'colsample_bytree': 0.5347204508151127, 'gamma': 0.7247375800105968}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:54:36,649] Trial 198 finished with value: 0.7208004971973112 and parameters: {'n_estimators': 800, 'learning_rate': 0.03729732855558997, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.727760757830552, 'colsample_bytree': 0.5192599942094395, 'gamma': 0.4397351650902877}. Best is trial 139 with value: 0.7211720735858024.\n",
      "[I 2024-11-01 21:55:09,940] Trial 199 finished with value: 0.7175617870943298 and parameters: {'n_estimators': 800, 'learning_rate': 0.032162459166477766, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.717174725180335, 'colsample_bytree': 0.5237854415994534, 'gamma': 0.438658674937279}. Best is trial 139 with value: 0.7211720735858024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'n_estimators': 800, 'learning_rate': 0.04036413044768581, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.7505214930635562, 'colsample_bytree': 0.6290102054237857, 'gamma': 0.648553153047272}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 목적함수를 클래스로 만들기\n",
    "class Objective:\n",
    "    # 변수 설정\n",
    "    def __init__(self, x, y, seed):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.seed = seed\n",
    "        self.cv = StratifiedKFold(5, shuffle= True, random_state= self.seed)\n",
    "\n",
    "    def __call__(self, trial):  # 콜백함수 역할\n",
    "        hp = {  \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "                \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                \"gamma\": trial.suggest_float(\"gamma\", 0, 1)  }\n",
    "        model = XGBClassifier(**hp, random_state= self.seed)    \n",
    "        score = cross_val_score(model, self.x, self.y, cv= self.cv, scoring= \"f1_macro\", n_jobs= -1).mean()\n",
    "        return score\n",
    "\n",
    "# Sampler 객체 생성(대체모델 역할)\n",
    "sampler = optuna.samplers.TPESampler(seed= SEED)\n",
    "\n",
    "# study 객체 생성\n",
    "study = optuna.create_study(direction= \"maximize\", sampler= sampler)\n",
    "\n",
    "# optimize 매서드 실행\n",
    "objective_func = Objective(train_ft, target, SEED)\n",
    "study.optimize(objective_func, n_trials= 200) \n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'learning_rate': 0.04036413044768581,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 7,\n",
       " 'subsample': 0.7505214930635562,\n",
       " 'colsample_bytree': 0.6290102054237857,\n",
       " 'gamma': 0.648553153047272}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "model.fit(train_ft, target)\n",
    "pred = model.predict(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-01 22:14:12] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-01 22:14:12] {1739} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 11-01 22:14:12] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-01 22:14:12] {1955} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 11-01 22:14:12] {2258} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:13] {2393} INFO - Estimated sufficient time budget=5392s. Estimated necessary time budget=5s.\n",
      "[flaml.automl.logger: 11-01 22:14:13] {2442} INFO -  at 2.3s,\testimator xgboost's best error=0.6223,\tbest estimator xgboost's best error=0.6223\n",
      "[flaml.automl.logger: 11-01 22:14:13] {2258} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:13] {2442} INFO -  at 2.9s,\testimator xgboost's best error=0.6223,\tbest estimator xgboost's best error=0.6223\n",
      "[flaml.automl.logger: 11-01 22:14:13] {2258} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:14] {2442} INFO -  at 3.4s,\testimator xgboost's best error=0.3873,\tbest estimator xgboost's best error=0.3873\n",
      "[flaml.automl.logger: 11-01 22:14:14] {2258} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:14] {2442} INFO -  at 4.1s,\testimator xgboost's best error=0.3873,\tbest estimator xgboost's best error=0.3873\n",
      "[flaml.automl.logger: 11-01 22:14:14] {2258} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:15] {2442} INFO -  at 4.7s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:15] {2258} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:16] {2442} INFO -  at 5.3s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:16] {2258} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:17] {2442} INFO -  at 6.2s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:17] {2258} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:17] {2442} INFO -  at 7.0s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:17] {2258} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:18] {2442} INFO -  at 7.6s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:18] {2258} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:19] {2442} INFO -  at 8.3s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:19] {2258} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:20] {2442} INFO -  at 9.2s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:20] {2258} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:20] {2442} INFO -  at 9.7s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:20] {2258} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:21] {2442} INFO -  at 10.6s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:21] {2258} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:22] {2442} INFO -  at 11.2s,\testimator xgboost's best error=0.3216,\tbest estimator xgboost's best error=0.3216\n",
      "[flaml.automl.logger: 11-01 22:14:22] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:23] {2442} INFO -  at 12.2s,\testimator xgboost's best error=0.3180,\tbest estimator xgboost's best error=0.3180\n",
      "[flaml.automl.logger: 11-01 22:14:23] {2258} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:24] {2442} INFO -  at 13.2s,\testimator xgboost's best error=0.3180,\tbest estimator xgboost's best error=0.3180\n",
      "[flaml.automl.logger: 11-01 22:14:24] {2258} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:27] {2442} INFO -  at 16.6s,\testimator xgboost's best error=0.3168,\tbest estimator xgboost's best error=0.3168\n",
      "[flaml.automl.logger: 11-01 22:14:27] {2258} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:33] {2442} INFO -  at 23.0s,\testimator xgboost's best error=0.3046,\tbest estimator xgboost's best error=0.3046\n",
      "[flaml.automl.logger: 11-01 22:14:33] {2258} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:35] {2442} INFO -  at 25.0s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:35] {2258} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:39] {2442} INFO -  at 28.3s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:39] {2258} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:40] {2442} INFO -  at 29.6s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:40] {2258} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:42] {2442} INFO -  at 31.3s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:42] {2258} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:45] {2442} INFO -  at 34.2s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:45] {2258} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:47] {2442} INFO -  at 36.7s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:47] {2258} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:49] {2442} INFO -  at 38.3s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:49] {2258} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:50] {2442} INFO -  at 39.3s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:50] {2258} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:56] {2442} INFO -  at 46.1s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:56] {2258} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:14:58] {2442} INFO -  at 47.9s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:14:58] {2258} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:00] {2442} INFO -  at 50.1s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:15:00] {2258} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:05] {2442} INFO -  at 54.6s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:15:05] {2258} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:06] {2442} INFO -  at 56.0s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:15:06] {2258} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:08] {2442} INFO -  at 57.5s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:15:08] {2258} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:10] {2442} INFO -  at 60.0s,\testimator xgboost's best error=0.2942,\tbest estimator xgboost's best error=0.2942\n",
      "[flaml.automl.logger: 11-01 22:15:10] {2258} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:14] {2442} INFO -  at 63.7s,\testimator xgboost's best error=0.2938,\tbest estimator xgboost's best error=0.2938\n",
      "[flaml.automl.logger: 11-01 22:15:14] {2258} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:16] {2442} INFO -  at 65.6s,\testimator xgboost's best error=0.2938,\tbest estimator xgboost's best error=0.2938\n",
      "[flaml.automl.logger: 11-01 22:15:16] {2258} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:22] {2442} INFO -  at 71.7s,\testimator xgboost's best error=0.2938,\tbest estimator xgboost's best error=0.2938\n",
      "[flaml.automl.logger: 11-01 22:15:22] {2258} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:26] {2442} INFO -  at 75.7s,\testimator xgboost's best error=0.2938,\tbest estimator xgboost's best error=0.2938\n",
      "[flaml.automl.logger: 11-01 22:15:26] {2258} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:39] {2442} INFO -  at 88.2s,\testimator xgboost's best error=0.2861,\tbest estimator xgboost's best error=0.2861\n",
      "[flaml.automl.logger: 11-01 22:15:39] {2258} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:15:42] {2442} INFO -  at 91.9s,\testimator xgboost's best error=0.2861,\tbest estimator xgboost's best error=0.2861\n",
      "[flaml.automl.logger: 11-01 22:15:42] {2258} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:16:15] {2442} INFO -  at 124.3s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:16:15] {2258} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:16:27] {2442} INFO -  at 136.6s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:16:27] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:17:31] {2442} INFO -  at 200.3s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:17:31] {2258} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:17:48] {2442} INFO -  at 217.3s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:17:48] {2258} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:18:04] {2442} INFO -  at 233.2s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:18:04] {2258} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:18:54] {2442} INFO -  at 283.6s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:18:54] {2258} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:19:24] {2442} INFO -  at 313.5s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:19:24] {2258} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:19:52] {2442} INFO -  at 341.3s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:19:52] {2258} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:20:20] {2442} INFO -  at 369.4s,\testimator xgboost's best error=0.2854,\tbest estimator xgboost's best error=0.2854\n",
      "[flaml.automl.logger: 11-01 22:20:20] {2258} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:20:44] {2442} INFO -  at 394.0s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:20:44] {2258} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:21:24] {2442} INFO -  at 433.8s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:21:24] {2258} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:22:02] {2442} INFO -  at 471.5s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:22:02] {2258} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:22:14] {2442} INFO -  at 483.8s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:22:14] {2258} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:25:17] {2442} INFO -  at 666.8s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:25:17] {2258} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:25:34] {2442} INFO -  at 684.0s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:25:34] {2258} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:26:06] {2442} INFO -  at 715.3s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:26:06] {2258} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:26:23] {2442} INFO -  at 733.0s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:26:23] {2258} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:27:13] {2442} INFO -  at 782.4s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:27:13] {2258} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:28:52] {2442} INFO -  at 881.6s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:28:52] {2258} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:28:58] {2442} INFO -  at 887.9s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:28:58] {2258} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:29:10] {2442} INFO -  at 899.7s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:29:10] {2258} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:32:40] {2442} INFO -  at 1109.9s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:32:40] {2258} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:32:44] {2442} INFO -  at 1113.3s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:32:44] {2258} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:36:40] {2442} INFO -  at 1349.7s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:36:40] {2258} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:37:26] {2442} INFO -  at 1395.3s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:37:26] {2258} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:37:41] {2442} INFO -  at 1410.5s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:37:41] {2258} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:37:51] {2442} INFO -  at 1420.6s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:37:51] {2258} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:38:52] {2442} INFO -  at 1482.0s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:38:52] {2258} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:39:56] {2442} INFO -  at 1546.0s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:39:56] {2258} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:40:15] {2442} INFO -  at 1564.6s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:40:15] {2258} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:42:12] {2442} INFO -  at 1681.4s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:42:12] {2258} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:42:19] {2442} INFO -  at 1689.0s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:42:19] {2258} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:43:45] {2442} INFO -  at 1774.4s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:43:45] {2258} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:43:50] {2442} INFO -  at 1780.1s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:43:50] {2258} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:44:16] {2442} INFO -  at 1805.9s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:44:16] {2258} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:44:56] {2442} INFO -  at 1845.4s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:44:56] {2258} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:45:21] {2442} INFO -  at 1870.8s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:45:21] {2258} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:45:51] {2442} INFO -  at 1901.0s,\testimator xgboost's best error=0.2838,\tbest estimator xgboost's best error=0.2838\n",
      "[flaml.automl.logger: 11-01 22:45:51] {2258} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:47:05] {2442} INFO -  at 1974.7s,\testimator xgboost's best error=0.2813,\tbest estimator xgboost's best error=0.2813\n",
      "[flaml.automl.logger: 11-01 22:47:05] {2258} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:47:30] {2442} INFO -  at 1999.5s,\testimator xgboost's best error=0.2813,\tbest estimator xgboost's best error=0.2813\n",
      "[flaml.automl.logger: 11-01 22:47:30] {2258} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:51:22] {2442} INFO -  at 2231.8s,\testimator xgboost's best error=0.2813,\tbest estimator xgboost's best error=0.2813\n",
      "[flaml.automl.logger: 11-01 22:51:22] {2258} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:51:46] {2442} INFO -  at 2255.4s,\testimator xgboost's best error=0.2813,\tbest estimator xgboost's best error=0.2813\n",
      "[flaml.automl.logger: 11-01 22:51:46] {2258} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:52:36] {2442} INFO -  at 2306.1s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 22:52:36] {2258} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:53:49] {2442} INFO -  at 2378.5s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 22:53:49] {2258} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:55:44] {2442} INFO -  at 2493.4s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 22:55:44] {2258} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:56:10] {2442} INFO -  at 2520.0s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 22:56:10] {2258} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:56:27] {2442} INFO -  at 2536.8s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 22:56:27] {2258} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 22:59:18] {2442} INFO -  at 2707.9s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 22:59:18] {2258} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:00:27] {2442} INFO -  at 2776.5s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:00:27] {2258} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:01:15] {2442} INFO -  at 2824.6s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:01:15] {2258} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:01:55] {2442} INFO -  at 2864.8s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:01:55] {2258} INFO - iteration 90, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:02:57] {2442} INFO -  at 2926.8s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:02:57] {2258} INFO - iteration 91, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:05:38] {2442} INFO -  at 3087.2s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:05:38] {2258} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:05:53] {2442} INFO -  at 3103.1s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:05:53] {2258} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:06:06] {2442} INFO -  at 3115.6s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:06:06] {2258} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:09:39] {2442} INFO -  at 3328.5s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:09:39] {2258} INFO - iteration 95, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:10:31] {2442} INFO -  at 3381.1s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:10:31] {2258} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:11:18] {2442} INFO -  at 3427.3s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:11:18] {2258} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:13:05] {2442} INFO -  at 3535.1s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:13:05] {2258} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:13:40] {2442} INFO -  at 3569.4s,\testimator xgboost's best error=0.2810,\tbest estimator xgboost's best error=0.2810\n",
      "[flaml.automl.logger: 11-01 23:14:31] {2685} INFO - retrain xgboost for 51.2s\n",
      "[flaml.automl.logger: 11-01 23:14:31] {2688} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=1.0, colsample_bynode=None,\n",
      "              colsample_bytree=0.8447620742715861, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.056604412387466024,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=47,\n",
      "              min_child_weight=0.7910763321600376, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=1150,\n",
      "              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 11-01 23:14:31] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-01 23:14:31] {1986} INFO - Time taken to find the best model: 2306.1316220760345\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "auto_ml = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*60,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"estimator_list\" : ['xgboost']  }   \n",
    "auto_ml.fit(train_ft, target, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7190496981014807"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- auto_ml.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1150,\n",
       " 'max_leaves': 47,\n",
       " 'min_child_weight': 0.7910763321600376,\n",
       " 'learning_rate': 0.056604412387466024,\n",
       " 'subsample': 0.8235981634894725,\n",
       " 'colsample_bylevel': 1.0,\n",
       " 'colsample_bytree': 0.8447620742715861,\n",
       " 'reg_alpha': 0.0011926146429896113,\n",
       " 'reg_lambda': 2.9660853748175002}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = auto_ml.predict(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-01 23:29:09] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-01 23:29:09] {1739} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 11-01 23:29:09] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-01 23:29:09] {1955} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 11-01 23:29:09] {2258} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:29:16] {2393} INFO - Estimated sufficient time budget=67793s. Estimated necessary time budget=68s.\n",
      "[flaml.automl.logger: 11-01 23:29:16] {2442} INFO -  at 8.2s,\testimator xgboost's best error=0.6223,\tbest estimator xgboost's best error=0.6223\n",
      "[flaml.automl.logger: 11-01 23:29:16] {2258} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:29:23] {2442} INFO -  at 15.4s,\testimator xgboost's best error=0.6223,\tbest estimator xgboost's best error=0.6223\n",
      "[flaml.automl.logger: 11-01 23:29:23] {2258} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:29:30] {2442} INFO -  at 22.5s,\testimator xgboost's best error=0.3885,\tbest estimator xgboost's best error=0.3885\n",
      "[flaml.automl.logger: 11-01 23:29:30] {2258} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:29:37] {2442} INFO -  at 29.4s,\testimator xgboost's best error=0.3885,\tbest estimator xgboost's best error=0.3885\n",
      "[flaml.automl.logger: 11-01 23:29:37] {2258} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:29:45] {2442} INFO -  at 37.4s,\testimator xgboost's best error=0.3129,\tbest estimator xgboost's best error=0.3129\n",
      "[flaml.automl.logger: 11-01 23:29:45] {2258} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:29:52] {2442} INFO -  at 44.4s,\testimator xgboost's best error=0.3129,\tbest estimator xgboost's best error=0.3129\n",
      "[flaml.automl.logger: 11-01 23:29:52] {2258} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:30:05] {2442} INFO -  at 56.7s,\testimator xgboost's best error=0.3070,\tbest estimator xgboost's best error=0.3070\n",
      "[flaml.automl.logger: 11-01 23:30:05] {2258} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:30:24] {2442} INFO -  at 76.2s,\testimator xgboost's best error=0.2944,\tbest estimator xgboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-01 23:30:24] {2258} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:30:36] {2442} INFO -  at 88.3s,\testimator xgboost's best error=0.2944,\tbest estimator xgboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-01 23:30:36] {2258} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:31:04] {2442} INFO -  at 115.6s,\testimator xgboost's best error=0.2944,\tbest estimator xgboost's best error=0.2944\n",
      "[flaml.automl.logger: 11-01 23:31:04] {2258} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:31:35] {2442} INFO -  at 146.8s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-01 23:31:35] {2258} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:31:53] {2442} INFO -  at 165.4s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-01 23:31:53] {2258} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:32:59] {2442} INFO -  at 231.2s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-01 23:32:59] {2258} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:33:14] {2442} INFO -  at 246.0s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-01 23:33:14] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:34:59] {2442} INFO -  at 351.4s,\testimator xgboost's best error=0.2841,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-01 23:34:59] {2258} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:36:29] {2442} INFO -  at 441.4s,\testimator xgboost's best error=0.2841,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-01 23:36:29] {2258} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:40:05] {2442} INFO -  at 656.6s,\testimator xgboost's best error=0.2828,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-01 23:40:05] {2258} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:52:34] {2442} INFO -  at 1406.3s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-01 23:52:34] {2258} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 23:56:07] {2442} INFO -  at 1619.3s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-01 23:56:07] {2258} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 00:15:21] {2442} INFO -  at 2772.9s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 00:15:21] {2258} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 00:25:07] {2442} INFO -  at 3359.1s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 00:25:07] {2258} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 00:30:48] {2442} INFO -  at 3699.8s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 00:30:48] {2258} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:01:19] {2442} INFO -  at 5530.9s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 01:01:19] {2258} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:18:42] {2442} INFO -  at 6573.7s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 01:19:57] {2685} INFO - retrain xgboost for 74.9s\n",
      "[flaml.automl.logger: 11-02 01:19:57] {2688} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.8734795776739355, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01581486020173773,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=27,\n",
      "              min_child_weight=1.6569101873119776, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=2303,\n",
      "              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 11-02 01:19:57] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-02 01:19:57] {1986} INFO - Time taken to find the best model: 1406.313464641571\n",
      "Best model: xgboost\n",
      "Best hyperparameters: {'n_estimators': 2303, 'max_leaves': 27, 'min_child_weight': 1.6569101873119776, 'learning_rate': 0.01581486020173773, 'subsample': 0.9299273637168837, 'colsample_bylevel': 0.8734795776739355, 'colsample_bytree': 1.0, 'reg_alpha': 0.0069961689373672555, 'reg_lambda': 2.7943035599446273}\n",
      "Best macro F1 score: 0.2816061153606407\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "auto_ml = AutoML()\n",
    "params = {\n",
    "    \"metric\": \"macro_f1\",                # 평가 지표\n",
    "    \"task\": \"classification\",            # 분류 작업\n",
    "    \"time_budget\": 2 * 60 * 60,          # 시간 제한 (2시간)\n",
    "    \"seed\": 42,                          # 랜덤 시드 설정\n",
    "    \"early_stop\": True,                  # 조기 종료 활성화\n",
    "    \"estimator_list\": [\"xgboost\"],  # 사용 모델 리스트\n",
    "    \"eval_method\": \"cv\",                 # 교차 검증\n",
    "    \"n_splits\": 10,                      # Stratified K-Fold로 10분할 교차 검증\n",
    "    \"log_type\": \"plain_text\"             # 로그 출력 형식 설정\n",
    "}  \n",
    "auto_ml.fit(train_ft, target, **params)\n",
    "\n",
    "print(\"Best model:\", auto_ml.best_estimator)\n",
    "print(\"Best hyperparameters:\", auto_ml.best_config)\n",
    "print(\"Best macro F1 score:\", auto_ml.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7183938846393594"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-auto_ml.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = auto_ml.predict(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-02 01:29:22] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-02 01:29:22] {1739} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 11-02 01:29:22] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-02 01:29:22] {1955} INFO - List of ML learners in AutoML Run: ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2', 'kneighbor']\n",
      "[flaml.automl.logger: 11-02 01:29:22] {2258} INFO - iteration 0, current learner catboost\n",
      "[flaml.automl.logger: 11-02 01:30:00] {2393} INFO - Estimated sufficient time budget=377128s. Estimated necessary time budget=592s.\n",
      "[flaml.automl.logger: 11-02 01:30:00] {2442} INFO -  at 39.2s,\testimator catboost's best error=0.2928,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-02 01:30:00] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:30:07] {2442} INFO -  at 46.8s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-02 01:30:07] {2258} INFO - iteration 2, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:30:17] {2442} INFO -  at 56.3s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-02 01:30:17] {2258} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:30:24] {2442} INFO -  at 63.1s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-02 01:30:24] {2258} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:30:26] {2442} INFO -  at 65.9s,\testimator rf's best error=0.4727,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-02 01:30:26] {2258} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:30:29] {2442} INFO -  at 68.9s,\testimator rf's best error=0.4727,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-02 01:30:29] {2258} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:30:37] {2442} INFO -  at 76.2s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2928\n",
      "[flaml.automl.logger: 11-02 01:30:37] {2258} INFO - iteration 7, current learner catboost\n",
      "[flaml.automl.logger: 11-02 01:31:25] {2442} INFO -  at 124.0s,\testimator catboost's best error=0.2916,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:25] {2258} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:31:28] {2442} INFO -  at 127.0s,\testimator rf's best error=0.3828,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:28] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:31:35] {2442} INFO -  at 134.0s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:35] {2258} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:31:42] {2442} INFO -  at 141.1s,\testimator lgbm's best error=0.3834,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:42] {2258} INFO - iteration 11, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:31:45] {2442} INFO -  at 144.1s,\testimator rf's best error=0.3674,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:45] {2258} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:31:48] {2442} INFO -  at 147.1s,\testimator rf's best error=0.3674,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:48] {2258} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:31:51] {2442} INFO -  at 150.6s,\testimator rf's best error=0.3674,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:51] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:31:58] {2442} INFO -  at 157.5s,\testimator xgboost's best error=0.3885,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:31:58] {2258} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:32:02] {2442} INFO -  at 161.7s,\testimator rf's best error=0.3568,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:32:02] {2258} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:32:09] {2442} INFO -  at 168.6s,\testimator xgboost's best error=0.3885,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:32:09] {2258} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:32:17] {2442} INFO -  at 176.1s,\testimator lgbm's best error=0.3189,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:32:17] {2258} INFO - iteration 18, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:32:27] {2442} INFO -  at 186.0s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:32:27] {2258} INFO - iteration 19, current learner catboost\n",
      "[flaml.automl.logger: 11-02 01:33:45] {2442} INFO -  at 264.8s,\testimator catboost's best error=0.2916,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:33:45] {2258} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:33:53] {2442} INFO -  at 272.4s,\testimator xgboost's best error=0.3129,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:33:53] {2258} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:33:57] {2442} INFO -  at 276.4s,\testimator rf's best error=0.3521,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:33:57] {2258} INFO - iteration 22, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:34:01] {2442} INFO -  at 280.2s,\testimator rf's best error=0.3521,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:34:01] {2258} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:34:08] {2442} INFO -  at 287.7s,\testimator lgbm's best error=0.3189,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:34:08] {2258} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:34:17] {2442} INFO -  at 296.5s,\testimator lgbm's best error=0.3110,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:34:17] {2258} INFO - iteration 25, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:34:27] {2442} INFO -  at 306.8s,\testimator histgb's best error=0.3579,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:34:27] {2258} INFO - iteration 26, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:34:42] {2442} INFO -  at 321.4s,\testimator histgb's best error=0.3428,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:34:42] {2258} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:34:47] {2442} INFO -  at 326.2s,\testimator rf's best error=0.3521,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:34:47] {2258} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:34:54] {2442} INFO -  at 332.9s,\testimator xgboost's best error=0.3129,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:34:54] {2258} INFO - iteration 29, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:35:03] {2442} INFO -  at 342.5s,\testimator histgb's best error=0.3428,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:35:03] {2258} INFO - iteration 30, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:35:15] {2442} INFO -  at 354.5s,\testimator histgb's best error=0.3428,\tbest estimator catboost's best error=0.2916\n",
      "[flaml.automl.logger: 11-02 01:35:15] {2258} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:35:24] {2442} INFO -  at 363.8s,\testimator lgbm's best error=0.2910,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:35:24] {2258} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:35:33] {2442} INFO -  at 372.7s,\testimator lgbm's best error=0.2910,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:35:33] {2258} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:35:43] {2442} INFO -  at 382.7s,\testimator lgbm's best error=0.2910,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:35:43] {2258} INFO - iteration 34, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:36:10] {2442} INFO -  at 409.9s,\testimator histgb's best error=0.3022,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:36:10] {2258} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:36:21] {2442} INFO -  at 420.0s,\testimator lgbm's best error=0.2910,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:36:21] {2258} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:36:24] {2442} INFO -  at 423.5s,\testimator rf's best error=0.3398,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:36:24] {2258} INFO - iteration 37, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:36:42] {2442} INFO -  at 441.3s,\testimator histgb's best error=0.3022,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:36:42] {2258} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:36:45] {2442} INFO -  at 444.9s,\testimator rf's best error=0.3384,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:36:45] {2258} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:36:49] {2442} INFO -  at 448.2s,\testimator rf's best error=0.3384,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:36:49] {2258} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:36:53] {2442} INFO -  at 452.4s,\testimator rf's best error=0.3313,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:36:53] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:37:04] {2442} INFO -  at 463.6s,\testimator xgboost's best error=0.3070,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:37:04] {2258} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:37:21] {2442} INFO -  at 480.3s,\testimator xgboost's best error=0.2944,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:37:21] {2258} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 11-02 01:37:55] {2442} INFO -  at 514.8s,\testimator catboost's best error=0.2916,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:37:55] {2258} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:38:07] {2442} INFO -  at 526.9s,\testimator xgboost's best error=0.2944,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:38:07] {2258} INFO - iteration 45, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:38:55] {2442} INFO -  at 574.6s,\testimator histgb's best error=0.2946,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:38:55] {2258} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:39:15] {2442} INFO -  at 594.4s,\testimator xgboost's best error=0.2944,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:39:15] {2258} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:39:19] {2442} INFO -  at 598.2s,\testimator rf's best error=0.3313,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:39:19] {2258} INFO - iteration 48, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:39:23] {2442} INFO -  at 602.7s,\testimator rf's best error=0.3313,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:39:23] {2258} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:39:38] {2442} INFO -  at 617.2s,\testimator lgbm's best error=0.2910,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:39:38] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:39:42] {2442} INFO -  at 621.2s,\testimator rf's best error=0.3313,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:39:42] {2258} INFO - iteration 51, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:40:23] {2442} INFO -  at 662.8s,\testimator histgb's best error=0.2930,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:40:23] {2258} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:40:28] {2442} INFO -  at 667.1s,\testimator rf's best error=0.3313,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:40:28] {2258} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:40:31] {2442} INFO -  at 670.8s,\testimator rf's best error=0.3313,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:40:31] {2258} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:40:39] {2442} INFO -  at 678.5s,\testimator lgbm's best error=0.2910,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:40:39] {2258} INFO - iteration 55, current learner catboost\n",
      "[flaml.automl.logger: 11-02 01:41:34] {2442} INFO -  at 733.7s,\testimator catboost's best error=0.2916,\tbest estimator lgbm's best error=0.2910\n",
      "[flaml.automl.logger: 11-02 01:41:34] {2258} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:42:03] {2442} INFO -  at 762.9s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:42:03] {2258} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:42:12] {2442} INFO -  at 771.5s,\testimator lgbm's best error=0.2910,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:42:12] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:42:16] {2442} INFO -  at 775.9s,\testimator rf's best error=0.3313,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:42:16] {2258} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:42:22] {2442} INFO -  at 781.0s,\testimator rf's best error=0.3247,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:42:22] {2258} INFO - iteration 60, current learner catboost\n",
      "[flaml.automl.logger: 11-02 01:42:52] {2442} INFO -  at 811.6s,\testimator catboost's best error=0.2916,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:42:52] {2258} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:42:59] {2442} INFO -  at 818.0s,\testimator rf's best error=0.3161,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:42:59] {2258} INFO - iteration 62, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:43:04] {2442} INFO -  at 823.2s,\testimator rf's best error=0.3161,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:43:04] {2258} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:43:08] {2442} INFO -  at 827.5s,\testimator rf's best error=0.3161,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:43:08] {2258} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:43:23] {2442} INFO -  at 842.5s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:43:23] {2258} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:43:36] {2442} INFO -  at 855.4s,\testimator lgbm's best error=0.2910,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:43:36] {2258} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:43:46] {2442} INFO -  at 865.5s,\testimator rf's best error=0.3124,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:43:46] {2258} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:44:02] {2442} INFO -  at 881.7s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:44:02] {2258} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:44:26] {2442} INFO -  at 905.8s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:44:26] {2258} INFO - iteration 69, current learner catboost\n",
      "[flaml.automl.logger: 11-02 01:45:07] {2442} INFO -  at 946.1s,\testimator catboost's best error=0.2916,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:45:07] {2258} INFO - iteration 70, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:45:15] {2442} INFO -  at 954.6s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:45:15] {2258} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:46:15] {2442} INFO -  at 1014.7s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:46:15] {2258} INFO - iteration 72, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:47:11] {2442} INFO -  at 1070.9s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:47:11] {2258} INFO - iteration 73, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:48:03] {2442} INFO -  at 1122.6s,\testimator histgb's best error=0.2930,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:48:03] {2258} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:48:16] {2442} INFO -  at 1135.1s,\testimator xgboost's best error=0.2883,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:48:16] {2258} INFO - iteration 75, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:48:32] {2442} INFO -  at 1151.0s,\testimator histgb's best error=0.2930,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:48:32] {2258} INFO - iteration 76, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:49:00] {2442} INFO -  at 1179.4s,\testimator lrl2's best error=0.2969,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:49:00] {2258} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:49:24] {2442} INFO -  at 1203.1s,\testimator lgbm's best error=0.2910,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:49:24] {2258} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 01:49:31] {2442} INFO -  at 1210.7s,\testimator lgbm's best error=0.2910,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:49:31] {2258} INFO - iteration 79, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:49:47] {2442} INFO -  at 1226.9s,\testimator lrl2's best error=0.2969,\tbest estimator xgboost's best error=0.2883\n",
      "[flaml.automl.logger: 11-02 01:49:47] {2258} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:51:19] {2442} INFO -  at 1318.8s,\testimator xgboost's best error=0.2841,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:51:19] {2258} INFO - iteration 81, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:52:14] {2442} INFO -  at 1373.7s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:52:14] {2258} INFO - iteration 82, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:52:29] {2442} INFO -  at 1388.2s,\testimator lrl2's best error=0.2969,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:52:29] {2258} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:53:47] {2442} INFO -  at 1466.0s,\testimator xgboost's best error=0.2841,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:53:47] {2258} INFO - iteration 84, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:54:02] {2442} INFO -  at 1481.2s,\testimator lrl2's best error=0.2966,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:54:02] {2258} INFO - iteration 85, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:54:18] {2442} INFO -  at 1497.4s,\testimator lrl2's best error=0.2966,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:54:18] {2258} INFO - iteration 86, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:54:32] {2442} INFO -  at 1511.6s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:54:32] {2258} INFO - iteration 87, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:54:48] {2442} INFO -  at 1527.4s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:54:48] {2258} INFO - iteration 88, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:54:59] {2442} INFO -  at 1538.8s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2841\n",
      "[flaml.automl.logger: 11-02 01:54:59] {2258} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 01:58:15] {2442} INFO -  at 1734.6s,\testimator xgboost's best error=0.2828,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 01:58:15] {2258} INFO - iteration 90, current learner rf\n",
      "[flaml.automl.logger: 11-02 01:58:25] {2442} INFO -  at 1744.3s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 01:58:25] {2258} INFO - iteration 91, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:58:41] {2442} INFO -  at 1760.6s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 01:58:41] {2258} INFO - iteration 92, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:59:13] {2442} INFO -  at 1792.4s,\testimator histgb's best error=0.2930,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 01:59:13] {2258} INFO - iteration 93, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 01:59:29] {2442} INFO -  at 1808.1s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 01:59:29] {2258} INFO - iteration 94, current learner histgb\n",
      "[flaml.automl.logger: 11-02 01:59:48] {2442} INFO -  at 1827.5s,\testimator histgb's best error=0.2930,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 01:59:48] {2258} INFO - iteration 95, current learner histgb\n",
      "[flaml.automl.logger: 11-02 02:00:52] {2442} INFO -  at 1891.2s,\testimator histgb's best error=0.2930,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:00:52] {2258} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:00:59] {2442} INFO -  at 1898.4s,\testimator lgbm's best error=0.2910,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:00:59] {2258} INFO - iteration 97, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:01:15] {2442} INFO -  at 1913.9s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:01:15] {2258} INFO - iteration 98, current learner rf\n",
      "[flaml.automl.logger: 11-02 02:01:53] {2442} INFO -  at 1952.1s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:01:53] {2258} INFO - iteration 99, current learner histgb\n",
      "[flaml.automl.logger: 11-02 02:03:12] {2442} INFO -  at 2031.9s,\testimator histgb's best error=0.2909,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:03:12] {2258} INFO - iteration 100, current learner rf\n",
      "[flaml.automl.logger: 11-02 02:03:23] {2442} INFO -  at 2042.6s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:03:23] {2258} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:03:46] {2442} INFO -  at 2065.6s,\testimator lgbm's best error=0.2910,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:03:46] {2258} INFO - iteration 102, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:04:01] {2442} INFO -  at 2080.3s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:04:01] {2258} INFO - iteration 103, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:04:07] {2442} INFO -  at 2086.4s,\testimator kneighbor's best error=0.3800,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:04:07] {2258} INFO - iteration 104, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:04:13] {2442} INFO -  at 2092.6s,\testimator kneighbor's best error=0.3677,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:04:13] {2258} INFO - iteration 105, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:05:20] {2442} INFO -  at 2159.6s,\testimator catboost's best error=0.2907,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:05:20] {2258} INFO - iteration 106, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:05:26] {2442} INFO -  at 2165.8s,\testimator kneighbor's best error=0.3585,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:05:26] {2258} INFO - iteration 107, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:05:33] {2442} INFO -  at 2172.1s,\testimator kneighbor's best error=0.3462,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:05:33] {2258} INFO - iteration 108, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:05:39] {2442} INFO -  at 2178.2s,\testimator kneighbor's best error=0.3462,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:05:39] {2258} INFO - iteration 109, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:05:45] {2442} INFO -  at 2184.6s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:05:45] {2258} INFO - iteration 110, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:05:52] {2442} INFO -  at 2191.4s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:05:52] {2258} INFO - iteration 111, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:05:58] {2442} INFO -  at 2197.6s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:05:58] {2258} INFO - iteration 112, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:06:04] {2442} INFO -  at 2203.9s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:06:04] {2258} INFO - iteration 113, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:07:22] {2442} INFO -  at 2281.5s,\testimator catboost's best error=0.2907,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:07:22] {2258} INFO - iteration 114, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:07:29] {2442} INFO -  at 2288.5s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:07:29] {2258} INFO - iteration 115, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:07:36] {2442} INFO -  at 2295.5s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:07:36] {2258} INFO - iteration 116, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:07:42] {2442} INFO -  at 2301.8s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:07:42] {2258} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:08:01] {2442} INFO -  at 2320.6s,\testimator lgbm's best error=0.2864,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:08:01] {2258} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:08:11] {2442} INFO -  at 2330.2s,\testimator lgbm's best error=0.2864,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:08:11] {2258} INFO - iteration 119, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:08:18] {2442} INFO -  at 2337.2s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:08:18] {2258} INFO - iteration 120, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:08:24] {2442} INFO -  at 2343.7s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:08:24] {2258} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:08:45] {2442} INFO -  at 2363.9s,\testimator lgbm's best error=0.2864,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:08:45] {2258} INFO - iteration 122, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:08:52] {2442} INFO -  at 2371.0s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:08:52] {2258} INFO - iteration 123, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:08:58] {2442} INFO -  at 2377.3s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:08:58] {2258} INFO - iteration 124, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:09:04] {2442} INFO -  at 2383.7s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:09:04] {2258} INFO - iteration 125, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:09:28] {2442} INFO -  at 2407.3s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:09:28] {2258} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:09:48] {2442} INFO -  at 2427.4s,\testimator lgbm's best error=0.2864,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:09:48] {2258} INFO - iteration 127, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:10:34] {2442} INFO -  at 2473.4s,\testimator catboost's best error=0.2907,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:10:34] {2258} INFO - iteration 128, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:11:30] {2442} INFO -  at 2529.8s,\testimator catboost's best error=0.2907,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:11:30] {2258} INFO - iteration 129, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:12:47] {2442} INFO -  at 2606.8s,\testimator catboost's best error=0.2907,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:12:47] {2258} INFO - iteration 130, current learner rf\n",
      "[flaml.automl.logger: 11-02 02:12:56] {2442} INFO -  at 2615.8s,\testimator rf's best error=0.3049,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:12:56] {2258} INFO - iteration 131, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:13:03] {2442} INFO -  at 2622.4s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:13:03] {2258} INFO - iteration 132, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:13:19] {2442} INFO -  at 2638.1s,\testimator lrl2's best error=0.2964,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:13:19] {2258} INFO - iteration 133, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:13:30] {2442} INFO -  at 2649.6s,\testimator lrl2's best error=0.2961,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:13:30] {2258} INFO - iteration 134, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:13:37] {2442} INFO -  at 2656.1s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:13:37] {2258} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:13:47] {2442} INFO -  at 2666.2s,\testimator lgbm's best error=0.2864,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:13:47] {2258} INFO - iteration 136, current learner rf\n",
      "[flaml.automl.logger: 11-02 02:14:51] {2442} INFO -  at 2730.5s,\testimator rf's best error=0.3029,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:14:51] {2258} INFO - iteration 137, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:15:05] {2442} INFO -  at 2744.5s,\testimator lrl2's best error=0.2961,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:15:05] {2258} INFO - iteration 138, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:15:12] {2442} INFO -  at 2751.4s,\testimator kneighbor's best error=0.3380,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:15:12] {2258} INFO - iteration 139, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:15:26] {2442} INFO -  at 2765.3s,\testimator lrl2's best error=0.2961,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:15:26] {2258} INFO - iteration 140, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:16:35] {2442} INFO -  at 2834.3s,\testimator catboost's best error=0.2903,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:16:35] {2258} INFO - iteration 141, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:16:42] {2442} INFO -  at 2841.2s,\testimator kneighbor's best error=0.3377,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:16:42] {2258} INFO - iteration 142, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:17:31] {2442} INFO -  at 2890.5s,\testimator lgbm's best error=0.2859,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:17:31] {2258} INFO - iteration 143, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:17:38] {2442} INFO -  at 2897.1s,\testimator kneighbor's best error=0.3377,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:17:38] {2258} INFO - iteration 144, current learner rf\n",
      "[flaml.automl.logger: 11-02 02:18:08] {2442} INFO -  at 2927.4s,\testimator rf's best error=0.3029,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:18:08] {2258} INFO - iteration 145, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:18:15] {2442} INFO -  at 2934.8s,\testimator kneighbor's best error=0.3377,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:18:15] {2258} INFO - iteration 146, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:18:29] {2442} INFO -  at 2948.3s,\testimator lrl2's best error=0.2961,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:18:29] {2258} INFO - iteration 147, current learner histgb\n",
      "[flaml.automl.logger: 11-02 02:19:10] {2442} INFO -  at 2989.5s,\testimator histgb's best error=0.2909,\tbest estimator xgboost's best error=0.2828\n",
      "[flaml.automl.logger: 11-02 02:19:10] {2258} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:20:00] {2442} INFO -  at 3039.6s,\testimator lgbm's best error=0.2825,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:20:00] {2258} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:20:55] {2442} INFO -  at 3094.9s,\testimator lgbm's best error=0.2825,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:20:55] {2258} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:21:32] {2442} INFO -  at 3131.4s,\testimator lgbm's best error=0.2825,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:21:32] {2258} INFO - iteration 151, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:22:37] {2442} INFO -  at 3196.4s,\testimator catboost's best error=0.2903,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:22:37] {2258} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:23:50] {2442} INFO -  at 3269.6s,\testimator lgbm's best error=0.2825,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:23:50] {2258} INFO - iteration 153, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:24:33] {2442} INFO -  at 3312.6s,\testimator lgbm's best error=0.2825,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:24:33] {2258} INFO - iteration 154, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:24:58] {2442} INFO -  at 3337.5s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:24:58] {2258} INFO - iteration 155, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:25:12] {2442} INFO -  at 3351.2s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:25:12] {2258} INFO - iteration 156, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:26:01] {2442} INFO -  at 3400.3s,\testimator catboost's best error=0.2903,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:26:01] {2258} INFO - iteration 157, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:27:27] {2442} INFO -  at 3486.6s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:27:27] {2258} INFO - iteration 158, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:27:34] {2442} INFO -  at 3493.3s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:27:34] {2258} INFO - iteration 159, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:27:40] {2442} INFO -  at 3499.5s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2825\n",
      "[flaml.automl.logger: 11-02 02:27:40] {2258} INFO - iteration 160, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 02:39:09] {2442} INFO -  at 4188.2s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:39:09] {2258} INFO - iteration 161, current learner histgb\n",
      "[flaml.automl.logger: 11-02 02:39:38] {2442} INFO -  at 4217.2s,\testimator histgb's best error=0.2909,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:39:38] {2258} INFO - iteration 162, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:39:45] {2442} INFO -  at 4224.2s,\testimator kneighbor's best error=0.3371,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:39:45] {2258} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 02:42:57] {2442} INFO -  at 4416.7s,\testimator xgboost's best error=0.2816,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:42:57] {2258} INFO - iteration 164, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:43:04] {2442} INFO -  at 4423.5s,\testimator kneighbor's best error=0.3371,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:43:04] {2258} INFO - iteration 165, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:43:10] {2442} INFO -  at 4429.9s,\testimator kneighbor's best error=0.3371,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:43:10] {2258} INFO - iteration 166, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:43:17] {2442} INFO -  at 4436.2s,\testimator kneighbor's best error=0.3371,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:43:17] {2258} INFO - iteration 167, current learner rf\n",
      "[flaml.automl.logger: 11-02 02:45:45] {2442} INFO -  at 4584.0s,\testimator rf's best error=0.3024,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:45:45] {2258} INFO - iteration 168, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:45:52] {2442} INFO -  at 4591.1s,\testimator kneighbor's best error=0.3371,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:45:52] {2258} INFO - iteration 169, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:45:59] {2442} INFO -  at 4598.1s,\testimator kneighbor's best error=0.3371,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:45:59] {2258} INFO - iteration 170, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:46:05] {2442} INFO -  at 4604.8s,\testimator kneighbor's best error=0.3371,\tbest estimator xgboost's best error=0.2816\n",
      "[flaml.automl.logger: 11-02 02:46:05] {2258} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 02:47:26] {2442} INFO -  at 4685.7s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:47:26] {2258} INFO - iteration 172, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:49:06] {2442} INFO -  at 4785.3s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:49:06] {2258} INFO - iteration 173, current learner catboost\n",
      "[flaml.automl.logger: 11-02 02:50:16] {2442} INFO -  at 4855.8s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:50:16] {2258} INFO - iteration 174, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:50:42] {2442} INFO -  at 4881.2s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:50:42] {2258} INFO - iteration 175, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:50:48] {2442} INFO -  at 4887.8s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:50:48] {2258} INFO - iteration 176, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:51:01] {2442} INFO -  at 4900.7s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:51:01] {2258} INFO - iteration 177, current learner rf\n",
      "[flaml.automl.logger: 11-02 02:56:32] {2442} INFO -  at 5231.3s,\testimator rf's best error=0.2988,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:56:32] {2258} INFO - iteration 178, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:56:39] {2442} INFO -  at 5238.4s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:56:39] {2258} INFO - iteration 179, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:57:05] {2442} INFO -  at 5264.0s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:57:05] {2258} INFO - iteration 180, current learner histgb\n",
      "[flaml.automl.logger: 11-02 02:58:26] {2442} INFO -  at 5345.3s,\testimator histgb's best error=0.2909,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:58:26] {2258} INFO - iteration 181, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 02:58:39] {2442} INFO -  at 5358.4s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:58:39] {2258} INFO - iteration 182, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:58:45] {2442} INFO -  at 5364.9s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:58:45] {2258} INFO - iteration 183, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 02:58:53] {2442} INFO -  at 5372.2s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 02:58:53] {2258} INFO - iteration 184, current learner rf\n",
      "[flaml.automl.logger: 11-02 03:01:22] {2442} INFO -  at 5521.7s,\testimator rf's best error=0.2988,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:01:22] {2258} INFO - iteration 185, current learner catboost\n",
      "[flaml.automl.logger: 11-02 03:02:57] {2442} INFO -  at 5616.6s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:02:57] {2258} INFO - iteration 186, current learner histgb\n",
      "[flaml.automl.logger: 11-02 03:03:19] {2442} INFO -  at 5638.6s,\testimator histgb's best error=0.2909,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:03:19] {2258} INFO - iteration 187, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:03:26] {2442} INFO -  at 5645.8s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:03:26] {2258} INFO - iteration 188, current learner rf\n",
      "[flaml.automl.logger: 11-02 03:08:19] {2442} INFO -  at 5938.7s,\testimator rf's best error=0.2988,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:08:19] {2258} INFO - iteration 189, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:08:26] {2442} INFO -  at 5945.4s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:08:26] {2258} INFO - iteration 190, current learner catboost\n",
      "[flaml.automl.logger: 11-02 03:09:28] {2442} INFO -  at 6007.6s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:09:28] {2258} INFO - iteration 191, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 03:27:52] {2442} INFO -  at 7111.3s,\testimator xgboost's best error=0.2816,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:27:52] {2258} INFO - iteration 192, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:27:59] {2442} INFO -  at 7118.1s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:27:59] {2258} INFO - iteration 193, current learner rf\n",
      "[flaml.automl.logger: 11-02 03:32:18] {2442} INFO -  at 7377.1s,\testimator rf's best error=0.2988,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:32:18] {2258} INFO - iteration 194, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:32:25] {2442} INFO -  at 7384.4s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:32:25] {2258} INFO - iteration 195, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 03:32:50] {2442} INFO -  at 7409.9s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:32:50] {2258} INFO - iteration 196, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:32:58] {2442} INFO -  at 7417.0s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:32:58] {2258} INFO - iteration 197, current learner histgb\n",
      "[flaml.automl.logger: 11-02 03:35:44] {2442} INFO -  at 7583.6s,\testimator histgb's best error=0.2881,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:35:44] {2258} INFO - iteration 198, current learner catboost\n",
      "[flaml.automl.logger: 11-02 03:37:13] {2442} INFO -  at 7672.6s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:37:13] {2258} INFO - iteration 199, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:37:20] {2442} INFO -  at 7679.7s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:37:20] {2258} INFO - iteration 200, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:37:27] {2442} INFO -  at 7686.4s,\testimator kneighbor's best error=0.3371,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:37:27] {2258} INFO - iteration 201, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:37:33] {2442} INFO -  at 7692.9s,\testimator kneighbor's best error=0.3368,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:37:33] {2258} INFO - iteration 202, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:37:40] {2442} INFO -  at 7699.8s,\testimator kneighbor's best error=0.3368,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:37:40] {2258} INFO - iteration 203, current learner catboost\n",
      "[flaml.automl.logger: 11-02 03:38:40] {2442} INFO -  at 7759.0s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:38:40] {2258} INFO - iteration 204, current learner rf\n",
      "[flaml.automl.logger: 11-02 03:45:01] {2442} INFO -  at 8140.0s,\testimator rf's best error=0.2988,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:01] {2258} INFO - iteration 205, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:07] {2442} INFO -  at 8146.4s,\testimator kneighbor's best error=0.3368,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:07] {2258} INFO - iteration 206, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:14] {2442} INFO -  at 8153.4s,\testimator kneighbor's best error=0.3368,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:14] {2258} INFO - iteration 207, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:20] {2442} INFO -  at 8159.7s,\testimator kneighbor's best error=0.3368,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:20] {2258} INFO - iteration 208, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:27] {2442} INFO -  at 8166.8s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:27] {2258} INFO - iteration 209, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:35] {2442} INFO -  at 8174.1s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:35] {2258} INFO - iteration 210, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:42] {2442} INFO -  at 8181.2s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:42] {2258} INFO - iteration 211, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:48] {2442} INFO -  at 8187.8s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:48] {2258} INFO - iteration 212, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:45:55] {2442} INFO -  at 8194.9s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:45:55] {2258} INFO - iteration 213, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:46:03] {2442} INFO -  at 8202.0s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:46:03] {2258} INFO - iteration 214, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:46:10] {2442} INFO -  at 8209.2s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:46:10] {2258} INFO - iteration 215, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:46:17] {2442} INFO -  at 8216.1s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:46:17] {2258} INFO - iteration 216, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:46:23] {2442} INFO -  at 8222.7s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:46:23] {2258} INFO - iteration 217, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 03:46:48] {2442} INFO -  at 8247.7s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:46:48] {2258} INFO - iteration 218, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:46:55] {2442} INFO -  at 8254.5s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:46:55] {2258} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 03:48:09] {2442} INFO -  at 8328.6s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:48:09] {2258} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 03:50:00] {2442} INFO -  at 8439.7s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:50:00] {2258} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 03:57:38] {2442} INFO -  at 8897.9s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:57:38] {2258} INFO - iteration 222, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:57:45] {2442} INFO -  at 8904.6s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:57:45] {2258} INFO - iteration 223, current learner catboost\n",
      "[flaml.automl.logger: 11-02 03:58:42] {2442} INFO -  at 8961.2s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:58:42] {2258} INFO - iteration 224, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:58:49] {2442} INFO -  at 8968.2s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:58:49] {2258} INFO - iteration 225, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 03:58:56] {2442} INFO -  at 8975.3s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 03:58:56] {2258} INFO - iteration 226, current learner catboost\n",
      "[flaml.automl.logger: 11-02 04:00:30] {2442} INFO -  at 9069.9s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:00:30] {2258} INFO - iteration 227, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 04:09:43] {2442} INFO -  at 9622.5s,\testimator xgboost's best error=0.2816,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:09:43] {2258} INFO - iteration 228, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:10:09] {2442} INFO -  at 9648.4s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:10:09] {2258} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 04:10:33] {2442} INFO -  at 9672.6s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:10:33] {2258} INFO - iteration 230, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:10:40] {2442} INFO -  at 9679.7s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:10:40] {2258} INFO - iteration 231, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:10:53] {2442} INFO -  at 9692.5s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:10:53] {2258} INFO - iteration 232, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:11:00] {2442} INFO -  at 9699.6s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:11:00] {2258} INFO - iteration 233, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:11:07] {2442} INFO -  at 9706.9s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:11:07] {2258} INFO - iteration 234, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:11:14] {2442} INFO -  at 9713.5s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:11:14] {2258} INFO - iteration 235, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:11:21] {2442} INFO -  at 9720.6s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:11:21] {2258} INFO - iteration 236, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:11:28] {2442} INFO -  at 9727.3s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:11:28] {2258} INFO - iteration 237, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:11:41] {2442} INFO -  at 9740.7s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:11:41] {2258} INFO - iteration 238, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:11:54] {2442} INFO -  at 9753.4s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:11:54] {2258} INFO - iteration 239, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:12:01] {2442} INFO -  at 9760.6s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:12:01] {2258} INFO - iteration 240, current learner histgb\n",
      "[flaml.automl.logger: 11-02 04:13:54] {2442} INFO -  at 9873.8s,\testimator histgb's best error=0.2881,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:13:54] {2258} INFO - iteration 241, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:14:07] {2442} INFO -  at 9886.6s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:14:07] {2258} INFO - iteration 242, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:14:14] {2442} INFO -  at 9893.7s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:14:14] {2258} INFO - iteration 243, current learner catboost\n",
      "[flaml.automl.logger: 11-02 04:15:14] {2442} INFO -  at 9953.8s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:15:14] {2258} INFO - iteration 244, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:15:27] {2442} INFO -  at 9966.3s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:15:27] {2258} INFO - iteration 245, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:15:40] {2442} INFO -  at 9979.0s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:15:40] {2258} INFO - iteration 246, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:15:47] {2442} INFO -  at 9986.2s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:15:47] {2258} INFO - iteration 247, current learner histgb\n",
      "[flaml.automl.logger: 11-02 04:20:21] {2442} INFO -  at 10260.2s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:20:21] {2258} INFO - iteration 248, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:20:27] {2442} INFO -  at 10266.8s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:20:27] {2258} INFO - iteration 249, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:20:41] {2442} INFO -  at 10280.5s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:20:41] {2258} INFO - iteration 250, current learner rf\n",
      "[flaml.automl.logger: 11-02 04:23:24] {2442} INFO -  at 10443.8s,\testimator rf's best error=0.2988,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:23:24] {2258} INFO - iteration 251, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:23:32] {2442} INFO -  at 10451.1s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:23:32] {2258} INFO - iteration 252, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:23:44] {2442} INFO -  at 10463.7s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:23:44] {2258} INFO - iteration 253, current learner catboost\n",
      "[flaml.automl.logger: 11-02 04:25:18] {2442} INFO -  at 10557.2s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:25:18] {2258} INFO - iteration 254, current learner histgb\n",
      "[flaml.automl.logger: 11-02 04:34:11] {2442} INFO -  at 11090.4s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:34:11] {2258} INFO - iteration 255, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:34:18] {2442} INFO -  at 11097.5s,\testimator kneighbor's best error=0.3360,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:34:18] {2258} INFO - iteration 256, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:34:25] {2442} INFO -  at 11104.0s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:34:25] {2258} INFO - iteration 257, current learner catboost\n",
      "[flaml.automl.logger: 11-02 04:35:29] {2442} INFO -  at 11168.6s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:35:29] {2258} INFO - iteration 258, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:35:36] {2442} INFO -  at 11175.4s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:35:36] {2258} INFO - iteration 259, current learner histgb\n",
      "[flaml.automl.logger: 11-02 04:36:46] {2442} INFO -  at 11245.8s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:36:46] {2258} INFO - iteration 260, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:36:53] {2442} INFO -  at 11252.3s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:36:53] {2258} INFO - iteration 261, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:37:00] {2442} INFO -  at 11259.2s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:37:00] {2258} INFO - iteration 262, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:37:06] {2442} INFO -  at 11265.9s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:37:06] {2258} INFO - iteration 263, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:37:32] {2442} INFO -  at 11291.4s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:37:32] {2258} INFO - iteration 264, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:37:38] {2442} INFO -  at 11297.8s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:37:38] {2258} INFO - iteration 265, current learner histgb\n",
      "[flaml.automl.logger: 11-02 04:44:45] {2442} INFO -  at 11724.3s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:44:45] {2258} INFO - iteration 266, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:44:52] {2442} INFO -  at 11731.2s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:44:52] {2258} INFO - iteration 267, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:44:58] {2442} INFO -  at 11737.8s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:44:58] {2258} INFO - iteration 268, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:45:05] {2442} INFO -  at 11744.4s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:45:05] {2258} INFO - iteration 269, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:45:12] {2442} INFO -  at 11751.0s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:45:12] {2258} INFO - iteration 270, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:45:18] {2442} INFO -  at 11757.6s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:45:18] {2258} INFO - iteration 271, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:45:25] {2442} INFO -  at 11764.0s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:45:25] {2258} INFO - iteration 272, current learner histgb\n",
      "[flaml.automl.logger: 11-02 04:47:07] {2442} INFO -  at 11866.7s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:47:07] {2258} INFO - iteration 273, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:47:14] {2442} INFO -  at 11873.5s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:47:14] {2258} INFO - iteration 274, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:47:40] {2442} INFO -  at 11899.2s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:47:40] {2258} INFO - iteration 275, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:47:52] {2442} INFO -  at 11911.9s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:47:52] {2258} INFO - iteration 276, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:48:05] {2442} INFO -  at 11924.4s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:48:05] {2258} INFO - iteration 277, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:48:17] {2442} INFO -  at 11936.8s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:48:17] {2258} INFO - iteration 278, current learner histgb\n",
      "[flaml.automl.logger: 11-02 04:59:03] {2442} INFO -  at 12582.2s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:59:03] {2258} INFO - iteration 279, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:59:09] {2442} INFO -  at 12588.7s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:59:09] {2258} INFO - iteration 280, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 04:59:35] {2442} INFO -  at 12614.0s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:59:35] {2258} INFO - iteration 281, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:59:41] {2442} INFO -  at 12620.8s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:59:41] {2258} INFO - iteration 282, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 04:59:48] {2442} INFO -  at 12627.6s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 04:59:48] {2258} INFO - iteration 283, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 05:01:16] {2442} INFO -  at 12715.1s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:01:16] {2258} INFO - iteration 284, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 05:01:28] {2442} INFO -  at 12727.6s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:01:28] {2258} INFO - iteration 285, current learner histgb\n",
      "[flaml.automl.logger: 11-02 05:04:16] {2442} INFO -  at 12895.1s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:04:16] {2258} INFO - iteration 286, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:04:22] {2442} INFO -  at 12901.6s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:04:22] {2258} INFO - iteration 287, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:04:29] {2442} INFO -  at 12908.3s,\testimator kneighbor's best error=0.3356,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:04:29] {2258} INFO - iteration 288, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:04:36] {2442} INFO -  at 12914.9s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:04:36] {2258} INFO - iteration 289, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:04:42] {2442} INFO -  at 12921.8s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:04:42] {2258} INFO - iteration 290, current learner histgb\n",
      "[flaml.automl.logger: 11-02 05:08:58] {2442} INFO -  at 13177.4s,\testimator histgb's best error=0.2863,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:08:58] {2258} INFO - iteration 291, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 05:14:19] {2442} INFO -  at 13498.3s,\testimator xgboost's best error=0.2816,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:14:19] {2258} INFO - iteration 292, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:14:26] {2442} INFO -  at 13505.3s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:14:26] {2258} INFO - iteration 293, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:14:32] {2442} INFO -  at 13511.9s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:14:32] {2258} INFO - iteration 294, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:14:39] {2442} INFO -  at 13518.7s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:14:39] {2258} INFO - iteration 295, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:14:46] {2442} INFO -  at 13525.5s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:14:46] {2258} INFO - iteration 296, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:14:53] {2442} INFO -  at 13532.0s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:14:53] {2258} INFO - iteration 297, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:14:59] {2442} INFO -  at 13538.8s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:14:59] {2258} INFO - iteration 298, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:15:06] {2442} INFO -  at 13545.8s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:15:06] {2258} INFO - iteration 299, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:15:13] {2442} INFO -  at 13552.6s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:15:13] {2258} INFO - iteration 300, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:15:20] {2442} INFO -  at 13559.5s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:15:20] {2258} INFO - iteration 301, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 05:15:45] {2442} INFO -  at 13584.5s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:15:45] {2258} INFO - iteration 302, current learner catboost\n",
      "[flaml.automl.logger: 11-02 05:17:06] {2442} INFO -  at 13665.4s,\testimator catboost's best error=0.2899,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:17:06] {2258} INFO - iteration 303, current learner lrl2\n",
      "[flaml.automl.logger: 11-02 05:17:19] {2442} INFO -  at 13678.3s,\testimator lrl2's best error=0.2961,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:17:19] {2258} INFO - iteration 304, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 05:19:22] {2442} INFO -  at 13801.5s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:19:22] {2258} INFO - iteration 305, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:19:29] {2442} INFO -  at 13808.2s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:19:29] {2258} INFO - iteration 306, current learner rf\n",
      "[flaml.automl.logger: 11-02 05:27:19] {2442} INFO -  at 14278.8s,\testimator rf's best error=0.2988,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:27:19] {2258} INFO - iteration 307, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:27:26] {2442} INFO -  at 14285.4s,\testimator kneighbor's best error=0.3355,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:27:26] {2258} INFO - iteration 308, current learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:27:26] {2470} INFO - stop trying learner kneighbor\n",
      "[flaml.automl.logger: 11-02 05:27:26] {2258} INFO - iteration 309, current learner lrl1\n",
      "[flaml.automl.logger: 11-02 05:29:41] {2442} INFO -  at 14420.0s,\testimator lrl1's best error=0.2953,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:29:41] {2258} INFO - iteration 310, current learner lrl1\n",
      "[flaml.automl.logger: 11-02 05:31:57] {2442} INFO -  at 14556.7s,\testimator lrl1's best error=0.2953,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:31:57] {2258} INFO - iteration 311, current learner lrl1\n",
      "[flaml.automl.logger: 11-02 05:34:11] {2442} INFO -  at 14690.7s,\testimator lrl1's best error=0.2933,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:34:11] {2258} INFO - iteration 312, current learner lgbm\n",
      "[flaml.automl.logger: 11-02 05:37:50] {2442} INFO -  at 14909.7s,\testimator lgbm's best error=0.2786,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:37:50] {2258} INFO - iteration 313, current learner lrl1\n",
      "[flaml.automl.logger: 11-02 05:39:58] {2442} INFO -  at 15037.4s,\testimator lrl1's best error=0.2912,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:39:58] {2258} INFO - iteration 314, current learner lrl1\n",
      "[flaml.automl.logger: 11-02 05:42:11] {2442} INFO -  at 15170.9s,\testimator lrl1's best error=0.2912,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 05:42:11] {2258} INFO - iteration 315, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 06:10:56] {2442} INFO -  at 16895.8s,\testimator xgboost's best error=0.2816,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 06:10:56] {2258} INFO - iteration 316, current learner lrl1\n",
      "[flaml.automl.logger: 11-02 06:13:11] {2442} INFO -  at 17030.3s,\testimator lrl1's best error=0.2912,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 06:13:11] {2258} INFO - iteration 317, current learner xgboost\n",
      "[flaml.automl.logger: 11-02 06:29:15] {2442} INFO -  at 17994.5s,\testimator xgboost's best error=0.2816,\tbest estimator lgbm's best error=0.2786\n",
      "[flaml.automl.logger: 11-02 06:29:15] {2582} INFO - [('lgbm', {'n_jobs': -1, 'n_estimators': 1852, 'num_leaves': 4, 'min_child_samples': 101, 'learning_rate': 0.10307534052139548, 'colsample_bytree': 0.7777111765274982, 'reg_alpha': 0.09452200380404109, 'reg_lambda': 17.38285461630384, 'max_bin': 31, 'verbose': -1}), ('xgboost', {'n_jobs': -1, 'n_estimators': 2303, 'max_leaves': 27, 'min_child_weight': 1.6569101873119776, 'learning_rate': 0.01581486020173773, 'subsample': 0.9299273637168837, 'colsample_bylevel': 0.8734795776739355, 'colsample_bytree': 1.0, 'reg_alpha': 0.0069961689373672555, 'reg_lambda': 2.7943035599446273, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('histgb', {'min_samples_leaf': 14, 'learning_rate': 0.09783887942872364, 'l2_regularization': 314.82106367212845, 'max_iter': 349, 'max_bins': 63, 'max_leaf_nodes': 1431, 'random_state': 24092023, 'verbose': 0}), ('catboost', {'early_stopping_rounds': 12, 'learning_rate': 0.03828531231633576, 'n_estimators': 208, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('lrl1', {'n_jobs': -1, 'C': 0.03125, 'tol': 0.0001, 'solver': 'saga', 'penalty': 'l1'}), ('lrl2', {'n_jobs': -1, 'C': 0.035713362202358226, 'tol': 0.0001, 'solver': 'lbfgs', 'penalty': 'l2'}), ('rf', {'n_jobs': -1, 'n_estimators': 646, 'max_features': 0.12571087081362692, 'criterion': 'entropy', 'max_leaf_nodes': 1042, 'random_state': 12032022, 'verbose': 0}), ('kneighbor', {'n_jobs': -1, 'n_neighbors': 104, 'weights': 'distance'})]\n",
      "[flaml.automl.logger: 11-02 06:29:15] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 11-02 06:44:15] {2631} INFO - ensemble: StackingClassifier(estimators=[('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x00000219A84C4190>),\n",
      "                               ('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x00000219A84C66B0>),\n",
      "                               ('histgb',\n",
      "                                <flaml.automl.contrib.histgb.HistGradientBoostingEstimator object at 0x00000219A813D300>),\n",
      "                               ('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x00000219A8...\n",
      "                                                 importance_type=None,\n",
      "                                                 interaction_constraints=None,\n",
      "                                                 learning_rate=None,\n",
      "                                                 max_bin=None,\n",
      "                                                 max_cat_threshold=None,\n",
      "                                                 max_cat_to_onehot=None,\n",
      "                                                 max_delta_step=None,\n",
      "                                                 max_depth=None,\n",
      "                                                 max_leaves=None,\n",
      "                                                 min_child_weight=None,\n",
      "                                                 missing=nan,\n",
      "                                                 monotone_constraints=None,\n",
      "                                                 multi_strategy=None,\n",
      "                                                 n_estimators=None, n_jobs=None,\n",
      "                                                 num_parallel_tree=None,\n",
      "                                                 random_state=None, ...),\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 11-02 06:44:15] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-02 06:44:15] {1986} INFO - Time taken to find the best model: 4685.7319440841675\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*60*5,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"eval_method\": \"cv\",                 # 교차 검증\n",
    "           \"n_splits\": 10,                      # Stratified K-Fold로 10분할 교차 검증\n",
    "           \"ensemble\" : {'final_estimator' : XGBClassifier() },    # 메타모델이 로지스틱 회귀!\n",
    "           \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2', 'kneighbor']  }   # 앙상블에 사용할 모델 지정\n",
    "\n",
    "auto_ml_ens.fit(train_ft, target, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = auto_ml_ens.predict(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.721442073758231"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - auto_ml_ens.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1852,\n",
       " 'num_leaves': 4,\n",
       " 'min_child_samples': 101,\n",
       " 'learning_rate': 0.10307534052139548,\n",
       " 'log_max_bin': 5,\n",
       " 'colsample_bytree': 0.7777111765274982,\n",
       " 'reg_alpha': 0.09452200380404109,\n",
       " 'reg_lambda': 17.38285461630384}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_ens.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lgbm'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_ens.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "params = auto_ml_ens.best_config\n",
    "model = LGBMClassifier(**params, random_state= 42)\n",
    "model.fit(train_ft, target)\n",
    "pred = model.predict(test_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcnCtcWPVrKn"
   },
   "source": [
    "# 평가를 위한 제출 파일 생성\n",
    "- 예측 결과를 target 컬럼에 넣어 csv 파일로 저장후에 제출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LLHqOugmVq_v"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12220</th>\n",
       "      <td>test_12220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>test_12221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222</th>\n",
       "      <td>test_12222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12223</th>\n",
       "      <td>test_12223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12224</th>\n",
       "      <td>test_12224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  target\n",
       "0          test_0     0.0\n",
       "1          test_1     0.0\n",
       "2          test_2     0.0\n",
       "3          test_3     1.0\n",
       "4          test_4     0.0\n",
       "...           ...     ...\n",
       "12220  test_12220     1.0\n",
       "12221  test_12221     0.0\n",
       "12222  test_12222     0.0\n",
       "12223  test_12223     0.0\n",
       "12224  test_12224     0.0\n",
       "\n",
       "[12225 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[\"target\"] = pred\n",
    "submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjw87GeIV-BP"
   },
   "source": [
    "- 예측 결과를 csv 파일로 저장하여 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SsLTeJeoWBc_"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Submit_csv/\"\n",
    "submit.to_csv(f\"{DATA_PATH}submit_v2.0_lgbm.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pO33hCMNWBaM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVxvAdrvWBXQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSU2eoSNVGn4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
