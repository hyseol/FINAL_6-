{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zknWXgof5u-B"
   },
   "source": [
    "# 컴피티션 링크\n",
    "- https://www.kaggle.com/t/2e45abe9f1434b59a3358365432a48bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "N44QYORV8wFy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhUuXRB5BCFE"
   },
   "source": [
    "- 데이터 경로 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "NfX2HPof87FT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/Desktop/데이터분석/05 Project_Final/Data/'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Data/\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd7JpzNBHa1"
   },
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "KFGKUIWt89fZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523105, 7), (14940, 2), (441196, 7), (12225, 2))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_tr = pd.read_csv(f\"{DATA_PATH}store_train_transactions.csv\") # 학습용 구매기록 데이터\n",
    "train_target = pd.read_csv(f\"{DATA_PATH}store_train.csv\") # 학습용 정답 데이터\n",
    "test_tr = pd.read_csv(f\"{DATA_PATH}store_test_transactions.csv\") # 테스트용 구매기록 데이터\n",
    "submit = pd.read_csv(f\"{DATA_PATH}store_submission.csv\") # 제출 양식 데이터\n",
    "\n",
    "train_tr.shape , train_target.shape , test_tr.shape , submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tr.isnull().sum().sum(), test_tr.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r43SCHUujW-f"
   },
   "source": [
    "# 특성 공학(Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONQYpWOjlbE9"
   },
   "source": [
    "## 날짜 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "SYPmQb7dlVTu"
   },
   "outputs": [],
   "source": [
    "train_tr[\"구매일시\"] = pd.to_datetime(train_tr[\"구매일시\"])\n",
    "test_tr[\"구매일시\"] = pd.to_datetime(test_tr[\"구매일시\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzdFiwxsrFa4"
   },
   "source": [
    "## 새로 만든 feature와 병합할 고객ID로만 이루어진 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Is0n2MKZrMWp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1), (12225, 1))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_target[[\"ID\"]]\n",
    "test_ft = submit[[\"ID\"]]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arH5g0kMmCTa"
   },
   "source": [
    "## 구매일시를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2004년 5월 ~ 2005년 4월 공휴일 리스트\n",
    "holiday_2004 = [\"2004-05-05\", \"2004-05-26\", \"2004-06-06\",\n",
    "                \"2004-07-17\", \"2004-08-15\", \"2004-09-27\",\n",
    "                \"2004-09-28\", \"2004-09-29\", \"2004-10-03\", \"2004-12-25\"]\n",
    "\n",
    "holiday_2005 = [\"2005-01-01\", \"2005-02-08\", \"2005-02-09\",\n",
    "                \"2005-02-10\", \"2005-03-01\", \"2005-04-05\"]\n",
    "\n",
    "holidays = pd.to_datetime(holiday_2004 + holiday_2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "OJt2fPnXmAsM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 72), (12225, 72))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "        # 컬럼명, 집계 방식\n",
    "        ('내점일수', lambda x: x.dt.date.nunique()),       # 내점일수 수정 : 날짜만 선택해서 nuique\n",
    "        ('구매주기', lambda x: int( (x.max() - x.min()).days / x.dt.date.nunique()) ),\n",
    "        ('주말방문비율', lambda x: np.mean(x.dt.weekday>4)),\n",
    "        ('평일방문비율', lambda x: np.mean(x.dt.weekday<=4)),        # 평일방문비율 추가\n",
    "        ('주말방문횟수', lambda x: np.sum(x.dt.weekday>4)),         # 주말방문횟수 추가\n",
    "        ('평일방문횟수', lambda x: np.sum(x.dt.weekday<=4)),        # 평일방문횟수 추가\n",
    "\n",
    "        ('봄_구매비율', lambda x: np.mean(x.dt.month.isin([3,4,5]))),\n",
    "        ('여름_구매비율', lambda x: np.mean(x.dt.month.isin([6,7,8]))),\n",
    "        ('가을_구매비율', lambda x: np.mean(x.dt.month.isin([9,10,11]))),\n",
    "        ('겨울_구매비율', lambda x: np.mean(x.dt.month.isin([1,2,12]))),\n",
    "        ('주구매요일', lambda x: x.dt.weekday.mode()[0]),\n",
    "        (\"주_구매_월\", lambda x: x.dt.month.mode()[0]),              # 주구매 월 추가\n",
    "        (\"주_구매시간대\", lambda x: x.dt.hour.mode()[0]),            # 주구매 시간대 추가\n",
    "        ('일별평균구매횟수', lambda x:  x.count() / x.dt.date.nunique() ),\n",
    "        ('거래개월수', lambda x: x.dt.date.astype(str).str[:-3].nunique() ),\n",
    "        \n",
    "        ('아침_구매비율', lambda x: np.mean(x.dt.hour.isin(range(6, 12)))),       # 시간대 별 구매비율 추가\n",
    "        ('점심_구매비율', lambda x: np.mean(x.dt.hour.isin(range(12, 18)))),      # 시간대 별 구매비율 추가\n",
    "        ('저녁_구매비율', lambda x:np.mean(x.dt.hour.isin(range(18, 22)))),       # 시간대 별 구매비율 추가\n",
    "        ('야간_구매비율', lambda x:np.mean(~x.dt.hour.isin(range(6, 22)))),       # 시간대 별 구매비율 추가\n",
    "\n",
    "        ('아침_구매횟수', lambda x: np.sum(x.dt.hour.isin(range(6, 12)))),       # 시간대 별 구매건수 추가\n",
    "        ('점심_구매횟수', lambda x: np.sum(x.dt.hour.isin(range(12, 18)))),      # 시간대 별 구매건수 추가\n",
    "        ('저녁_구매횟수', lambda x:np.sum(x.dt.hour.isin(range(18, 22)))),       # 시간대 별 구매건수 추가\n",
    "        ('야간_구매횟수', lambda x:np.sum(~x.dt.hour.isin(range(6, 22)))),       # 시간대 별 구매건수 추가\n",
    "\n",
    "        ('월초_구매비율', lambda x: np.mean(x.dt.day <= 10)),                     # 월초 구매비율 추가(10일 이전)\n",
    "        ('월말_구매비율', lambda x: np.mean(x.dt.day >= 20)),                     # 월말 구매비율 추가(20일 이후)\n",
    "        ('월초_구매횟수', lambda x: np.sum(x.dt.day <= 10)),                     # 월초 구매건수 추가(10일 이전)\n",
    "        ('월말_구매횟수', lambda x: np.sum(x.dt.day >= 20)),                     # 월말 구매건수 추가(20일 이후)\n",
    "\n",
    "        ('웨딩성수기_구매비율', lambda x: np.mean(x.dt.month.isin([4, 5, 9, 10]))),  # 결혼 성수기 시즌 구매 비율\n",
    "        ('웨딩성수기_구매횟수', lambda x: ((x.dt.month == 4) | (x.dt.month == 5) | (x.dt.month == 9) | (x.dt.month == 10)).sum()),  # 결혼 성수기 시즌 구매 횟수\n",
    "        \n",
    "        ('1월_구매비율', lambda x: np.mean(x.dt.month == 1)), # 1월 구매비율\n",
    "        ('2월_구매비율', lambda x: np.mean(x.dt.month == 2)), # 2월 구매비율\n",
    "        ('3월_구매비율', lambda x: np.mean(x.dt.month == 3)), # 3월 구매비율\n",
    "        ('4월_구매비율', lambda x: np.mean(x.dt.month == 4)), # 4월 구매비율\n",
    "        ('5월_구매비율', lambda x: np.mean(x.dt.month == 5)), # 5월 구매비율\n",
    "        ('6월_구매비율', lambda x: np.mean(x.dt.month == 6)), # 6월 구매비율\n",
    "        ('7월_구매비율', lambda x: np.mean(x.dt.month == 7)), # 7월 구매비율\n",
    "        ('8월_구매비율', lambda x: np.mean(x.dt.month == 8)), # 8월 구매비율\n",
    "        ('9월_구매비율', lambda x: np.mean(x.dt.month == 9)), # 9월 구매비율\n",
    "        ('10월_구매비율', lambda x: np.mean(x.dt.month == 10)), # 10월 구매비율\n",
    "        ('11월_구매비율', lambda x: np.mean(x.dt.month == 11)), # 11월 구매비율\n",
    "        ('12월_구매비율', lambda x: np.mean(x.dt.month == 12)), # 12월 구매비율\n",
    "\n",
    "        ('1월_구매횟수', lambda x: (x.dt.month == 1).sum()),  # 1월 구매 횟수\n",
    "        ('2월_구매횟수', lambda x: (x.dt.month == 2).sum()),  # 2월 구매 횟수\n",
    "        ('3월_구매횟수', lambda x: (x.dt.month == 3).sum()),  # 3월 구매 횟수\n",
    "        ('4월_구매횟수', lambda x: (x.dt.month == 4).sum()),  # 4월 구매 횟수\n",
    "        ('5월_구매횟수', lambda x: (x.dt.month == 5).sum()),  # 5월 구매 횟수\n",
    "        ('6월_구매횟수', lambda x: (x.dt.month == 6).sum()),  # 6월 구매 횟수\n",
    "        ('7월_구매횟수', lambda x: (x.dt.month == 7).sum()),  # 7월 구매 횟수\n",
    "        ('8월_구매횟수', lambda x: (x.dt.month == 8).sum()),  # 8월 구매 횟수\n",
    "        ('9월_구매횟수', lambda x: (x.dt.month == 9).sum()),  # 9월 구매 횟수\n",
    "        ('10월_구매횟수', lambda x: (x.dt.month == 10).sum()),  # 10월 구매 횟수\n",
    "        ('11월_구매횟수', lambda x: (x.dt.month == 11).sum()),  # 11월 구매 횟수\n",
    "        ('12월_구매횟수', lambda x: (x.dt.month == 12).sum()),   # 12월 구매 횟수\n",
    "\n",
    "        ('1월_방문횟수', lambda x: x[x.dt.month == 1].dt.date.nunique()),\n",
    "        ('2월_방문횟수', lambda x: x[x.dt.month == 2].dt.date.nunique()),\n",
    "        ('3월_방문횟수', lambda x: x[x.dt.month == 3].dt.date.nunique()),\n",
    "        ('4월_방문횟수', lambda x: x[x.dt.month == 4].dt.date.nunique()),\n",
    "        ('5월_방문횟수', lambda x: x[x.dt.month == 5].dt.date.nunique()),\n",
    "        ('6월_방문횟수', lambda x: x[x.dt.month == 6].dt.date.nunique()),\n",
    "        ('7월_방문횟수', lambda x: x[x.dt.month == 7].dt.date.nunique()),\n",
    "        ('8월_방문횟수', lambda x: x[x.dt.month == 8].dt.date.nunique()),\n",
    "        ('9월_방문횟수', lambda x: x[x.dt.month == 9].dt.date.nunique()),\n",
    "        ('10월_방문횟수', lambda x: x[x.dt.month == 10].dt.date.nunique()),\n",
    "        ('11월_방문횟수', lambda x: x[x.dt.month == 11].dt.date.nunique()),\n",
    "        ('12월_방문횟수', lambda x: x[x.dt.month == 12].dt.date.nunique()),\n",
    "\n",
    "        # (\"공휴일_구매유무\", lambda x: x.dt.date.isin(holidays.date).any().astype(int)),       # 공휴일 구매 유무(0과 1로 반환)\n",
    "        (\"공휴일_구매비율\", lambda x: np.mean(x.dt.date.isin(holidays.date))),                  # 공휴일 구매 비율\n",
    "        (\"여름휴가_구매비율\", lambda x: np.mean(x.dt.month.isin([7,8]))),                       # 방학,여름휴가(7,8월) 구매비율\n",
    "        (\"연말_구매비율\", lambda x: np.sum(x.dt.month.isin([12,1,2]))),                        # 연말(12월~2월) 구매비율\n",
    "        \n",
    "        (\"공휴일_구매횟수\", lambda x: np.sum(x.dt.date.isin(holidays.date))),                  # 공휴일 구매 비율\n",
    "        (\"여름휴가_구매횟수\", lambda x: np.sum(x.dt.month.isin([7,8]))),                       # 방학,여름휴가(7,8월) 구매비율\n",
    "        (\"연말_구매횟수\", lambda x: np.sum(x.dt.month.isin([12,1,2]))),                        # 연말(12월~2월) 구매비율\n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 월별 총구매금액 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 84), (12225, 84))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    train_tmp = train_tr[train_tr[\"구매일시\"].dt.month == i].groupby(\"ID\")[\"구매가격\"].sum().reset_index(name=f\"{i}월_총구매금액\")\n",
    "    train_ft = train_ft.merge(train_tmp, on= \"ID\", how = \"left\")\n",
    "    train_ft[f\"{i}월_총구매금액\"] = train_ft[f\"{i}월_총구매금액\"].fillna(0)\n",
    "\n",
    "    test_tmp = test_tr[test_tr[\"구매일시\"].dt.month == i].groupby(\"ID\")[\"구매가격\"].sum().reset_index(name=f\"{i}월_총구매금액\")\n",
    "    test_ft = test_ft.merge(test_tmp, on= \"ID\", how = \"left\")\n",
    "    test_ft[f\"{i}월_총구매금액\"] = test_ft[f\"{i}월_총구매금액\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 월별 평균구매금액 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 96), (12225, 96))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    train_tmp = train_tr[train_tr[\"구매일시\"].dt.month == i].groupby(\"ID\")[\"구매가격\"].mean().reset_index(name=f\"{i}월_평균구매금액\")\n",
    "    train_ft = train_ft.merge(train_tmp, on= \"ID\", how = \"left\")\n",
    "    train_ft[f\"{i}월_평균구매금액\"] = train_ft[f\"{i}월_평균구매금액\"].fillna(0)\n",
    "\n",
    "    test_tmp = test_tr[test_tr[\"구매일시\"].dt.month == i].groupby(\"ID\")[\"구매가격\"].mean().reset_index(name=f\"{i}월_평균구매금액\")\n",
    "    test_ft = test_ft.merge(test_tmp, on= \"ID\", how = \"left\")\n",
    "    test_ft[f\"{i}월_평균구매금액\"] = test_ft[f\"{i}월_평균구매금액\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 휴면회원 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 98), (12225, 98))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [(\"최근구매일\", lambda x: int( (x.max() - x.min()).days))]\n",
    "\n",
    "sort_value = train_tr.sort_values([\"ID\", \"구매일시\"], ascending= False).drop_duplicates(subset=[\"ID\", \"구매일시\"],keep='first').groupby(\"ID\").head(2)\n",
    "tmp = sort_value.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "tmp[\"휴면회원\"] = (tmp[\"최근구매일\"] > 90).astype(int)\n",
    "train_ft = train_ft.merge(tmp, how= 'left', on= \"ID\")\n",
    "\n",
    "sort_value = test_tr.sort_values([\"ID\", \"구매일시\"], ascending= False).drop_duplicates(subset=[\"ID\", \"구매일시\"],keep='first').groupby(\"ID\").head(2)\n",
    "tmp = sort_value.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "tmp[\"휴면회원\"] = (tmp[\"최근구매일\"] > 90).astype(int)\n",
    "test_ft = test_ft.merge(tmp, how= 'left', on= \"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxm1aP9bstSP"
   },
   "source": [
    "## 지점을 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "NAhiyQqgmAna"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 101), (12225, 101))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "          (\"방문지점수\",\"nunique\"),\n",
    "          ('주구매지점', lambda x: x.mode()[0]),\n",
    "          \n",
    "          (\"지점다양성_비율\", lambda x: x.nunique() / len(x)), # 지점 다양성 비율 추가\n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"지점코드\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"지점코드\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC7i927ntZMf"
   },
   "source": [
    "## 브랜드코드를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "U55_ClZktWbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 103), (12225, 103))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "             ('브랜드코드_nunique', 'nunique'),\n",
    "\n",
    "             ('브랜드다양성_비율',lambda x: x.nunique() / len(x)) # 브랜드다양성 추가\n",
    "\n",
    "             ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"브랜드코드\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"브랜드코드\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대분류를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>구매일시</th>\n",
       "      <th>지점코드</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>브랜드코드</th>\n",
       "      <th>구매가격</th>\n",
       "      <th>대분류_수정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_13219</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>공산품파트</td>\n",
       "      <td>차류</td>\n",
       "      <td>5100</td>\n",
       "      <td>59700</td>\n",
       "      <td>생식품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_5590</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>화장잡화</td>\n",
       "      <td>5101</td>\n",
       "      <td>17000</td>\n",
       "      <td>의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_7200</td>\n",
       "      <td>2004-05-01 10:20:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>공산품</td>\n",
       "      <td>용기보증</td>\n",
       "      <td>5100</td>\n",
       "      <td>34937</td>\n",
       "      <td>생식품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3010</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A373000</td>\n",
       "      <td>아동_스포츠</td>\n",
       "      <td>아동복</td>\n",
       "      <td>5105</td>\n",
       "      <td>19000</td>\n",
       "      <td>아동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_10851</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>가정용품</td>\n",
       "      <td>전화기_카세트</td>\n",
       "      <td>5110</td>\n",
       "      <td>215000</td>\n",
       "      <td>가정용품</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                구매일시     지점코드     대분류      중분류  브랜드코드    구매가격  \\\n",
       "0  train_13219 2004-05-01 09:40:00  A144000   공산품파트       차류   5100   59700   \n",
       "1   train_5590 2004-05-01 09:40:00  A144000    잡화파트     화장잡화   5101   17000   \n",
       "2   train_7200 2004-05-01 10:20:00  A112000     공산품     용기보증   5100   34937   \n",
       "3   train_3010 2004-05-01 10:30:00  A373000  아동_스포츠      아동복   5105   19000   \n",
       "4  train_10851 2004-05-01 10:30:00  A112000    가정용품  전화기_카세트   5110  215000   \n",
       "\n",
       "  대분류_수정  \n",
       "0    생식품  \n",
       "1     의류  \n",
       "2    생식품  \n",
       "3     아동  \n",
       "4   가정용품  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 대분류 범주 생성\n",
    "def classification(x):\n",
    "    lst_kids = ['아동_스포츠', '아동문화', '케주얼_구두_아동', '아동']\n",
    "    lst_young = [\"영어덜트캐쥬얼\", \"영캐릭터\", \"영플라자\", \"영라이브\"]\n",
    "    lst_foods = [\"생식품파트\", \"생식품\", \"공산품\", \"공산품파트\"]\n",
    "    lst_home = [\"가정용품파트\", \"가정용품\"]\n",
    "    lst_clothes = [\"스포츠캐쥬얼\", \"패션잡화\", \"여성캐쥬얼\",\"여성캐주얼\", \"남성정장스포츠\",\n",
    "                \"남성의류\", \"여성정장\", \"여성의류파트\", \"골프_유니캐쥬얼\", \"잡화파트\", \"잡화\" ]\n",
    "    lst_loyal = [\"명품잡화\", \"로얄부띠끄\", \"로얄부틱\"]\n",
    "\n",
    "    if x in lst_kids:\n",
    "        ans = \"아동\"\n",
    "    elif x in lst_foods:\n",
    "        ans = \"생식품\"\n",
    "    elif x in lst_home:\n",
    "        ans = \"가정용품\" \n",
    "    elif x in lst_clothes:\n",
    "        ans = \"의류\"      \n",
    "    elif x in lst_loyal:\n",
    "        ans = \"명품\"  \n",
    "    elif x in lst_young:\n",
    "        ans = \"영\"\n",
    "    else:\n",
    "        ans = \"기타\"\n",
    "    return ans\n",
    "\n",
    "train_tr[\"대분류_수정\"] = train_tr[\"대분류\"].apply(classification)\n",
    "test_tr[\"대분류_수정\"] = test_tr[\"대분류\"].apply(classification)\n",
    "\n",
    "train_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 120), (12225, 120))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "            ('대분류_수정_nunique', 'nunique'),                 # 대분류_수정 기준 구매횟수\n",
    "            ('주구매_대분류_수정', lambda x: x.mode()[0]),      # 대분류_수정 기준 주구매\n",
    "\n",
    "            # ('대분류_수정_아동_구매여부', lambda x: int(x.str.contains(\"아동\").any())),              # 대분류_수정에서 아동 구매 여부(1/0)\n",
    "            # ('대분류_수정_생식품_구매여부', lambda x: int(x.str.contains(\"생식품\").any())),          # 대분류_수정에서 생식품 구매 여부(1/0)\n",
    "            # ('대분류_수정_가정용품_구매여부', lambda x: int(x.str.contains(\"가정용품\").any())),      # 대분류_수정에서 가정용품 구매 여부(1/0)\n",
    "            # ('대분류_수정_의류_구매여부', lambda x: int(x.str.contains(\"의류\").any())),              # 대분류_수정에서 의류 구매 여부(1/0)\n",
    "            # ('대분류_수정_명품_구매여부', lambda x: int(x.str.contains(\"명품\").any())),              # 대분류_수정에서 명품 구매 여부(1/0)\n",
    "\n",
    "            ('대분류_수정_아동_구매횟수', lambda x: int(x.str.contains(\"아동\").sum())),              # 대분류_수정에서 아동 구매횟수\n",
    "            ('대분류_수정_생식품_구매횟수', lambda x: int(x.str.contains(\"생식품\").sum())),          # 대분류_수정에서 생식품 구매횟수\n",
    "            ('대분류_수정_가정용품_구매횟수', lambda x: int(x.str.contains(\"가정용품\").sum())),      # 대분류_수정에서 가정용품 구매횟수\n",
    "            ('대분류_수정_의류_구매횟수', lambda x: int(x.str.contains(\"의류\").sum())),              # 대분류_수정에서 의류 구매횟수\n",
    "            ('대분류_수정_명품_구매횟수', lambda x: int(x.str.contains(\"명품\").sum())),              # 대분류_수정에서 명품 구매횟수\n",
    "\n",
    "            ('대분류_수정_아동_구매비중', lambda x: int(x.str.contains(\"아동\").mean())),              # 대분류_수정에서 아동 구매횟수\n",
    "            ('대분류_수정_생식품_구매비중', lambda x: int(x.str.contains(\"생식품\").mean())),          # 대분류_수정에서 생식품 구매횟수\n",
    "            ('대분류_수정_가정용품_구매비중', lambda x: int(x.str.contains(\"가정용품\").mean())),      # 대분류_수정에서 가정용품 구매횟수\n",
    "            ('대분류_수정_의류_구매비중', lambda x: int(x.str.contains(\"의류\").mean())),              # 대분류_수정에서 의류 구매횟수\n",
    "            ('대분류_수정_명품_구매비중', lambda x: int(x.str.contains(\"명품\").mean())),              # 대분류_수정에서 명품 구매횟수\n",
    "\n",
    "\n",
    "            ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"대분류_수정\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"대분류_수정\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중분류를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_row', None)     # 최대 행 수 제한 해제\n",
    "# pp = pd.DataFrame(train_tr.groupby(\"대분류\")[\"중분류\"].unique())\n",
    "# print(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>구매일시</th>\n",
       "      <th>지점코드</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>브랜드코드</th>\n",
       "      <th>구매가격</th>\n",
       "      <th>대분류_수정</th>\n",
       "      <th>중분류_수정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_13219</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>공산품파트</td>\n",
       "      <td>차류</td>\n",
       "      <td>5100</td>\n",
       "      <td>59700</td>\n",
       "      <td>생식품</td>\n",
       "      <td>식료품_식료품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_5590</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>화장잡화</td>\n",
       "      <td>5101</td>\n",
       "      <td>17000</td>\n",
       "      <td>의류</td>\n",
       "      <td>의류_화장품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_7200</td>\n",
       "      <td>2004-05-01 10:20:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>공산품</td>\n",
       "      <td>용기보증</td>\n",
       "      <td>5100</td>\n",
       "      <td>34937</td>\n",
       "      <td>생식품</td>\n",
       "      <td>식료품_기타</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3010</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A373000</td>\n",
       "      <td>아동_스포츠</td>\n",
       "      <td>아동복</td>\n",
       "      <td>5105</td>\n",
       "      <td>19000</td>\n",
       "      <td>아동</td>\n",
       "      <td>아동_의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_10851</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>가정용품</td>\n",
       "      <td>전화기_카세트</td>\n",
       "      <td>5110</td>\n",
       "      <td>215000</td>\n",
       "      <td>가정용품</td>\n",
       "      <td>가정용품_가전</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                구매일시     지점코드     대분류      중분류  브랜드코드    구매가격  \\\n",
       "0  train_13219 2004-05-01 09:40:00  A144000   공산품파트       차류   5100   59700   \n",
       "1   train_5590 2004-05-01 09:40:00  A144000    잡화파트     화장잡화   5101   17000   \n",
       "2   train_7200 2004-05-01 10:20:00  A112000     공산품     용기보증   5100   34937   \n",
       "3   train_3010 2004-05-01 10:30:00  A373000  아동_스포츠      아동복   5105   19000   \n",
       "4  train_10851 2004-05-01 10:30:00  A112000    가정용품  전화기_카세트   5110  215000   \n",
       "\n",
       "  대분류_수정   중분류_수정  \n",
       "0    생식품  식료품_식료품  \n",
       "1     의류   의류_화장품  \n",
       "2    생식품   식료품_기타  \n",
       "3     아동    아동_의류  \n",
       "4   가정용품  가정용품_가전  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 중분류 범주 생성\n",
    "\n",
    "kids_toy_lst = [ '아동', '문화', '완구', '유아', '문구_팬시', '비디오', '완구(문화)','문구','사무용품','팬시코너(문화)','잡화(문화)', '레코드(문화)', \n",
    "                 '스포츠용품','문구(문화)', '영창(문화)','유아용품', '유아발육기','아동단품',  ]         \n",
    "kids_clothes_lst = [ '아동복', '테이프', '진케주얼', '트래디셔널', '영트랜드', '유아복', '란제리', '잡화', '교복행사','스키',\n",
    "                     '캐쥬얼구두', '내의', '임대구두', '수입구두', '팬시', '드레스구두',  '피혁A행사', '아동특선', '셔츠', '단품(트래디셔널)', \n",
    "                     '단품행사',  '모자', '수입종합화장품' , '아동잡화', '유아복', '아웃도어', '신생아','단품', '수영복', '슈즈','스포츠웨어' ]\n",
    "kids_etc_lst = ['용기보증', '상품군미지정']\n",
    "\n",
    "young_toy_lst = ['영잡화', '문화', '패스트푸드', '취미소품']\n",
    "young_colthes_lst = ['캐릭터캐쥬얼', '캐리어캐쥬얼', '캐릭터슈즈', '수입슈즈', '임대슈즈', '패션잡화', '행사슈즈', '구두수선', '행사핸드백', '머플러', \n",
    "                     '베이직캐주얼', '영커리어캐주얼', '트렌드캐주얼', '뉴베이직캐주얼', '영캐주얼', '진캐주얼', '패션란제리', '화장품', '스포츠캐주얼', \n",
    "                     '피혁토탈(B2)', '단품_행사1', '단품_행사2', '단품', '유니섹스캐주얼', '단품_행사', '장신구', '스포츠단품', '영캐쥬얼', '행사', '진캐쥬얼']\n",
    "young_etc_lst = ['용기보증']\n",
    "\n",
    "foods_lst = ['정육', '곡물', '생선', '야채', '청과', '냉장식품', '기타식품', '조미료', '과자', '건식품', '즉석조리', '과자류', '인스턴트식품', '면류', \n",
    "             '일반조리', '건어물', '통병조림', '차류', '냉동식품','인스탄트식품', '건강식품', '일반식품명품']\n",
    "foods_drink_lst = ['음료', '주류']\n",
    "foods_etc_lst = ['용기보증', '일용잡화', '가정잡화', '상품군미지정', '주방용품' ]\n",
    "\n",
    "home_elec_lst = ['전화기_카세트', 'TV_VCR', '세탁기_냉장고', '소형취사가전','가전특정','취사소형', '카세트_전화기', 'TV_VTR','소형전기','냉장고_세탁기', \n",
    "                 '컴퓨터','카메라','오디오', '건강용품','냉난방','냉장고.세탁기', '전화기','라디오.카세트', '가스렌지', 'TV.VTR', '오디오',  '조명', '가스기기']\n",
    "home_furn_lst = ['전문가구(가구)', '원목(주니어)','원목_주니어', '소형가구(가구)', '침대', '소파',  '사무용품','쇼파', '식탁', '수입_종합가구',]\n",
    "home_daily_lst = [ '주방용품', '문구_팬시', '침구', '욕실용품', 'L_B침구', '크리스탈', '초도자기', '카페트','수예_인테리어소품', '브랜드침구','홈데코',\n",
    "                  '식탁_소품', '식기', 'N_B침구', '수입도자기',  '수예','수예침장',  '카페트_대자리', '그라스', '장식액자','직수입침구', '수예행사' ]\n",
    "home_etc_lst = ['종합_수입','해외SHOP','용기보증', '상품군미지정', '통판', '특판','정장']\n",
    "\n",
    "clothes_lst = ['수입의류', '단품', '캐릭터', '엘레강스', '타운웨어', '트래디셔널', '타운', '칼라드래디셔널', '영캐주얼', '미씨캐릭터', '인텔리젼스캐주얼', \n",
    "               '엘레강스캐주얼', '영트랜디', '디자이너캐릭터', '캐릭터캐주얼', '진캐쥬얼', '니트웨어', '부띠끄', '디자이너부띠끄', '엘레강스부틱', '레포츠단품', \n",
    "               '니트', '수입명품', '수입의류행사', '모피니트', '레포츠', '훼미닌부틱', '마담SIZE', '모피_피혁', '부띠끄행사', 'TOP디자이너', '모피.피혁',\n",
    "               '레이디숍A', '하이캐쥬얼', '타운단품', '디자이너숍', '캐릭터캐쥬얼', '수입캐주얼', '미시케쥬얼', '영캐쥬얼', '디자이너니트', '인텔리젼스', \n",
    "               '모피', '디자이너', '행사_단품', '셔츠', '남성잡화', '수입', '라이센스', '어덜트', '마춤', '트.단품', '디자이너캐주얼', '내셔날', '내셔널', \n",
    "               '특정', '정장행사', '행사구두(5F)', '로얄', '피혁', '단품_행사(캐릭터)', '골프(LC)', '트레디셔널캐주얼', '트래디셔널캐쥬얼',\n",
    "               '단품_행사(트래디셔널)', '캐주얼단품', '골프웨어', '스포츠웨어', '수영복', '골프단품', '임대골프', 'DC캐주얼', '스포츠단품', '로얄수입행사', \n",
    "               '단품(트래디셔널)', '스키', '스포츠단품', '아웃도어', '골프(단품)', '골프(NB)', '캐쥬얼단품', '골프(국내)','골프(수입)' ]\n",
    "clothes_beuty_lst = ['화장잡화', '수입종합화장품', '향수','색조화장품', '국내화장품', '수입향수','국산화장품']\n",
    "clothes_goods_lst = ['잡화', '양말', '우산장갑', '스카프', '손수건', '수입ACC', 'NB제화', '싸롱화', '핸드백', '토탈', '국내종합화장품', '보석', '시계'\n",
    "                     '핸드백행사', '가방', '패션ACC', '헤어ACC', '스타킹', '준보석', '모자', '구두행사', '선글라스', '피혁소품행사', 'NB핸드백', '머플러',\n",
    "                      '란제리', '우산_장갑',  '골프용품',' 골프(용품)', '여성구두', '구두임대', '로얄부틱2F', '핸드백임대', '썬그라스','패션시계',\n",
    "                      '수입피혁', '일반ACC', '임대핸드백','피혁소품','넥타이','피혁B행사', '스포츠용퓸', '수입악세사리', '지갑_벨트', '행사핸드백', \n",
    "                      '선글래스', '행사소품', '패션악세사리', '헤어악세사리','남성구두', '스포츠슈즈', '용품', '스포츠용품' ]\n",
    "clothes_etc_lst = ['상품군미지정', '행사', '용기보증','상품개발지원','GBR  지원','욕실용품','특선행사' ]\n",
    "\n",
    "loyal_lst = ['수입부띠끄', '국내부띠끄', '로얄수입행사','잡화토탈', '엘레강스부틱', '의류기타', '행사', '토탈부틱','패션시계', '색조화장품', '핸드백', \n",
    "             '란제리', '수입향수', '명품', '수입종합화장품', '로얄부틱2F', '모자', '수입액세서리', '여성구두', '구두임대', '우산_장갑', '장신구행사업체', \n",
    "             '머플러', '넥타이', '수입명품', '일반악세사리', '가방', '보석', '헤어액세사리', '임대화장품', '준보석', '스타킹', '양말', '손수건', '화장잡화',\n",
    "               '수입행사', '스카프', '핸드백임대' ]\n",
    "loyal_etc_lst = [ '페레  지원', '용기보증', '상품군미지정']\n",
    "\n",
    "\n",
    "new_lst = []\n",
    "for x in range(train_tr.shape[0]):\n",
    "    if  (train_tr[\"대분류_수정\"][x] == \"아동\") & (train_tr[\"중분류\"][x] in kids_toy_lst):\n",
    "        new_lst.append(\"아동_완구\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"아동\") & (train_tr[\"중분류\"][x] in kids_clothes_lst):\n",
    "        new_lst.append(\"아동_의류\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"아동\") & (train_tr[\"중분류\"][x] in kids_etc_lst):\n",
    "        new_lst.append(\"아동_기타\")\n",
    "\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"영\") & (train_tr[\"중분류\"][x] in young_toy_lst):\n",
    "        new_lst.append(\"영_완구\")     \n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"영\") & (train_tr[\"중분류\"][x] in young_colthes_lst):\n",
    "        new_lst.append(\"영_의류\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"영\") & (train_tr[\"중분류\"][x] in young_etc_lst):\n",
    "        new_lst.append(\"영_기타\")\n",
    "\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"생식품\") & (train_tr[\"중분류\"][x] in foods_lst):\n",
    "        new_lst.append(\"식료품_식료품\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"생식품\") & (train_tr[\"중분류\"][x] in foods_drink_lst):\n",
    "        new_lst.append(\"식료품_음료\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"생식품\") & (train_tr[\"중분류\"][x] in foods_etc_lst):\n",
    "        new_lst.append(\"식료품_기타\")\n",
    "\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"가정용품\") & (train_tr[\"중분류\"][x] in home_elec_lst):\n",
    "        new_lst.append(\"가정용품_가전\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"가정용품\") & (train_tr[\"중분류\"][x] in home_furn_lst):\n",
    "        new_lst.append(\"가정용품_가구\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"가정용품\") & (train_tr[\"중분류\"][x] in home_daily_lst):\n",
    "        new_lst.append(\"가정용품_잡화\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"가정용품\") & (train_tr[\"중분류\"][x] in home_etc_lst):\n",
    "        new_lst.append(\"가정용품_기타\")\n",
    "\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"의류\") & (train_tr[\"중분류\"][x] in clothes_lst):\n",
    "        new_lst.append(\"의류_의류\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"의류\") & (train_tr[\"중분류\"][x] in clothes_beuty_lst):\n",
    "        new_lst.append(\"의류_화장품\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"의류\") & (train_tr[\"중분류\"][x] in clothes_goods_lst):\n",
    "        new_lst.append(\"의류_잡화\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"의류\") & (train_tr[\"중분류\"][x] in clothes_etc_lst):\n",
    "        new_lst.append(\"의류_기타\")\n",
    "\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"명품\") & (train_tr[\"중분류\"][x] in loyal_lst):\n",
    "        new_lst.append(\"명품_명품\")\n",
    "    elif (train_tr[\"대분류_수정\"][x] == \"명품\") & (train_tr[\"중분류\"][x] in loyal_etc_lst):\n",
    "        new_lst.append(\"명품_기타\")\n",
    "    else:\n",
    "        new_lst.append(\"기타\")\n",
    "\n",
    "    \n",
    "train_tr[\"중분류_수정\"] = new_lst\n",
    "\n",
    "train_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>구매일시</th>\n",
       "      <th>지점코드</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>브랜드코드</th>\n",
       "      <th>구매가격</th>\n",
       "      <th>대분류_수정</th>\n",
       "      <th>중분류_수정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_3366</td>\n",
       "      <td>2004-05-01 10:20:00</td>\n",
       "      <td>A373000</td>\n",
       "      <td>생식품</td>\n",
       "      <td>건식품</td>\n",
       "      <td>5100</td>\n",
       "      <td>7000</td>\n",
       "      <td>생식품</td>\n",
       "      <td>식료품_식료품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_9389</td>\n",
       "      <td>2004-05-01 10:23:00</td>\n",
       "      <td>A373000</td>\n",
       "      <td>명품잡화</td>\n",
       "      <td>스타킹</td>\n",
       "      <td>5104</td>\n",
       "      <td>46000</td>\n",
       "      <td>명품</td>\n",
       "      <td>명품_명품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_8190</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>수입종합화장품</td>\n",
       "      <td>5106</td>\n",
       "      <td>260000</td>\n",
       "      <td>의류</td>\n",
       "      <td>의류_화장품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_8835</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>준보석</td>\n",
       "      <td>5107</td>\n",
       "      <td>17000</td>\n",
       "      <td>의류</td>\n",
       "      <td>의류_잡화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_1167</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A373000</td>\n",
       "      <td>남성의류</td>\n",
       "      <td>셔츠</td>\n",
       "      <td>5108</td>\n",
       "      <td>138000</td>\n",
       "      <td>의류</td>\n",
       "      <td>의류_의류</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                구매일시     지점코드   대분류      중분류  브랜드코드    구매가격  \\\n",
       "0  test_3366 2004-05-01 10:20:00  A373000   생식품      건식품   5100    7000   \n",
       "1  test_9389 2004-05-01 10:23:00  A373000  명품잡화      스타킹   5104   46000   \n",
       "2  test_8190 2004-05-01 10:30:00  A144000  잡화파트  수입종합화장품   5106  260000   \n",
       "3  test_8835 2004-05-01 10:30:00  A144000  잡화파트      준보석   5107   17000   \n",
       "4  test_1167 2004-05-01 10:30:00  A373000  남성의류       셔츠   5108  138000   \n",
       "\n",
       "  대분류_수정   중분류_수정  \n",
       "0    생식품  식료품_식료품  \n",
       "1     명품    명품_명품  \n",
       "2     의류   의류_화장품  \n",
       "3     의류    의류_잡화  \n",
       "4     의류    의류_의류  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lst = []\n",
    "for x in range(test_tr.shape[0]):\n",
    "    if  (test_tr[\"대분류_수정\"][x] == \"아동\") & (test_tr[\"중분류\"][x] in kids_toy_lst):\n",
    "        new_lst.append(\"아동_완구\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"아동\") & (test_tr[\"중분류\"][x] in kids_clothes_lst):\n",
    "        new_lst.append(\"아동_의류\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"아동\") & (test_tr[\"중분류\"][x] in kids_etc_lst):\n",
    "        new_lst.append(\"아동_기타\")\n",
    "\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"영\") & (test_tr[\"중분류\"][x] in young_toy_lst):\n",
    "        new_lst.append(\"영_완구\")     \n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"영\") & (test_tr[\"중분류\"][x] in young_colthes_lst):\n",
    "        new_lst.append(\"영_의류\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"영\") & (test_tr[\"중분류\"][x] in young_etc_lst):\n",
    "        new_lst.append(\"영_기타\")\n",
    "\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"생식품\") & (test_tr[\"중분류\"][x] in foods_lst):\n",
    "        new_lst.append(\"식료품_식료품\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"생식품\") & (test_tr[\"중분류\"][x] in foods_drink_lst):\n",
    "        new_lst.append(\"식료품_음료\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"생식품\") & (test_tr[\"중분류\"][x] in foods_etc_lst):\n",
    "        new_lst.append(\"식료품_기타\")\n",
    "\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"가정용품\") & (test_tr[\"중분류\"][x] in home_elec_lst):\n",
    "        new_lst.append(\"가정용품_가전\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"가정용품\") & (test_tr[\"중분류\"][x] in home_furn_lst):\n",
    "        new_lst.append(\"가정용품_가구\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"가정용품\") & (test_tr[\"중분류\"][x] in home_daily_lst):\n",
    "        new_lst.append(\"가정용품_잡화\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"가정용품\") & (test_tr[\"중분류\"][x] in home_etc_lst):\n",
    "        new_lst.append(\"가정용품_기타\")\n",
    "\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"의류\") & (test_tr[\"중분류\"][x] in clothes_lst):\n",
    "        new_lst.append(\"의류_의류\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"의류\") & (test_tr[\"중분류\"][x] in clothes_beuty_lst):\n",
    "        new_lst.append(\"의류_화장품\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"의류\") & (test_tr[\"중분류\"][x] in clothes_goods_lst):\n",
    "        new_lst.append(\"의류_잡화\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"의류\") & (test_tr[\"중분류\"][x] in clothes_etc_lst):\n",
    "        new_lst.append(\"의류_기타\")\n",
    "\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"명품\") & (test_tr[\"중분류\"][x] in loyal_lst):\n",
    "        new_lst.append(\"명품_명품\")\n",
    "    elif (test_tr[\"대분류_수정\"][x] == \"명품\") & (test_tr[\"중분류\"][x] in loyal_etc_lst):\n",
    "        new_lst.append(\"명품_기타\")\n",
    "    else:\n",
    "        new_lst.append(\"기타\")\n",
    "\n",
    "    \n",
    "test_tr[\"중분류_수정\"] = new_lst\n",
    "\n",
    "test_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 122), (12225, 122))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "            ('중분류_수정_nunique', 'nunique'),\n",
    "            ('주구매_중분류_수정', lambda x: x.mode()[0]),\n",
    "\n",
    "            ]\n",
    "tmp = train_tr.groupby('ID')[\"중분류_수정\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"중분류_수정\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구매가격을 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 141), (12225, 141))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "        ('총구매액',lambda x: x[x > 0].sum()),         # 0 이상에서 적용\n",
    "        ('구매횟수', lambda x: x[x > 0].count()),      # 0 이상에서 적용\n",
    "        ('평균구매액', lambda x: x[x > 0].mean()),     # 0 이상에서 적용\n",
    "        ('최대구매액', 'max'),\n",
    "        ('최소구매액',lambda x: x[x > 0].min() ) ,\n",
    "        ('환불금액',lambda x: x[x < 0].sum() ) ,\n",
    "        ('환불건수', lambda x: ( x < 0 ).sum() ),\n",
    "        ('구매금액표준편차',lambda x: x[x > 0].std() ),\n",
    "\n",
    "        # ('평균저가구매비율', lambda x: (x <= 102479.91701049241).sum() / len(x)), # 저가 구매 비율 (구매 총평균에 비례)\n",
    "        # ('평균고가구매비율', lambda x: (x > 102479.91701049241).sum() / len(x)),   # 고가 구매 비율 (구매 총평균에 비례)\n",
    "\n",
    "        ('저가_구매횟수', lambda x: ((x > 0) & (x <= 28000)).sum()),            # train_tr의 사분위수 기준\n",
    "        ('중저가_구매횟수', lambda x: ((x > 28000) & (x <= 58000)).sum()),\n",
    "        ('중고가_구매횟수', lambda x: ((x > 58000) & (x <= 128000)).sum()),\n",
    "        ('고가_구매횟수', lambda x: ((x > 128000) & (x <= 30820000)).sum()),\n",
    "\n",
    "        ('저가_구매비율', lambda x: ((x > 0) & (x <= 28000)).mean()), \n",
    "        ('중저가_구매비율', lambda x: ((x > 28000) & (x <= 58000)).mean()),\n",
    "        ('중고가_구매비율', lambda x: ((x > 58000) & (x <= 128000)).mean()),\n",
    "        ('고가_구매비율', lambda x: ((x > 128000) & (x <= 30820000)).mean()),\n",
    "        \n",
    "        (\"공휴일_총구매금액\", lambda x: np.sum(x[train_tr[\"구매일시\"].dt.date.isin(holidays.date)])),       # 공휴일 총구매금액\n",
    "        (\"여름휴가_총구매금액\", lambda x: np.sum(x[train_tr[\"구매일시\"].dt.month.isin([7,8])])),             # 방학,여름휴가(7,8월) 총구매금액\n",
    "        (\"연말_총구매금액\", lambda x: np.sum(x[train_tr[\"구매일시\"].dt.month.isin([12,1,2])])),              # 연말(12월~2월) 총구매금액\n",
    "    ]\n",
    "    \n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"구매가격\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, on= \"ID\", how='left')\n",
    "train_ft[\"구매금액표준편차\"] = train_ft[\"구매금액표준편차\"].fillna(0)\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"구매가격\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, on= \"ID\", how='left')\n",
    "test_ft[\"구매금액표준편차\"] = test_ft[\"구매금액표준편차\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 등급 범주 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 142), (12225, 142))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grade(x):\n",
    "    if x >= 10000000:\n",
    "        ans = 1\n",
    "    elif 5000000 <= x & x < 10000000:\n",
    "        ans = 2\n",
    "    elif 1000000 <= x & x < 5000000:\n",
    "        ans = 3\n",
    "    elif 0 <= x & x < 1000000:\n",
    "        ans = 4\n",
    "    return ans\n",
    "\n",
    "train_ft[\"등급\"] = train_ft[\"총구매액\"].apply(grade)\n",
    "test_ft[\"등급\"] = test_ft[\"총구매액\"].apply(grade)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지점별 금액 합계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_8860\\3346531936.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  a373000_sum = (test_tr[train_tr[\"지점코드\"] == \"A373000\"].groupby('ID')['구매가격'].sum().reset_index(name='A373000지점_구매금액'))\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_8860\\3346531936.py:24: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  a202000_sum = (test_tr[train_tr[\"지점코드\"] == \"A202000\"].groupby('ID')['구매가격'].sum().reset_index(name='A202000지점_구매금액'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((14940, 146), (12225, 146))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 지점별 합계 금액 코드 추가 (train)\n",
    "a144000_sum = (train_tr[train_tr[\"지점코드\"] == \"A144000\"].groupby('ID')['구매가격'].sum().reset_index(name='A144000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a144000_sum, how='left', on='ID')\n",
    "\n",
    "a112000_sum = (train_tr[train_tr[\"지점코드\"] == \"A112000\"].groupby('ID')['구매가격'].sum().reset_index(name='A112000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a112000_sum, how='left', on='ID')\n",
    "\n",
    "a373000_sum = (train_tr[train_tr[\"지점코드\"] == \"A373000\"].groupby('ID')['구매가격'].sum().reset_index(name='A373000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a373000_sum, how='left', on='ID')\n",
    "\n",
    "a202000_sum = (train_tr[train_tr[\"지점코드\"] == \"A202000\"].groupby('ID')['구매가격'].sum().reset_index(name='A202000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a202000_sum, how='left', on='ID')\n",
    "\n",
    "#지점별 합계 금액 코드 추가 (test)\n",
    "a144000_sum = (test_tr[test_tr[\"지점코드\"] == \"A144000\"].groupby('ID')['구매가격'].sum().reset_index(name='A144000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a144000_sum, how='left', on='ID')\n",
    "\n",
    "a112000_sum = (test_tr[test_tr[\"지점코드\"] == \"A112000\"].groupby('ID')['구매가격'].sum().reset_index(name='A112000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a112000_sum, how='left', on='ID')\n",
    "\n",
    "a373000_sum = (test_tr[train_tr[\"지점코드\"] == \"A373000\"].groupby('ID')['구매가격'].sum().reset_index(name='A373000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a373000_sum, how='left', on='ID')\n",
    "\n",
    "a202000_sum = (test_tr[train_tr[\"지점코드\"] == \"A202000\"].groupby('ID')['구매가격'].sum().reset_index(name='A202000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a202000_sum, how='left', on='ID')\n",
    "\n",
    "train_ft[\"A144000지점_구매금액\"] = train_ft[\"A144000지점_구매금액\"].fillna(0)\n",
    "train_ft[\"A112000지점_구매금액\"] = train_ft[\"A112000지점_구매금액\"].fillna(0)\n",
    "train_ft[\"A373000지점_구매금액\"] = train_ft[\"A373000지점_구매금액\"].fillna(0)\n",
    "train_ft[\"A202000지점_구매금액\"] = train_ft[\"A202000지점_구매금액\"].fillna(0)\n",
    "\n",
    "test_ft[\"A144000지점_구매금액\"] = test_ft[\"A144000지점_구매금액\"].fillna(0)\n",
    "test_ft[\"A112000지점_구매금액\"] = test_ft[\"A112000지점_구매금액\"].fillna(0)\n",
    "test_ft[\"A373000지점_구매금액\"] = test_ft[\"A373000지점_구매금액\"].fillna(0)\n",
    "test_ft[\"A202000지점_구매금액\"] = test_ft[\"A202000지점_구매금액\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지점별 구매 브랜드 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 150), (12225, 150))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#지점별 구매 브랜드 갯수 추가(train)\n",
    "a144000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A144000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A1440000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a144000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a112000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A112000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A112000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a112000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a373000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A373000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A373000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a373000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a202000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A202000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A202000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a202000_brand_counts, how='left', on='ID')\n",
    "train_ft.head()\n",
    "\n",
    "#지점별 구매 브랜드 갯수 추가(test)\n",
    "a144000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A144000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A1440000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a144000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a112000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A112000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A112000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a112000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a373000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A373000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A373000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a373000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a202000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A202000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A202000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a202000_brand_counts, how='left', on='ID')\n",
    "\n",
    "\n",
    "train_ft[\"A1440000_구매브랜드_갯수\"] = train_ft[\"A1440000_구매브랜드_갯수\"].fillna(0)\n",
    "train_ft[\"A112000_구매브랜드_갯수\"] = train_ft[\"A112000_구매브랜드_갯수\"].fillna(0)\n",
    "train_ft[\"A373000_구매브랜드_갯수\"] = train_ft[\"A373000_구매브랜드_갯수\"].fillna(0)\n",
    "train_ft[\"A202000_구매브랜드_갯수\"] = train_ft[\"A202000_구매브랜드_갯수\"].fillna(0)\n",
    "\n",
    "test_ft[\"A1440000_구매브랜드_갯수\"] = test_ft[\"A1440000_구매브랜드_갯수\"].fillna(0)\n",
    "test_ft[\"A112000_구매브랜드_갯수\"] = test_ft[\"A112000_구매브랜드_갯수\"].fillna(0)\n",
    "test_ft[\"A373000_구매브랜드_갯수\"] = test_ft[\"A373000_구매브랜드_갯수\"].fillna(0)\n",
    "test_ft[\"A202000_구매브랜드_갯수\"] = test_ft[\"A202000_구매브랜드_갯수\"].fillna(0)\n",
    "\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pivot_table을 이용한 특성 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류_수정 기준 금액 합계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 156), (12225, 156))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = pd.pivot_table(train_tr,index=\"ID\",columns=\"대분류_수정\",values=\"구매가격\",aggfunc=\"sum\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_대분류수정_\").add_suffix(\"_총구매금액\").reset_index()\n",
    "train_ft = train_ft.merge(train_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "test_tmp = pd.pivot_table(test_tr,index=\"ID\",columns=\"대분류_수정\",values=\"구매가격\",aggfunc=\"sum\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_대분류수정_\").add_suffix(\"_총구매금액\").reset_index()\n",
    "\n",
    "for col in train_tmp.columns:\n",
    "    if col not in test_tmp.columns:\n",
    "        test_tmp[col] = 0\n",
    "\n",
    "test_tmp = test_tmp[train_tmp.columns]\n",
    "test_ft = test_ft.merge(test_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류_수정 기준 구매횟수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 162), (12225, 162))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = pd.pivot_table(train_tr,index=\"ID\",columns=\"대분류_수정\",values=\"구매가격\",aggfunc=\"count\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_대분류수정_\").add_suffix(\"_구매횟수\").reset_index()\n",
    "train_ft = train_ft.merge(train_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "test_tmp = pd.pivot_table(test_tr,index=\"ID\",columns=\"대분류_수정\",values=\"구매가격\",aggfunc=\"count\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_대분류수정_\").add_suffix(\"_구매횟수\").reset_index()\n",
    "\n",
    "for col in train_tmp.columns:\n",
    "    if col not in test_tmp.columns:\n",
    "        test_tmp[col] = 0\n",
    "\n",
    "test_tmp = test_tmp[train_tmp.columns]\n",
    "test_ft = test_ft.merge(test_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류_수정 기준 구입비중\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 168), (12225, 168))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in train_tr[\"대분류_수정\"].unique():\n",
    "    train_ft[f\"pv_대분류수정_{col}_구입비중\"] = train_ft[f\"pv_대분류수정_{col}_총구매금액\"]/train_ft[\"총구매액\"]\n",
    "    test_ft[f\"pv_대분류수정_{col}_구입비중\"] = test_ft[f\"pv_대분류수정_{col}_총구매금액\"]/test_ft[\"총구매액\"]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류별 구매주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 174), (12225, 174))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = pd.pivot_table(train_tr,index=\"ID\",columns=\"대분류_수정\",values=\"구매일시\",\\\n",
    "                           aggfunc=(lambda x: int( (x.max() - x.min()).days / x.dt.date.nunique())), fill_value=0)\\\n",
    "                           .add_prefix(\"대분류수정_\").add_suffix(\"_구매주기\").reset_index()\n",
    "train_ft = train_ft.merge(train_tmp, on=\"ID\", how= \"left\")\n",
    "\n",
    "test_tmp = pd.pivot_table(test_tr,index=\"ID\",columns=\"대분류_수정\",values=\"구매일시\",\\\n",
    "                           aggfunc=(lambda x: int( (x.max() - x.min()).days / x.dt.date.nunique())), fill_value=0)\\\n",
    "                           .add_prefix(\"대분류수정_\").add_suffix(\"_구매주기\").reset_index()\n",
    "test_ft = test_ft.merge(test_tmp, on=\"ID\", how= \"left\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중분류_수정 기준 금액 합계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 194), (12225, 194))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = pd.pivot_table(train_tr,index=\"ID\",columns=\"중분류_수정\",values=\"구매가격\",aggfunc=\"sum\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_중분류수정_\").add_suffix(\"_총구매금액\").reset_index()\n",
    "train_ft = train_ft.merge(train_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "test_tmp = pd.pivot_table(test_tr,index=\"ID\",columns=\"중분류_수정\",values=\"구매가격\",aggfunc=\"sum\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_중분류수정_\").add_suffix(\"_총구매금액\").reset_index()\n",
    "\n",
    "for col in train_tmp.columns:\n",
    "    if col not in test_tmp.columns:\n",
    "        test_tmp[col] = 0\n",
    "\n",
    "test_tmp = test_tmp[train_tmp.columns]\n",
    "test_ft = test_ft.merge(test_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중분류_수정 기준 구매횟수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 214), (12225, 214))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = pd.pivot_table(train_tr,index=\"ID\",columns=\"중분류_수정\",values=\"구매가격\",aggfunc=\"count\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_중분류수정_\").add_suffix(\"_구매횟수\").reset_index()\n",
    "train_ft = train_ft.merge(train_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "test_tmp = pd.pivot_table(test_tr,index=\"ID\",columns=\"중분류_수정\",values=\"구매가격\",aggfunc=\"count\",fill_value=0)\\\n",
    "            .add_prefix(\"pv_중분류수정_\").add_suffix(\"_구매횟수\").reset_index()\n",
    "\n",
    "for col in train_tmp.columns:\n",
    "    if col not in test_tmp.columns:\n",
    "        test_tmp[col] = 0\n",
    "\n",
    "test_tmp = test_tmp[train_tmp.columns]\n",
    "test_ft = test_ft.merge(test_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중분류_수정 기준 구입비중\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 234), (12225, 234))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in train_tr[\"중분류_수정\"].unique():\n",
    "    train_ft[f\"pv_중분류수정_{col}_구입비중\"] = train_ft[f\"pv_중분류수정_{col}_총구매금액\"]/train_ft[\"총구매액\"]\n",
    "    test_ft[f\"pv_중분류수정_{col}_구입비중\"] = test_ft[f\"pv_중분류수정_{col}_총구매금액\"]/test_ft[\"총구매액\"]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중분류별 구매주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 254), (12225, 254))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = pd.pivot_table(train_tr,index=\"ID\",columns=\"중분류_수정\",values=\"구매일시\",\\\n",
    "                           aggfunc=(lambda x: int( (x.max() - x.min()).days / x.dt.date.nunique())), fill_value=0)\\\n",
    "                           .add_prefix(\"중분류수정_\").add_suffix(\"_구매주기\").reset_index()\n",
    "train_ft = train_ft.merge(train_tmp, on=\"ID\", how= \"left\")\n",
    "\n",
    "test_tmp = pd.pivot_table(test_tr,index=\"ID\",columns=\"중분류_수정\",values=\"구매일시\",\\\n",
    "                           aggfunc=(lambda x: int( (x.max() - x.min()).days / x.dt.date.nunique())), fill_value=0)\\\n",
    "                           .add_prefix(\"중분류수정_\").add_suffix(\"_구매주기\").reset_index()\n",
    "test_ft = test_ft.merge(test_tmp, on=\"ID\", how= \"left\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공휴일에 구매한 대분류별 가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 260), (12225, 260))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공휴일에 구매한 대분류별 가격 - train\n",
    "holiday_data = train_tr[train_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_pivot = pd.pivot_table(holiday_data, index= \"ID\", columns= \"대분류_수정\", values= \"구매가격\", aggfunc=\"sum\", fill_value= 0)\\\n",
    "                .add_prefix(\"공휴일_대분류수정_\").add_suffix(\"_총구매금액\").reset_index()\n",
    "\n",
    "train_ft = train_ft.merge(holiday_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        train_ft[col] = train_ft[col].fillna(0)\n",
    "\n",
    "# 공휴일에 구매한 대분류별 가격 - test\n",
    "holiday_data = test_tr[test_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_pivot = pd.pivot_table(holiday_data, index= \"ID\", columns= \"대분류_수정\", values= \"구매가격\", aggfunc=\"sum\", fill_value= 0)\\\n",
    "                .add_prefix(\"공휴일_대분류수정_\").add_suffix(\"_총구매금액\").reset_index()\n",
    "\n",
    "test_ft = test_ft.merge(holiday_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        test_ft[col] = test_ft[col].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공휴일에 구매한 대분류별 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 266), (12225, 266))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공휴일에 구매한 대분류별 횟수 - train\n",
    "holiday_data = train_tr[train_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_pivot = pd.pivot_table(holiday_data, index= \"ID\", columns= \"대분류_수정\", values= \"구매가격\", aggfunc=\"count\", fill_value= 0)\\\n",
    "                .add_prefix(\"공휴일_대분류수정_\").add_suffix(\"_구매횟수\").reset_index()\n",
    "\n",
    "train_ft = train_ft.merge(holiday_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        train_ft[col] = train_ft[col].fillna(0)\n",
    "\n",
    "# 공휴일에 구매한 대분류별 가격 - test\n",
    "holiday_data = test_tr[test_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_pivot = pd.pivot_table(holiday_data, index= \"ID\", columns= \"대분류_수정\", values= \"구매가격\", aggfunc=\"count\", fill_value= 0)\\\n",
    "                .add_prefix(\"공휴일_대분류수정_\").add_suffix(\"_구매횟수\").reset_index()\n",
    "\n",
    "test_ft = test_ft.merge(holiday_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        test_ft[col] = test_ft[col].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류별 최대평균금액  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 268), (12225, 268))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = train_tr.pivot_table(index= [\"ID\", \"대분류_수정\"], values= \"구매가격\", aggfunc= \"mean\")\\\n",
    "      .sort_values(by=['ID', \"구매가격\"], ascending=False).groupby('ID').head(1).reset_index()\n",
    "train_tmp = train_tmp.rename(columns= {\"대분류_수정\": \"대분류_수정_평균금액최대\", \"구매가격\" : \"대분류_수정_평균구매가격\"})\n",
    "train_ft = train_ft.merge(train_tmp, on= \"ID\", how= \"left\")\n",
    "\n",
    "test_tmp = test_tr.pivot_table(index= [\"ID\", \"대분류_수정\"], values= \"구매가격\", aggfunc= \"mean\")\\\n",
    "      .sort_values(by=['ID', \"구매가격\"], ascending=False).groupby('ID').head(1).reset_index()\n",
    "test_tmp = test_tmp.rename(columns= {\"대분류_수정\": \"대분류_수정_평균금액최대\", \"구매가격\" : \"대분류_수정_평균구매가격\"})\n",
    "test_ft = test_ft.merge(test_tmp, on= \"ID\", how= \"left\")\n",
    "\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LopLwsb3NaE0"
   },
   "source": [
    "# 항상 확인하기\n",
    "- 학습데이터와 테스트 데이터의 피처개수는 동일해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.isnull().sum().sum(), test_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "At-Xx2XoNXDo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 268), (12225, 268))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxEi3_gLM8rh"
   },
   "source": [
    "# 추출한 피처 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "am-hCMk3M3x-"
   },
   "outputs": [],
   "source": [
    "train_ft.to_csv(\"train_common_v2.3_1104.csv\",index=False)\n",
    "test_ft.to_csv(\"test_common_v2.3_1104.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/05 Project_Final/Feature_csv\"\n",
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v2.0_1101.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v2.0_1101.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 465), (12225, 465))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.isnull().sum().sum(), test_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft.drop(columns= \"ID\", inplace= True)\n",
    "test_ft.drop(columns= \"ID\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['주구매지점', '주구매_대분류_수정', '주구매_중분류_수정', '대분류_수정_평균금액최대'], dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "# 범주형 변수 원핫인코딩\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(train_ft[cols])\n",
    "tmp = pd.DataFrame(\n",
    "    enc.transform(train_ft[cols]).toarray(),\n",
    "    columns = enc.get_feature_names_out()\n",
    ")\n",
    "train_ft = pd.concat([train_ft,tmp],axis=1).drop(columns=cols)\n",
    "\n",
    "tmp = pd.DataFrame(\n",
    "    enc.transform(test_ft[cols]).toarray(),\n",
    "    columns = enc.get_feature_names_out()\n",
    ")\n",
    "test_ft = pd.concat([test_ft,tmp],axis=1).drop(columns=cols)\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_ft)\n",
    "train_ft[train_ft.columns] = scaler.transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)\n",
    "\n",
    "# 정답 데이터\n",
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Macro Score: 0.701819076212095\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {'n_estimators': 800,\n",
    " 'learning_rate': 0.04036413044768581,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.7505214930635562,\n",
    " 'colsample_bytree': 0.6290102054237857,\n",
    " 'gamma': 0.648553153047272}\n",
    "\n",
    "# F1 매크로 스코어와 모델을 저장할 리스트\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "# Stratified K-Fold 교차 검증 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 루프\n",
    "for tri, vai in cv.split(train_ft, target):\n",
    "    # 학습 데이터와 검증 데이터 분리\n",
    "    x_train = train_ft.iloc[tri]\n",
    "    y_train = target.iloc[tri]\n",
    "    x_valid = train_ft.iloc[vai]\n",
    "    y_valid = target.iloc[vai]\n",
    "\n",
    "    # 모델 초기화 및 학습\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)   \n",
    "    \n",
    "    # 모델 저장\n",
    "    models.append(model)\n",
    "\n",
    "    # 예측 및 F1 매크로 스코어 계산\n",
    "    pred = model.predict(x_valid)\n",
    "    score = f1_score(y_valid, pred, average='macro')\n",
    "    scores.append(score)\n",
    "\n",
    "# F1 매크로 스코어의 평균 출력\n",
    "print(\"Mean F1 Macro Score:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7037877333128504,\n",
       " 0.700004893139275,\n",
       " 0.6998877039105895,\n",
       " 0.7110895279393836,\n",
       " 0.6943255227583771]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {'n_estimators': 800,\n",
    " 'learning_rate': 0.04036413044768581,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 7,\n",
    " 'subsample': 0.7505214930635562,\n",
    " 'colsample_bytree': 0.6290102054237857,\n",
    " 'gamma': 0.648553153047272}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "model.fit(train_ft, target)\n",
    "pred = model.predict(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = pred\n",
    "\n",
    "submit.to_csv(\"6조_v2.1_1104.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "importance = model.feature_importances_  \n",
    "feature_names = train_ft.columns \n",
    "importance_list = []\n",
    "for i in range(len(importance)):\n",
    "    importance_list.append([feature_names[i], importance[i]])\n",
    "pd.DataFrame(importance_list, columns=[\"feature_names\", \"importance\"]).sort_values(by= \"importance\", ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7010463996128611"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)   # 특성 선택을 하기 위한 모델\n",
    "cv = StratifiedKFold(5, shuffle= True, random_state= 42)\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "fs = SelectFromModel(rf)    # 특성선택에 사용하기 위한 모델의 객체 전달\n",
    "fs.fit(train_ft, target)    # fit : 평균 이상의 중요도를 가진 피처의 컬럼들을 저장\n",
    "x_train = fs.transform(train_ft)     # transform : 입력 데이터를 저장된 컬럼명의 피처들만 선택해서 넘파이 형태로 반환해줌\n",
    "\n",
    "scores = cross_val_score(model, x_train, target, cv= cv, scoring= \"f1_macro\", n_jobs= -1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['내점일수', '구매주기', '주말방문비율', '봄_구매비율', '여름_구매비율', '가을_구매비율',\n",
       "       '겨울_구매비율', '주구매요일', '일별평균구매건수', '아침_구매비율', '점심_구매비율', '저녁_구매비율',\n",
       "       '아침_구매건수', '점심_구매건수', '저녁_구매건수', '월초_구매비율', '월말_구매비율', '월초_구매건수',\n",
       "       '월말_구매건수', '주_구매_월', '주_구매시간대', '웨딩성수기_구매비율', '웨딩성수기_구매횟수',\n",
       "       '1월_구매비율', '2월_구매비율', '3월_구매비율', '4월_구매비율', '5월_구매비율', '6월_구매비율',\n",
       "       '7월_구매비율', '8월_구매비율', '9월_구매비율', '10월_구매비율', '11월_구매비율',\n",
       "       '12월_구매비율', '공휴일_구매비율', '여름휴가_구매비율', '연말_구매비율', '1월_구매금액',\n",
       "       '2월_구매금액', '3월_구매금액', '4월_구매금액', '5월_구매금액', '6월_구매금액', '7월_구매금액',\n",
       "       '8월_구매금액', '9월_구매금액', '10월_구매금액', '11월_구매금액', '12월_구매금액', '최근구매일',\n",
       "       '지점다양성_비율', '브랜드코드_nunique', '브랜드다양성_비율', '대분류_수정_아동_구매횟수',\n",
       "       '대분류_수정_생식품_구매횟수', '대분류_수정_의류_구매횟수', '총구매액', '구매건수', '평균구매액',\n",
       "       '최대구매액', '최소구매액', '환불금액', '구매금액표준편차', '저가_구매횟수', '중저가_구매횟수',\n",
       "       '중고가_구매횟수', '고가_구매횟수', '저가_구매비율', '중저가_구매비율', '중고가_구매비율',\n",
       "       '고가_구매비율', '대분류_수정_생식품_구매금액', '대분류_수정_의류_구매금액', '대분류_수정_아동_구매금액',\n",
       "       '대분류_수정_가정용품_구매금액', '대분류_수정_영_구매금액', '대분류_수정_명품_구매금액',\n",
       "       '대분류_수정_아동_구입비중', '대분류_수정_가정용품_구입비중', '대분류_수정_의류_구입비중',\n",
       "       '대분류_수정_생식품_구입비중', '대분류_수정_명품_구입비중', 'A144000지점_구매금액',\n",
       "       'A112000지점_구매금액', 'A373000지점_구매금액', 'A112000_구매브랜드_갯수',\n",
       "       'A373000_구매브랜드_갯수', 'pivot_cnt_식료품_기타', 'pivot_cnt_식료품_식료품',\n",
       "       'pivot_cnt_아동_완구', 'pivot_cnt_의류_의류', 'pivot_cnt_의류_잡화',\n",
       "       'pivot_cnt_의류_화장품', '대분류_수정_평균구매가격'], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-05 14:08:32] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-05 14:08:32] {1739} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 11-05 14:08:32] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-05 14:08:32] {1955} INFO - List of ML learners in AutoML Run: ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2', 'kneighbor']\n",
      "[flaml.automl.logger: 11-05 14:08:32] {2258} INFO - iteration 0, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:08:38] {2393} INFO - Estimated sufficient time budget=56421s. Estimated necessary time budget=89s.\n",
      "[flaml.automl.logger: 11-05 14:08:38] {2442} INFO -  at 6.5s,\testimator catboost's best error=0.3225,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:38] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:38] {2442} INFO -  at 6.9s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:38] {2258} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:39] {2442} INFO -  at 7.2s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:39] {2258} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:39] {2442} INFO -  at 7.5s,\testimator lgbm's best error=0.4121,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:39] {2258} INFO - iteration 4, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:40] {2442} INFO -  at 8.1s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:40] {2258} INFO - iteration 5, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:08:44] {2442} INFO -  at 12.9s,\testimator catboost's best error=0.3225,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:44] {2258} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:45] {2442} INFO -  at 13.2s,\testimator lgbm's best error=0.3488,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:45] {2258} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:45] {2442} INFO -  at 13.6s,\testimator lgbm's best error=0.3488,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:45] {2258} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:46] {2442} INFO -  at 14.2s,\testimator lgbm's best error=0.3437,\tbest estimator catboost's best error=0.3225\n",
      "[flaml.automl.logger: 11-05 14:08:46] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:47] {2442} INFO -  at 15.0s,\testimator lgbm's best error=0.3154,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:47] {2258} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:47] {2442} INFO -  at 15.6s,\testimator lgbm's best error=0.3154,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:47] {2258} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:48] {2442} INFO -  at 16.3s,\testimator lgbm's best error=0.3154,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:48] {2258} INFO - iteration 12, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:48] {2442} INFO -  at 16.7s,\testimator histgb's best error=0.6223,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:48] {2258} INFO - iteration 13, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:49] {2442} INFO -  at 17.1s,\testimator histgb's best error=0.3714,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:49] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:08:49] {2442} INFO -  at 17.7s,\testimator xgboost's best error=0.6223,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:49] {2258} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:08:50] {2442} INFO -  at 18.0s,\testimator xgboost's best error=0.6223,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:50] {2258} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:50] {2442} INFO -  at 18.8s,\testimator lgbm's best error=0.3154,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:50] {2258} INFO - iteration 17, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:51] {2442} INFO -  at 19.3s,\testimator histgb's best error=0.3604,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:51] {2258} INFO - iteration 18, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:08:53] {2442} INFO -  at 21.0s,\testimator catboost's best error=0.3225,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:53] {2258} INFO - iteration 19, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:53] {2442} INFO -  at 21.3s,\testimator histgb's best error=0.3604,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:53] {2258} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:08:53] {2442} INFO -  at 21.6s,\testimator xgboost's best error=0.3895,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:53] {2258} INFO - iteration 21, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:54] {2442} INFO -  at 22.1s,\testimator histgb's best error=0.3604,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:54] {2258} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:08:55] {2442} INFO -  at 23.4s,\testimator lgbm's best error=0.3154,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:55] {2258} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:08:55] {2442} INFO -  at 23.8s,\testimator xgboost's best error=0.3895,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:55] {2258} INFO - iteration 24, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:56] {2442} INFO -  at 24.8s,\testimator histgb's best error=0.3210,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:56] {2258} INFO - iteration 25, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:08:57] {2442} INFO -  at 25.4s,\testimator histgb's best error=0.3210,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:57] {2258} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:08:57] {2442} INFO -  at 25.8s,\testimator xgboost's best error=0.3401,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:57] {2258} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:08:58] {2442} INFO -  at 26.1s,\testimator xgboost's best error=0.3401,\tbest estimator lgbm's best error=0.3154\n",
      "[flaml.automl.logger: 11-05 14:08:58] {2258} INFO - iteration 28, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:09:03] {2442} INFO -  at 31.3s,\testimator histgb's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:03] {2258} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2442} INFO -  at 32.0s,\testimator xgboost's best error=0.3238,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2258} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2442} INFO -  at 32.2s,\testimator rf's best error=0.4385,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2258} INFO - iteration 31, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2442} INFO -  at 32.5s,\testimator rf's best error=0.4385,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2258} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2442} INFO -  at 32.8s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:04] {2258} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:05] {2442} INFO -  at 33.1s,\testimator rf's best error=0.3846,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:05] {2258} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:06] {2442} INFO -  at 34.3s,\testimator xgboost's best error=0.3201,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:06] {2258} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:09:06] {2442} INFO -  at 34.8s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:06] {2258} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:07] {2442} INFO -  at 35.1s,\testimator rf's best error=0.3693,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:07] {2258} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:07] {2442} INFO -  at 35.8s,\testimator xgboost's best error=0.3201,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:07] {2258} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:08] {2442} INFO -  at 36.1s,\testimator rf's best error=0.3693,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:08] {2258} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:08] {2442} INFO -  at 36.4s,\testimator rf's best error=0.3693,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:08] {2258} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:08] {2442} INFO -  at 36.7s,\testimator rf's best error=0.3576,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:08] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:11] {2442} INFO -  at 39.2s,\testimator xgboost's best error=0.3201,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:11] {2258} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:14] {2442} INFO -  at 42.1s,\testimator xgboost's best error=0.3152,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:14] {2258} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:09:19] {2442} INFO -  at 47.1s,\testimator catboost's best error=0.3225,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:19] {2258} INFO - iteration 44, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:19] {2442} INFO -  at 47.4s,\testimator rf's best error=0.3576,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:19] {2258} INFO - iteration 45, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:09:20] {2442} INFO -  at 48.6s,\testimator histgb's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:20] {2258} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:21] {2442} INFO -  at 49.2s,\testimator rf's best error=0.3576,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:21] {2258} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:21] {2442} INFO -  at 49.6s,\testimator rf's best error=0.3576,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:21] {2258} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:22] {2442} INFO -  at 50.6s,\testimator xgboost's best error=0.3152,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:22] {2258} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:09:23] {2442} INFO -  at 51.7s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:23] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:24] {2442} INFO -  at 52.2s,\testimator rf's best error=0.3530,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:24] {2258} INFO - iteration 51, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:09:25] {2442} INFO -  at 53.5s,\testimator histgb's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:25] {2258} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:25] {2442} INFO -  at 53.8s,\testimator rf's best error=0.3520,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:25] {2258} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:26] {2442} INFO -  at 54.1s,\testimator rf's best error=0.3520,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:26] {2258} INFO - iteration 54, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:26] {2442} INFO -  at 54.6s,\testimator rf's best error=0.3457,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:26] {2258} INFO - iteration 55, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:09:30] {2442} INFO -  at 58.2s,\testimator catboost's best error=0.3222,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:30] {2258} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:30] {2442} INFO -  at 58.7s,\testimator rf's best error=0.3454,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:30] {2258} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:31] {2442} INFO -  at 59.4s,\testimator rf's best error=0.3454,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:31] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:31] {2442} INFO -  at 59.8s,\testimator rf's best error=0.3454,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:31] {2258} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:32] {2442} INFO -  at 60.3s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:32] {2258} INFO - iteration 60, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:09:38] {2442} INFO -  at 66.3s,\testimator catboost's best error=0.3222,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:38] {2258} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:38] {2442} INFO -  at 66.8s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:38] {2258} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:09:41] {2442} INFO -  at 69.0s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:41] {2258} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:41] {2442} INFO -  at 69.6s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:41] {2258} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:42] {2442} INFO -  at 70.2s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:42] {2258} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:09:42] {2442} INFO -  at 70.5s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:42] {2258} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:43] {2442} INFO -  at 71.3s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:43] {2258} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:49] {2442} INFO -  at 77.1s,\testimator xgboost's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:49] {2258} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:49] {2442} INFO -  at 77.5s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:49] {2258} INFO - iteration 69, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:09:53] {2442} INFO -  at 81.3s,\testimator catboost's best error=0.3222,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:53] {2258} INFO - iteration 70, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:53] {2442} INFO -  at 81.7s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:53] {2258} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:09:56] {2442} INFO -  at 84.3s,\testimator xgboost's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:56] {2258} INFO - iteration 72, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:09:57] {2442} INFO -  at 85.3s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:57] {2258} INFO - iteration 73, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:09:58] {2442} INFO -  at 86.3s,\testimator histgb's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:09:58] {2258} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:10:17] {2442} INFO -  at 105.7s,\testimator xgboost's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:10:17] {2258} INFO - iteration 75, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:10:19] {2442} INFO -  at 107.2s,\testimator histgb's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:10:19] {2258} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:10:19] {2442} INFO -  at 107.6s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:10:19] {2258} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:10:24] {2442} INFO -  at 113.0s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:10:24] {2258} INFO - iteration 78, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:10:26] {2442} INFO -  at 114.4s,\testimator histgb's best error=0.3093,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:10:26] {2258} INFO - iteration 79, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:10:27] {2442} INFO -  at 115.0s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:10:27] {2258} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:10:29] {2442} INFO -  at 117.9s,\testimator lgbm's best error=0.3154,\tbest estimator histgb's best error=0.3093\n",
      "[flaml.automl.logger: 11-05 14:10:29] {2258} INFO - iteration 81, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:10:32] {2442} INFO -  at 120.3s,\testimator histgb's best error=0.3082,\tbest estimator histgb's best error=0.3082\n",
      "[flaml.automl.logger: 11-05 14:10:32] {2258} INFO - iteration 82, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:10:33] {2442} INFO -  at 121.5s,\testimator rf's best error=0.3405,\tbest estimator histgb's best error=0.3082\n",
      "[flaml.automl.logger: 11-05 14:10:33] {2258} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:10:36] {2442} INFO -  at 124.6s,\testimator xgboost's best error=0.3017,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:36] {2258} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:10:42] {2442} INFO -  at 130.2s,\testimator xgboost's best error=0.3017,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:42] {2258} INFO - iteration 85, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:10:46] {2442} INFO -  at 134.0s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:46] {2258} INFO - iteration 86, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:10:46] {2442} INFO -  at 134.4s,\testimator rf's best error=0.3405,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:46] {2258} INFO - iteration 87, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:10:47] {2442} INFO -  at 135.8s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:47] {2258} INFO - iteration 88, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:10:48] {2442} INFO -  at 136.5s,\testimator rf's best error=0.3404,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:48] {2258} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:10:49] {2442} INFO -  at 137.0s,\testimator lgbm's best error=0.3154,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:49] {2258} INFO - iteration 90, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:10:51] {2442} INFO -  at 139.6s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:51] {2258} INFO - iteration 91, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:10:53] {2442} INFO -  at 141.3s,\testimator rf's best error=0.3404,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:53] {2258} INFO - iteration 92, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:10:54] {2442} INFO -  at 142.6s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:10:54] {2258} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:11:09] {2442} INFO -  at 157.3s,\testimator xgboost's best error=0.3017,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:09] {2258} INFO - iteration 94, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:09] {2442} INFO -  at 158.0s,\testimator rf's best error=0.3404,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:10] {2258} INFO - iteration 95, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:11:13] {2442} INFO -  at 161.9s,\testimator catboost's best error=0.3222,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:13] {2258} INFO - iteration 96, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:11:15] {2442} INFO -  at 163.6s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:15] {2258} INFO - iteration 97, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:16] {2442} INFO -  at 164.9s,\testimator rf's best error=0.3404,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:16] {2258} INFO - iteration 98, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:17] {2442} INFO -  at 165.6s,\testimator rf's best error=0.3356,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:17] {2258} INFO - iteration 99, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:17] {2442} INFO -  at 165.9s,\testimator rf's best error=0.3356,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:17] {2258} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:11:18] {2442} INFO -  at 166.7s,\testimator lgbm's best error=0.3154,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:18] {2258} INFO - iteration 101, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:11:23] {2442} INFO -  at 171.1s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:23] {2258} INFO - iteration 102, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:24] {2442} INFO -  at 172.4s,\testimator rf's best error=0.3356,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:24] {2258} INFO - iteration 103, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:11:33] {2442} INFO -  at 181.9s,\testimator catboost's best error=0.3106,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:33] {2258} INFO - iteration 104, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:34] {2442} INFO -  at 182.5s,\testimator rf's best error=0.3356,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:34] {2258} INFO - iteration 105, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:35] {2442} INFO -  at 183.5s,\testimator rf's best error=0.3273,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:35] {2258} INFO - iteration 106, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:37] {2442} INFO -  at 185.3s,\testimator rf's best error=0.3273,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:37] {2258} INFO - iteration 107, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:11:40] {2442} INFO -  at 188.1s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:40] {2258} INFO - iteration 108, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:40] {2442} INFO -  at 188.7s,\testimator rf's best error=0.3273,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:40] {2258} INFO - iteration 109, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:11:42] {2442} INFO -  at 191.0s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:43] {2258} INFO - iteration 110, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:11:43] {2442} INFO -  at 191.9s,\testimator rf's best error=0.3273,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:11:43] {2258} INFO - iteration 111, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:12:05] {2442} INFO -  at 213.2s,\testimator catboost's best error=0.3106,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:05] {2258} INFO - iteration 112, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:12:09] {2442} INFO -  at 217.1s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:09] {2258} INFO - iteration 113, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:12:10] {2442} INFO -  at 218.2s,\testimator rf's best error=0.3273,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:10] {2258} INFO - iteration 114, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:12:11] {2442} INFO -  at 219.4s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:11] {2258} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:12:12] {2442} INFO -  at 220.1s,\testimator lgbm's best error=0.3140,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:12] {2258} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:12:12] {2442} INFO -  at 220.5s,\testimator lgbm's best error=0.3140,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:12] {2258} INFO - iteration 117, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:12:15] {2442} INFO -  at 223.3s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:15] {2258} INFO - iteration 118, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:12:16] {2442} INFO -  at 224.6s,\testimator rf's best error=0.3257,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:16] {2258} INFO - iteration 119, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:12:24] {2442} INFO -  at 232.8s,\testimator catboost's best error=0.3106,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:24] {2258} INFO - iteration 120, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:12:26] {2442} INFO -  at 234.1s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:26] {2258} INFO - iteration 121, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:12:27] {2442} INFO -  at 235.3s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:27] {2258} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:12:28] {2442} INFO -  at 236.3s,\testimator xgboost's best error=0.3017,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:28] {2258} INFO - iteration 123, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:12:29] {2442} INFO -  at 237.3s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:29] {2258} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:12:31] {2442} INFO -  at 239.0s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:31] {2258} INFO - iteration 125, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:12:34] {2442} INFO -  at 242.4s,\testimator catboost's best error=0.3106,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:12:34] {2258} INFO - iteration 126, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:13:05] {2442} INFO -  at 273.9s,\testimator catboost's best error=0.3106,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:05] {2258} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:13:07] {2442} INFO -  at 275.7s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:07] {2258} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:13:09] {2442} INFO -  at 277.5s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:09] {2258} INFO - iteration 129, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:13:10] {2442} INFO -  at 278.1s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:10] {2258} INFO - iteration 130, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:13:11] {2442} INFO -  at 279.7s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:11] {2258} INFO - iteration 131, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:13:12] {2442} INFO -  at 280.5s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:12] {2258} INFO - iteration 132, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:13:14] {2442} INFO -  at 282.3s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:14] {2258} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:13:15] {2442} INFO -  at 283.6s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:15] {2258} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:13:18] {2442} INFO -  at 286.0s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:18] {2258} INFO - iteration 135, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:13:19] {2442} INFO -  at 287.8s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:19] {2258} INFO - iteration 136, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:13:21] {2442} INFO -  at 289.3s,\testimator histgb's best error=0.3082,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:21] {2258} INFO - iteration 137, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:13:22] {2442} INFO -  at 290.2s,\testimator rf's best error=0.3192,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:22] {2258} INFO - iteration 138, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:13:40] {2442} INFO -  at 308.0s,\testimator catboost's best error=0.3106,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:40] {2258} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:13:43] {2442} INFO -  at 311.0s,\testimator xgboost's best error=0.3017,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:43] {2258} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:13:44] {2442} INFO -  at 312.6s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:44] {2258} INFO - iteration 141, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:13:48] {2442} INFO -  at 316.0s,\testimator xgboost's best error=0.3017,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:48] {2258} INFO - iteration 142, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:13:50] {2442} INFO -  at 318.7s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:50] {2258} INFO - iteration 143, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:13:56] {2442} INFO -  at 324.8s,\testimator lrl2's best error=0.3160,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:13:56] {2258} INFO - iteration 144, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:14:00] {2442} INFO -  at 328.0s,\testimator lrl2's best error=0.3154,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:14:00] {2258} INFO - iteration 145, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:14:03] {2442} INFO -  at 331.0s,\testimator lrl2's best error=0.3154,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:14:03] {2258} INFO - iteration 146, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:14:05] {2442} INFO -  at 333.9s,\testimator lrl2's best error=0.3154,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:14:05] {2258} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:14:07] {2442} INFO -  at 335.4s,\testimator lgbm's best error=0.3063,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:14:07] {2258} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:14:09] {2442} INFO -  at 337.7s,\testimator lgbm's best error=0.3043,\tbest estimator xgboost's best error=0.3017\n",
      "[flaml.automl.logger: 11-05 14:14:09] {2258} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:14:21] {2442} INFO -  at 349.5s,\testimator lgbm's best error=0.3004,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:14:21] {2258} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:14:23] {2442} INFO -  at 351.7s,\testimator lgbm's best error=0.3004,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:14:23] {2258} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:14:32] {2442} INFO -  at 360.2s,\testimator lgbm's best error=0.3004,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:14:32] {2258} INFO - iteration 152, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:14:33] {2442} INFO -  at 361.3s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:14:33] {2258} INFO - iteration 153, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:14:35] {2442} INFO -  at 363.8s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:14:35] {2258} INFO - iteration 154, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:14:36] {2442} INFO -  at 364.6s,\testimator xgboost's best error=0.3017,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:14:36] {2258} INFO - iteration 155, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:14:42] {2442} INFO -  at 370.7s,\testimator catboost's best error=0.3106,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:14:42] {2258} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:15:06] {2442} INFO -  at 394.9s,\testimator lgbm's best error=0.3004,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:06] {2258} INFO - iteration 157, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:15:09] {2442} INFO -  at 397.4s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:09] {2258} INFO - iteration 158, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:15:12] {2442} INFO -  at 400.3s,\testimator histgb's best error=0.3082,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:12] {2258} INFO - iteration 159, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:15:13] {2442} INFO -  at 401.6s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:13] {2258} INFO - iteration 160, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:15:14] {2442} INFO -  at 402.1s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:14] {2258} INFO - iteration 161, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:15:16] {2442} INFO -  at 404.5s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:16] {2258} INFO - iteration 162, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:15:18] {2442} INFO -  at 406.0s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:18] {2258} INFO - iteration 163, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:15:19] {2442} INFO -  at 407.3s,\testimator histgb's best error=0.3082,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:19] {2258} INFO - iteration 164, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:15:21] {2442} INFO -  at 409.9s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:21] {2258} INFO - iteration 165, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:15:22] {2442} INFO -  at 410.9s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:22] {2258} INFO - iteration 166, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:15:23] {2442} INFO -  at 411.4s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:23] {2258} INFO - iteration 167, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:15:25] {2442} INFO -  at 413.5s,\testimator histgb's best error=0.3082,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:25] {2258} INFO - iteration 168, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:15:26] {2442} INFO -  at 414.3s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:26] {2258} INFO - iteration 169, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:15:27] {2442} INFO -  at 415.3s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:27] {2258} INFO - iteration 170, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:15:29] {2442} INFO -  at 417.4s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:29] {2258} INFO - iteration 171, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:15:43] {2442} INFO -  at 431.7s,\testimator catboost's best error=0.3106,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:15:43] {2258} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:16:06] {2442} INFO -  at 454.0s,\testimator lgbm's best error=0.3004,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:06] {2258} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:16:13] {2442} INFO -  at 461.9s,\testimator xgboost's best error=0.3017,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:13] {2258} INFO - iteration 174, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2442} INFO -  at 463.0s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2258} INFO - iteration 175, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2442} INFO -  at 463.4s,\testimator kneighbor's best error=0.3765,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2258} INFO - iteration 176, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2442} INFO -  at 463.6s,\testimator kneighbor's best error=0.3536,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2258} INFO - iteration 177, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2442} INFO -  at 463.9s,\testimator kneighbor's best error=0.3536,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:15] {2258} INFO - iteration 178, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:16] {2442} INFO -  at 464.2s,\testimator kneighbor's best error=0.3536,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:16] {2258} INFO - iteration 179, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:16] {2442} INFO -  at 464.5s,\testimator kneighbor's best error=0.3493,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:16] {2258} INFO - iteration 180, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:16] {2442} INFO -  at 464.7s,\testimator kneighbor's best error=0.3493,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:16] {2258} INFO - iteration 181, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2442} INFO -  at 465.0s,\testimator kneighbor's best error=0.3493,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2258} INFO - iteration 182, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2442} INFO -  at 465.3s,\testimator kneighbor's best error=0.3493,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2258} INFO - iteration 183, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2442} INFO -  at 465.5s,\testimator kneighbor's best error=0.3448,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2258} INFO - iteration 184, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2442} INFO -  at 465.8s,\testimator kneighbor's best error=0.3448,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:17] {2258} INFO - iteration 185, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:16:18] {2442} INFO -  at 466.6s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:18] {2258} INFO - iteration 186, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:18] {2442} INFO -  at 466.9s,\testimator kneighbor's best error=0.3448,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:18] {2258} INFO - iteration 187, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:19] {2442} INFO -  at 467.1s,\testimator kneighbor's best error=0.3448,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:19] {2258} INFO - iteration 188, current learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:19] {2470} INFO - stop trying learner kneighbor\n",
      "[flaml.automl.logger: 11-05 14:16:19] {2258} INFO - iteration 189, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:19] {2442} INFO -  at 467.9s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:19] {2258} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:16:22] {2442} INFO -  at 470.9s,\testimator lgbm's best error=0.3004,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:22] {2258} INFO - iteration 191, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:16:24] {2442} INFO -  at 472.1s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:24] {2258} INFO - iteration 192, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:25] {2442} INFO -  at 473.2s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:25] {2258} INFO - iteration 193, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:16:26] {2442} INFO -  at 474.3s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:26] {2258} INFO - iteration 194, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:27] {2442} INFO -  at 475.2s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:27] {2258} INFO - iteration 195, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:16:29] {2442} INFO -  at 477.7s,\testimator histgb's best error=0.3082,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:29] {2258} INFO - iteration 196, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:30] {2442} INFO -  at 478.7s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:30] {2258} INFO - iteration 197, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:16:31] {2442} INFO -  at 479.8s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:31] {2258} INFO - iteration 198, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:16:39] {2442} INFO -  at 487.3s,\testimator lgbm's best error=0.3004,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:39] {2258} INFO - iteration 199, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:40] {2442} INFO -  at 488.3s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:40] {2258} INFO - iteration 200, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:41] {2442} INFO -  at 489.2s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:41] {2258} INFO - iteration 201, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:42] {2442} INFO -  at 490.0s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:42] {2258} INFO - iteration 202, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:42] {2442} INFO -  at 490.8s,\testimator lrl2's best error=0.3145,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:42] {2258} INFO - iteration 203, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:16:48] {2442} INFO -  at 496.0s,\testimator catboost's best error=0.3106,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:48] {2258} INFO - iteration 204, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:16:49] {2442} INFO -  at 497.2s,\testimator rf's best error=0.3192,\tbest estimator lgbm's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:49] {2258} INFO - iteration 205, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:16:51] {2442} INFO -  at 499.2s,\testimator histgb's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:51] {2258} INFO - iteration 206, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:52] {2442} INFO -  at 500.2s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:52] {2258} INFO - iteration 207, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:53] {2442} INFO -  at 501.0s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:53] {2258} INFO - iteration 208, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:16:56] {2442} INFO -  at 504.7s,\testimator xgboost's best error=0.3017,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:56] {2258} INFO - iteration 209, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:16:57] {2442} INFO -  at 505.7s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:57] {2258} INFO - iteration 210, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:16:59] {2442} INFO -  at 507.8s,\testimator histgb's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:16:59] {2258} INFO - iteration 211, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:17:01] {2442} INFO -  at 509.3s,\testimator rf's best error=0.3192,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:01] {2258} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:17:03] {2442} INFO -  at 511.4s,\testimator xgboost's best error=0.3017,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:03] {2258} INFO - iteration 213, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:17:04] {2442} INFO -  at 512.7s,\testimator histgb's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:04] {2258} INFO - iteration 214, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:17:05] {2442} INFO -  at 513.4s,\testimator xgboost's best error=0.3017,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:05] {2258} INFO - iteration 215, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:17:06] {2442} INFO -  at 514.4s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:06] {2258} INFO - iteration 216, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:17:07] {2442} INFO -  at 515.4s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:07] {2258} INFO - iteration 217, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:17:08] {2442} INFO -  at 516.3s,\testimator rf's best error=0.3192,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:08] {2258} INFO - iteration 218, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:17:09] {2442} INFO -  at 517.2s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:09] {2258} INFO - iteration 219, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:17:10] {2442} INFO -  at 518.3s,\testimator rf's best error=0.3192,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:10] {2258} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:17:24] {2442} INFO -  at 532.2s,\testimator lgbm's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:24] {2258} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:17:34] {2442} INFO -  at 542.5s,\testimator lgbm's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:34] {2258} INFO - iteration 222, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:17:49] {2442} INFO -  at 557.1s,\testimator xgboost's best error=0.3017,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:17:49] {2258} INFO - iteration 223, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:18:00] {2442} INFO -  at 568.9s,\testimator catboost's best error=0.3106,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:00] {2258} INFO - iteration 224, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:18:01] {2442} INFO -  at 569.7s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:01] {2258} INFO - iteration 225, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:18:02] {2442} INFO -  at 570.7s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:02] {2258} INFO - iteration 226, current learner catboost\n",
      "[flaml.automl.logger: 11-05 14:18:10] {2442} INFO -  at 578.0s,\testimator catboost's best error=0.3106,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:10] {2258} INFO - iteration 227, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:18:12] {2442} INFO -  at 580.4s,\testimator rf's best error=0.3192,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:12] {2258} INFO - iteration 228, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:18:12] {2442} INFO -  at 580.8s,\testimator rf's best error=0.3192,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:12] {2258} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl.logger: 11-05 14:18:21] {2442} INFO -  at 589.5s,\testimator lgbm's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:21] {2258} INFO - iteration 230, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:18:22] {2442} INFO -  at 590.4s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:22] {2258} INFO - iteration 231, current learner rf\n",
      "[flaml.automl.logger: 11-05 14:18:23] {2442} INFO -  at 591.1s,\testimator rf's best error=0.3192,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:23] {2258} INFO - iteration 232, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:18:23] {2442} INFO -  at 591.8s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:23] {2258} INFO - iteration 233, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:18:25] {2442} INFO -  at 593.2s,\testimator histgb's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:25] {2258} INFO - iteration 234, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:18:25] {2442} INFO -  at 593.9s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:25] {2258} INFO - iteration 235, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:18:26] {2442} INFO -  at 594.6s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:26] {2258} INFO - iteration 236, current learner lrl2\n",
      "[flaml.automl.logger: 11-05 14:18:27] {2442} INFO -  at 595.3s,\testimator lrl2's best error=0.3145,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:27] {2258} INFO - iteration 237, current learner xgboost\n",
      "[flaml.automl.logger: 11-05 14:18:28] {2442} INFO -  at 596.9s,\testimator xgboost's best error=0.3017,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:28] {2258} INFO - iteration 238, current learner histgb\n",
      "[flaml.automl.logger: 11-05 14:18:30] {2442} INFO -  at 598.8s,\testimator histgb's best error=0.3004,\tbest estimator histgb's best error=0.3004\n",
      "[flaml.automl.logger: 11-05 14:18:30] {2582} INFO - [('histgb', {'min_samples_leaf': 33, 'learning_rate': 0.10078347470274521, 'l2_regularization': 3.86635699392674, 'max_iter': 38, 'max_bins': 15, 'max_leaf_nodes': 191, 'random_state': 24092023, 'verbose': 0}), ('lgbm', {'n_jobs': -1, 'n_estimators': 949, 'num_leaves': 22, 'min_child_samples': 37, 'learning_rate': 0.1336594694727987, 'colsample_bytree': 0.8631649584961264, 'reg_alpha': 0.0029577506362347197, 'reg_lambda': 0.20900979993309593, 'max_bin': 31, 'verbose': -1}), ('xgboost', {'n_jobs': -1, 'n_estimators': 151, 'max_leaves': 5, 'min_child_weight': 1.1771864684999496, 'learning_rate': 0.24872052407934214, 'subsample': 0.6125952671072183, 'colsample_bylevel': 0.9035822408331884, 'colsample_bytree': 0.8438144153658806, 'reg_alpha': 0.0029695775514540367, 'reg_lambda': 91.74556962155438, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('catboost', {'early_stopping_rounds': 10, 'learning_rate': 0.044286743990707034, 'n_estimators': 216, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('lrl2', {'n_jobs': -1, 'C': 1.6645000755176713, 'tol': 0.0001, 'solver': 'lbfgs', 'penalty': 'l2'}), ('rf', {'n_jobs': -1, 'n_estimators': 10, 'max_features': 0.148261023608464, 'criterion': 'entropy', 'max_leaf_nodes': 146, 'random_state': 12032022, 'verbose': 0}), ('kneighbor', {'n_jobs': -1, 'n_neighbors': 16, 'weights': 'distance'})]\n",
      "[flaml.automl.logger: 11-05 14:18:30] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 11-05 14:21:10] {2631} INFO - ensemble: StackingClassifier(estimators=[('histgb',\n",
      "                                <flaml.automl.contrib.histgb.HistGradientBoostingEstimator object at 0x0000018740277340>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x00000187402758D0>),\n",
      "                               ('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x0000018740BB0880>),\n",
      "                               ('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x0000018740...\n",
      "                                                   interaction_constraints=None,\n",
      "                                                   max_bin=None,\n",
      "                                                   max_cat_threshold=None,\n",
      "                                                   max_cat_to_onehot=None,\n",
      "                                                   max_delta_step=None,\n",
      "                                                   max_depth=None,\n",
      "                                                   max_leaves=None,\n",
      "                                                   min_child_weight=None,\n",
      "                                                   missing=nan,\n",
      "                                                   monotone_constraints=None,\n",
      "                                                   multi_strategy=None,\n",
      "                                                   n_estimators=None,\n",
      "                                                   n_jobs=None,\n",
      "                                                   num_parallel_tree=None,\n",
      "                                                   objective='binary:logistic',\n",
      "                                                   random_state=None,\n",
      "                                                   reg_alpha=None, ...),\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 11-05 14:21:10] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-05 14:21:10] {1986} INFO - Time taken to find the best model: 499.2197108268738\n",
      "[flaml.automl.logger: 11-05 14:21:10] {1996} WARNING - Time taken to find the best model is 83% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*10,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"ensemble\" : {'final_estimator' : XGBRFClassifier() },    # 메타모델이 로지스틱 회귀!\n",
    "           \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2', 'kneighbor']  }   # 앙상블에 사용할 모델 지정\n",
    "auto_ml_ens.fit(train_ft, target, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3003927358629854"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_ens.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3401226993865031"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = auto_ml_ens.predict(test_ft)\n",
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = pred\n",
    "\n",
    "submit.to_csv(\"6조_v2.3_1105.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
