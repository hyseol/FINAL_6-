{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = pd.read_csv(r'C:\\Users\\leeya\\OneDrive\\Desktop\\부캠 수업자료\\Final\\train_common_v3.3_피처삭제X_log_sqrt.csv')\n",
    "test_ft = pd.read_csv(r'C:\\Users\\leeya\\OneDrive\\Desktop\\부캠 수업자료\\Final\\test_common_v3.3_피처삭제X_log_sqrt.csv')\n",
    "target =  pd.read_csv(r'C:\\Users\\leeya\\OneDrive\\Desktop\\부캠 수업자료\\Final\\store_train.csv')\n",
    "submit = pd.read_csv(r'C:\\Users\\leeya\\OneDrive\\Desktop\\부캠 수업자료\\Final\\store_submission (2).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.shape , target.shape , test.shape , submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.isnull().sum().sum(), test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ft = train.iloc[:,1:]\n",
    "# test_ft = test.iloc[:,1:]\n",
    "# train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
    "# train_ft[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# cols = train_ft.select_dtypes(include=['object']).columns\n",
    "# enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "# enc.fit(train_ft[cols])\n",
    "\n",
    "# tmp = pd.DataFrame(\n",
    "#     enc.transform(train_ft[cols]).toarray(),\n",
    "#     columns = enc.get_feature_names_out()\n",
    "# )\n",
    "# train_ft = pd.concat([train_ft, tmp], axis=1).drop(columns=cols)\n",
    "\n",
    "# tmp = pd.DataFrame(\n",
    "#     enc.transform(test_ft[cols]).toarray(),\n",
    "#     columns = enc.get_feature_names_out()\n",
    "# )\n",
    "# test_ft = pd.concat([test_ft, tmp], axis=1).drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object'), Index([], dtype='object'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.select_dtypes(\"object\").columns , test_ft.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>내점일수</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>평일방문비율</th>\n",
       "      <th>주말방문횟수</th>\n",
       "      <th>평일방문횟수</th>\n",
       "      <th>봄_구매비율</th>\n",
       "      <th>여름_구매비율</th>\n",
       "      <th>가을_구매비율</th>\n",
       "      <th>겨울_구매비율</th>\n",
       "      <th>...</th>\n",
       "      <th>공휴일_대분류_영플라자_구매횟수</th>\n",
       "      <th>공휴일_대분류_잡화_구매횟수</th>\n",
       "      <th>공휴일_대분류_케주얼_구두_아동_구매횟수</th>\n",
       "      <th>공휴일_대분류_패션잡화_구매횟수</th>\n",
       "      <th>주구매지점_1</th>\n",
       "      <th>주구매지점_2</th>\n",
       "      <th>주구매지점_3</th>\n",
       "      <th>주구매지점_4</th>\n",
       "      <th>주구매_중분류_cnt</th>\n",
       "      <th>주구매_대분류_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.817307</td>\n",
       "      <td>0.465122</td>\n",
       "      <td>2.057180</td>\n",
       "      <td>-2.057180</td>\n",
       "      <td>0.402950</td>\n",
       "      <td>-0.707545</td>\n",
       "      <td>0.389871</td>\n",
       "      <td>0.169105</td>\n",
       "      <td>0.983673</td>\n",
       "      <td>-1.139300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>2.135925</td>\n",
       "      <td>0.117952</td>\n",
       "      <td>0.605952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.079415</td>\n",
       "      <td>1.594786</td>\n",
       "      <td>0.257728</td>\n",
       "      <td>-0.257728</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>-0.707545</td>\n",
       "      <td>-2.554055</td>\n",
       "      <td>-1.174204</td>\n",
       "      <td>2.619433</td>\n",
       "      <td>0.091939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>1.632592</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.864013</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.244703</td>\n",
       "      <td>-0.767239</td>\n",
       "      <td>-1.141847</td>\n",
       "      <td>1.141847</td>\n",
       "      <td>-2.069449</td>\n",
       "      <td>-0.571325</td>\n",
       "      <td>-2.554055</td>\n",
       "      <td>1.646745</td>\n",
       "      <td>0.838272</td>\n",
       "      <td>-1.139300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>1.515861</td>\n",
       "      <td>1.448160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100008</td>\n",
       "      <td>-0.356452</td>\n",
       "      <td>-0.966900</td>\n",
       "      <td>0.966900</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>0.329126</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>1.029662</td>\n",
       "      <td>0.552014</td>\n",
       "      <td>-0.523681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>1.604686</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>1.515861</td>\n",
       "      <td>-0.626416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.420032</td>\n",
       "      <td>0.311077</td>\n",
       "      <td>1.524009</td>\n",
       "      <td>-1.524009</td>\n",
       "      <td>0.529411</td>\n",
       "      <td>-0.279285</td>\n",
       "      <td>0.401323</td>\n",
       "      <td>0.169105</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>-0.670257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>1.604686</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.865137</td>\n",
       "      <td>-0.991013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       내점일수      구매주기    주말방문비율    평일방문비율    주말방문횟수    평일방문횟수    봄_구매비율  \\\n",
       "0 -0.817307  0.465122  2.057180 -2.057180  0.402950 -0.707545  0.389871   \n",
       "1 -1.079415  1.594786  0.257728 -0.257728  0.294145 -0.707545 -2.554055   \n",
       "2 -1.244703 -0.767239 -1.141847  1.141847 -2.069449 -0.571325 -2.554055   \n",
       "3  0.100008 -0.356452 -0.966900  0.966900  0.294145  0.329126  0.350468   \n",
       "4 -0.420032  0.311077  1.524009 -1.524009  0.529411 -0.279285  0.401323   \n",
       "\n",
       "    여름_구매비율   가을_구매비율   겨울_구매비율  ...  공휴일_대분류_영플라자_구매횟수  공휴일_대분류_잡화_구매횟수  \\\n",
       "0  0.169105  0.983673 -1.139300  ...          -0.162079         -0.35278   \n",
       "1 -1.174204  2.619433  0.091939  ...          -0.162079         -0.35278   \n",
       "2  1.646745  0.838272 -1.139300  ...          -0.162079         -0.35278   \n",
       "3  1.029662  0.552014 -0.523681  ...          -0.162079         -0.35278   \n",
       "4  0.169105  0.014334 -0.670257  ...          -0.162079         -0.35278   \n",
       "\n",
       "   공휴일_대분류_케주얼_구두_아동_구매횟수  공휴일_대분류_패션잡화_구매횟수   주구매지점_1   주구매지점_2   주구매지점_3  \\\n",
       "0               -0.276145          -0.259675 -0.604571 -0.623175 -0.612523   \n",
       "1               -0.276145          -0.259675 -0.604571 -0.623175  1.632592   \n",
       "2               -0.276145          -0.259675  1.654066 -0.623175 -0.612523   \n",
       "3               -0.276145          -0.259675 -0.604571  1.604686 -0.612523   \n",
       "4               -0.276145          -0.259675 -0.604571  1.604686 -0.612523   \n",
       "\n",
       "    주구매지점_4  주구매_중분류_cnt  주구매_대분류_cnt  \n",
       "0  2.135925     0.117952     0.605952  \n",
       "1 -0.468181    -0.864013     1.064726  \n",
       "2 -0.468181     1.515861     1.448160  \n",
       "3 -0.468181     1.515861    -0.626416  \n",
       "4 -0.468181    -0.865137    -0.991013  \n",
       "\n",
       "[5 rows x 1472 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>내점일수</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>평일방문비율</th>\n",
       "      <th>주말방문횟수</th>\n",
       "      <th>평일방문횟수</th>\n",
       "      <th>봄_구매비율</th>\n",
       "      <th>여름_구매비율</th>\n",
       "      <th>가을_구매비율</th>\n",
       "      <th>겨울_구매비율</th>\n",
       "      <th>...</th>\n",
       "      <th>공휴일_대분류_영플라자_구매횟수</th>\n",
       "      <th>공휴일_대분류_잡화_구매횟수</th>\n",
       "      <th>공휴일_대분류_케주얼_구두_아동_구매횟수</th>\n",
       "      <th>공휴일_대분류_패션잡화_구매횟수</th>\n",
       "      <th>주구매지점_1</th>\n",
       "      <th>주구매지점_2</th>\n",
       "      <th>주구매지점_3</th>\n",
       "      <th>주구매지점_4</th>\n",
       "      <th>주구매_중분류_cnt</th>\n",
       "      <th>주구매_대분류_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.255374</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.257728</td>\n",
       "      <td>-0.257728</td>\n",
       "      <td>0.428635</td>\n",
       "      <td>-0.128919</td>\n",
       "      <td>0.346813</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.838272</td>\n",
       "      <td>0.338186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.352780</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.741478</td>\n",
       "      <td>-1.315250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.402970</td>\n",
       "      <td>-0.356452</td>\n",
       "      <td>-1.008554</td>\n",
       "      <td>1.008554</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.398608</td>\n",
       "      <td>-0.390607</td>\n",
       "      <td>0.620171</td>\n",
       "      <td>-0.552996</td>\n",
       "      <td>...</td>\n",
       "      <td>2.389509</td>\n",
       "      <td>-0.352780</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>3.890999</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>1.604686</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.448069</td>\n",
       "      <td>-0.626416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.911468</td>\n",
       "      <td>-0.869935</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>-0.036742</td>\n",
       "      <td>0.718373</td>\n",
       "      <td>1.388325</td>\n",
       "      <td>0.410273</td>\n",
       "      <td>-0.514333</td>\n",
       "      <td>-0.304527</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.352780</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>1.632592</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.869072</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.007893</td>\n",
       "      <td>-1.023980</td>\n",
       "      <td>-0.080558</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>2.358551</td>\n",
       "      <td>0.401120</td>\n",
       "      <td>-0.327474</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>-0.135636</td>\n",
       "      <td>...</td>\n",
       "      <td>10.044273</td>\n",
       "      <td>-0.352780</td>\n",
       "      <td>3.562547</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>1.515861</td>\n",
       "      <td>-0.248364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.722054</td>\n",
       "      <td>-0.613193</td>\n",
       "      <td>0.302875</td>\n",
       "      <td>-0.302875</td>\n",
       "      <td>0.620560</td>\n",
       "      <td>0.657384</td>\n",
       "      <td>0.362380</td>\n",
       "      <td>1.707410</td>\n",
       "      <td>-0.130285</td>\n",
       "      <td>-0.821561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>2.905522</td>\n",
       "      <td>3.691907</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.847712</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       내점일수      구매주기    주말방문비율    평일방문비율    주말방문횟수    평일방문횟수    봄_구매비율  \\\n",
       "0 -0.255374  0.002987  0.257728 -0.257728  0.428635 -0.128919  0.346813   \n",
       "1  0.402970 -0.356452 -1.008554  1.008554  0.294145  0.554897  0.398608   \n",
       "2  1.911468 -0.869935  0.036742 -0.036742  0.718373  1.388325  0.410273   \n",
       "3  3.007893 -1.023980 -0.080558  0.080558  0.873482  2.358551  0.401120   \n",
       "4  0.722054 -0.613193  0.302875 -0.302875  0.620560  0.657384  0.362380   \n",
       "\n",
       "    여름_구매비율   가을_구매비율   겨울_구매비율  ...  공휴일_대분류_영플라자_구매횟수  공휴일_대분류_잡화_구매횟수  \\\n",
       "0  0.001191  0.838272  0.338186  ...          -0.162079        -0.352780   \n",
       "1 -0.390607  0.620171 -0.552996  ...           2.389509        -0.352780   \n",
       "2 -0.514333 -0.304527 -0.059266  ...          -0.162079        -0.352780   \n",
       "3 -0.327474  0.008592 -0.135636  ...          10.044273        -0.352780   \n",
       "4  1.707410 -0.130285 -0.821561  ...          -0.162079         2.905522   \n",
       "\n",
       "   공휴일_대분류_케주얼_구두_아동_구매횟수  공휴일_대분류_패션잡화_구매횟수   주구매지점_1   주구매지점_2   주구매지점_3  \\\n",
       "0               -0.276145          -0.259675  1.654066 -0.623175 -0.612523   \n",
       "1               -0.276145           3.890999 -0.604571  1.604686 -0.612523   \n",
       "2               -0.276145          -0.259675 -0.604571 -0.623175  1.632592   \n",
       "3                3.562547          -0.259675  1.654066 -0.623175 -0.612523   \n",
       "4                3.691907          -0.259675  1.654066 -0.623175 -0.612523   \n",
       "\n",
       "    주구매지점_4  주구매_중분류_cnt  주구매_대분류_cnt  \n",
       "0 -0.468181    -0.741478    -1.315250  \n",
       "1 -0.468181    -0.448069    -0.626416  \n",
       "2 -0.468181    -0.869072     1.064726  \n",
       "3 -0.468181     1.515861    -0.248364  \n",
       "4 -0.468181    -0.847712     1.064726  \n",
       "\n",
       "[5 rows x 1472 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n",
    "# test_ft[test_ft.columns] = scaler.fit_transform(test_ft)\n",
    "# train_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>내점일수</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>평일방문비율</th>\n",
       "      <th>주말방문횟수</th>\n",
       "      <th>평일방문횟수</th>\n",
       "      <th>봄_구매비율</th>\n",
       "      <th>여름_구매비율</th>\n",
       "      <th>가을_구매비율</th>\n",
       "      <th>겨울_구매비율</th>\n",
       "      <th>...</th>\n",
       "      <th>공휴일_대분류_영플라자_구매횟수</th>\n",
       "      <th>공휴일_대분류_잡화_구매횟수</th>\n",
       "      <th>공휴일_대분류_케주얼_구두_아동_구매횟수</th>\n",
       "      <th>공휴일_대분류_패션잡화_구매횟수</th>\n",
       "      <th>주구매지점_1</th>\n",
       "      <th>주구매지점_2</th>\n",
       "      <th>주구매지점_3</th>\n",
       "      <th>주구매지점_4</th>\n",
       "      <th>주구매_중분류_cnt</th>\n",
       "      <th>주구매_대분류_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.817307</td>\n",
       "      <td>0.465122</td>\n",
       "      <td>2.057180</td>\n",
       "      <td>-2.057180</td>\n",
       "      <td>0.402950</td>\n",
       "      <td>-0.707545</td>\n",
       "      <td>0.389871</td>\n",
       "      <td>0.169105</td>\n",
       "      <td>0.983673</td>\n",
       "      <td>-1.139300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>2.135925</td>\n",
       "      <td>0.117952</td>\n",
       "      <td>0.605952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.079415</td>\n",
       "      <td>1.594786</td>\n",
       "      <td>0.257728</td>\n",
       "      <td>-0.257728</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>-0.707545</td>\n",
       "      <td>-2.554055</td>\n",
       "      <td>-1.174204</td>\n",
       "      <td>2.619433</td>\n",
       "      <td>0.091939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>1.632592</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.864013</td>\n",
       "      <td>1.064726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.244703</td>\n",
       "      <td>-0.767239</td>\n",
       "      <td>-1.141847</td>\n",
       "      <td>1.141847</td>\n",
       "      <td>-2.069449</td>\n",
       "      <td>-0.571325</td>\n",
       "      <td>-2.554055</td>\n",
       "      <td>1.646745</td>\n",
       "      <td>0.838272</td>\n",
       "      <td>-1.139300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>1.654066</td>\n",
       "      <td>-0.623175</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>1.515861</td>\n",
       "      <td>1.448160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100008</td>\n",
       "      <td>-0.356452</td>\n",
       "      <td>-0.966900</td>\n",
       "      <td>0.966900</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>0.329126</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>1.029662</td>\n",
       "      <td>0.552014</td>\n",
       "      <td>-0.523681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>1.604686</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>1.515861</td>\n",
       "      <td>-0.626416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.420032</td>\n",
       "      <td>0.311077</td>\n",
       "      <td>1.524009</td>\n",
       "      <td>-1.524009</td>\n",
       "      <td>0.529411</td>\n",
       "      <td>-0.279285</td>\n",
       "      <td>0.401323</td>\n",
       "      <td>0.169105</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>-0.670257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>-0.35278</td>\n",
       "      <td>-0.276145</td>\n",
       "      <td>-0.259675</td>\n",
       "      <td>-0.604571</td>\n",
       "      <td>1.604686</td>\n",
       "      <td>-0.612523</td>\n",
       "      <td>-0.468181</td>\n",
       "      <td>-0.865137</td>\n",
       "      <td>-0.991013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       내점일수      구매주기    주말방문비율    평일방문비율    주말방문횟수    평일방문횟수    봄_구매비율  \\\n",
       "0 -0.817307  0.465122  2.057180 -2.057180  0.402950 -0.707545  0.389871   \n",
       "1 -1.079415  1.594786  0.257728 -0.257728  0.294145 -0.707545 -2.554055   \n",
       "2 -1.244703 -0.767239 -1.141847  1.141847 -2.069449 -0.571325 -2.554055   \n",
       "3  0.100008 -0.356452 -0.966900  0.966900  0.294145  0.329126  0.350468   \n",
       "4 -0.420032  0.311077  1.524009 -1.524009  0.529411 -0.279285  0.401323   \n",
       "\n",
       "    여름_구매비율   가을_구매비율   겨울_구매비율  ...  공휴일_대분류_영플라자_구매횟수  공휴일_대분류_잡화_구매횟수  \\\n",
       "0  0.169105  0.983673 -1.139300  ...          -0.162079         -0.35278   \n",
       "1 -1.174204  2.619433  0.091939  ...          -0.162079         -0.35278   \n",
       "2  1.646745  0.838272 -1.139300  ...          -0.162079         -0.35278   \n",
       "3  1.029662  0.552014 -0.523681  ...          -0.162079         -0.35278   \n",
       "4  0.169105  0.014334 -0.670257  ...          -0.162079         -0.35278   \n",
       "\n",
       "   공휴일_대분류_케주얼_구두_아동_구매횟수  공휴일_대분류_패션잡화_구매횟수   주구매지점_1   주구매지점_2   주구매지점_3  \\\n",
       "0               -0.276145          -0.259675 -0.604571 -0.623175 -0.612523   \n",
       "1               -0.276145          -0.259675 -0.604571 -0.623175  1.632592   \n",
       "2               -0.276145          -0.259675  1.654066 -0.623175 -0.612523   \n",
       "3               -0.276145          -0.259675 -0.604571  1.604686 -0.612523   \n",
       "4               -0.276145          -0.259675 -0.604571  1.604686 -0.612523   \n",
       "\n",
       "    주구매지점_4  주구매_중분류_cnt  주구매_대분류_cnt  \n",
       "0  2.135925     0.117952     0.605952  \n",
       "1 -0.468181    -0.864013     1.064726  \n",
       "2 -0.468181     1.515861     1.448160  \n",
       "3 -0.468181     1.515861    -0.626416  \n",
       "4 -0.468181    -0.865137    -0.991013  \n",
       "\n",
       "[5 rows x 1472 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1        1.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "14935    0.0\n",
       "14936    0.0\n",
       "14937    0.0\n",
       "14938    1.0\n",
       "14939    1.0\n",
       "Name: target, Length: 14940, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = target[\"target\"]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_ml_ens = AutoML()\n",
    "\n",
    "# best_params = {\n",
    "#     'hidden_layer_sizes': (88, 89), \n",
    "#     'activation': 'relu',\n",
    "#     'solver': 'adam',\n",
    "#     'alpha': 0.001230314130334757,\n",
    "#     'learning_rate_init': 0.0016991055449377132,\n",
    "#     'max_iter': 500,\n",
    "#     'validation_fraction': 0.15000000000000002,\n",
    "#     'n_iter_no_change': 10,\n",
    "#     'early_stopping': True\n",
    "# }\n",
    "\n",
    "# params = { \"metric\" : \"macro_f1\",\n",
    "#            \"task\" : \"classification\",\n",
    "#            \"time_budget\" : 60*10,\n",
    "#            \"seed\" : 42,\n",
    "#            \"early_stop\" : True,\n",
    "#            \"ensemble\" : {'final_estimator' : MLPClassifier(random_state=42, **best_params) }, \n",
    "#            \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2', 'kneighbor','svc', 'histgb']  }   # 앙상블에 사용할 모델 지정\n",
    "# auto_ml_ens.fit(train_ft, target, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-auto_ml_ens.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leeya\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leeya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-13 14:47:41] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-13 14:47:41] {1739} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 11-13 14:47:42] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-13 14:47:42] {1955} INFO - List of ML learners in AutoML Run: ['catboost', 'lgbm', 'histgb', 'lrl1', 'extra_tree']\n",
      "[flaml.automl.logger: 11-13 14:47:42] {2258} INFO - iteration 0, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:47:58] {2393} INFO - Estimated sufficient time budget=156219s. Estimated necessary time budget=186s.\n",
      "[flaml.automl.logger: 11-13 14:47:58] {2442} INFO -  at 24.9s,\testimator catboost's best error=0.2967,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:47:58] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:48:01] {2442} INFO -  at 27.6s,\testimator lgbm's best error=0.6221,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:01] {2258} INFO - iteration 2, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:48:03] {2442} INFO -  at 29.8s,\testimator histgb's best error=0.6221,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:03] {2258} INFO - iteration 3, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:48:03] {2442} INFO -  at 30.4s,\testimator extra_tree's best error=0.5235,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:03] {2258} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:48:05] {2442} INFO -  at 31.5s,\testimator extra_tree's best error=0.4118,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:05] {2258} INFO - iteration 5, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:48:06] {2442} INFO -  at 32.6s,\testimator extra_tree's best error=0.4118,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:06] {2258} INFO - iteration 6, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:48:37] {2442} INFO -  at 63.5s,\testimator catboost's best error=0.2967,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:37] {2258} INFO - iteration 7, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:48:39] {2442} INFO -  at 65.7s,\testimator histgb's best error=0.6221,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:39] {2258} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:48:41] {2442} INFO -  at 68.3s,\testimator lgbm's best error=0.6221,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:41] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:48:46] {2442} INFO -  at 72.9s,\testimator lgbm's best error=0.3468,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:46] {2258} INFO - iteration 10, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:48:53] {2442} INFO -  at 80.4s,\testimator histgb's best error=0.3523,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:53] {2258} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:48:55] {2442} INFO -  at 81.9s,\testimator extra_tree's best error=0.4118,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:48:55] {2258} INFO - iteration 12, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:49:02] {2442} INFO -  at 89.4s,\testimator histgb's best error=0.3523,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:03] {2258} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:03] {2442} INFO -  at 90.1s,\testimator extra_tree's best error=0.4038,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:03] {2258} INFO - iteration 14, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:49:06] {2442} INFO -  at 92.9s,\testimator histgb's best error=0.3403,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:06] {2258} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:07] {2442} INFO -  at 93.9s,\testimator extra_tree's best error=0.4038,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:07] {2258} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:49:09] {2442} INFO -  at 96.0s,\testimator lgbm's best error=0.3199,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:09] {2258} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:10] {2442} INFO -  at 96.6s,\testimator extra_tree's best error=0.3728,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:10] {2258} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:49:12] {2442} INFO -  at 98.8s,\testimator lgbm's best error=0.3199,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:12] {2258} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:13] {2442} INFO -  at 99.7s,\testimator extra_tree's best error=0.3487,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:13] {2258} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:13] {2442} INFO -  at 100.4s,\testimator extra_tree's best error=0.3487,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:14] {2258} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:14] {2442} INFO -  at 101.2s,\testimator extra_tree's best error=0.3487,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:14] {2258} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:49:16] {2442} INFO -  at 103.3s,\testimator lgbm's best error=0.3064,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:16] {2258} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:49:19] {2442} INFO -  at 106.0s,\testimator lgbm's best error=0.3064,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:19] {2258} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:20] {2442} INFO -  at 107.2s,\testimator extra_tree's best error=0.3340,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:20] {2258} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:21] {2442} INFO -  at 108.1s,\testimator extra_tree's best error=0.3340,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:21] {2258} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:49:25] {2442} INFO -  at 112.1s,\testimator lgbm's best error=0.3064,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:25] {2258} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:28] {2442} INFO -  at 114.5s,\testimator extra_tree's best error=0.3124,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:28] {2258} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:30] {2442} INFO -  at 117.1s,\testimator extra_tree's best error=0.3124,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:30] {2258} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:33] {2442} INFO -  at 119.6s,\testimator extra_tree's best error=0.3124,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:33] {2258} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:49:39] {2442} INFO -  at 126.1s,\testimator lgbm's best error=0.3064,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:39] {2258} INFO - iteration 31, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:49:51] {2442} INFO -  at 138.3s,\testimator catboost's best error=0.2967,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:51] {2258} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:49:54] {2442} INFO -  at 140.4s,\testimator lgbm's best error=0.3064,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:54] {2258} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:49:56] {2442} INFO -  at 142.8s,\testimator extra_tree's best error=0.3124,\tbest estimator catboost's best error=0.2967\n",
      "[flaml.automl.logger: 11-13 14:49:56] {2258} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:50:00] {2442} INFO -  at 147.3s,\testimator lgbm's best error=0.2952,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:00] {2258} INFO - iteration 35, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:50:05] {2442} INFO -  at 152.1s,\testimator histgb's best error=0.3158,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:05] {2258} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:50:07] {2442} INFO -  at 153.6s,\testimator extra_tree's best error=0.3124,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:07] {2258} INFO - iteration 37, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:50:10] {2442} INFO -  at 157.3s,\testimator histgb's best error=0.3158,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:10] {2258} INFO - iteration 38, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:50:16] {2442} INFO -  at 162.7s,\testimator histgb's best error=0.3158,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:16] {2258} INFO - iteration 39, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:50:23] {2442} INFO -  at 170.3s,\testimator histgb's best error=0.3037,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:23] {2258} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:50:25] {2442} INFO -  at 171.7s,\testimator extra_tree's best error=0.3124,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:25] {2258} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:50:27] {2442} INFO -  at 174.0s,\testimator extra_tree's best error=0.3105,\tbest estimator lgbm's best error=0.2952\n",
      "[flaml.automl.logger: 11-13 14:50:27] {2258} INFO - iteration 42, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:50:56] {2442} INFO -  at 202.4s,\testimator catboost's best error=0.2924,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:50:56] {2258} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:50:59] {2442} INFO -  at 205.7s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:50:59] {2258} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:51:00] {2442} INFO -  at 207.0s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:00] {2258} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:51:04] {2442} INFO -  at 210.5s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:04] {2258} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:51:24] {2442} INFO -  at 230.9s,\testimator lgbm's best error=0.2952,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:24] {2258} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:51:28] {2442} INFO -  at 234.5s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:28] {2258} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:51:38] {2442} INFO -  at 244.6s,\testimator lgbm's best error=0.2952,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:38] {2258} INFO - iteration 49, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:51:45] {2442} INFO -  at 252.0s,\testimator histgb's best error=0.3037,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:45] {2258} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:51:47] {2442} INFO -  at 254.3s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:47] {2258} INFO - iteration 51, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:51:57] {2442} INFO -  at 264.0s,\testimator histgb's best error=0.3036,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:51:57] {2258} INFO - iteration 52, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:52:18] {2442} INFO -  at 284.6s,\testimator histgb's best error=0.2961,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:52:18] {2258} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:52:30] {2442} INFO -  at 296.4s,\testimator lgbm's best error=0.2952,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:52:30] {2258} INFO - iteration 54, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:53:22] {2442} INFO -  at 349.2s,\testimator catboost's best error=0.2924,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:53:22] {2258} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:53:26] {2442} INFO -  at 352.7s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:53:26] {2258} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.logger: 11-13 14:53:43] {2442} INFO -  at 369.7s,\testimator lgbm's best error=0.2952,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:53:43] {2258} INFO - iteration 57, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:54:45] {2442} INFO -  at 432.4s,\testimator histgb's best error=0.2961,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:54:45] {2258} INFO - iteration 58, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:54:47] {2442} INFO -  at 433.7s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2924\n",
      "[flaml.automl.logger: 11-13 14:54:47] {2258} INFO - iteration 59, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:55:02] {2442} INFO -  at 448.7s,\testimator catboost's best error=0.2897,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:02] {2258} INFO - iteration 60, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:55:04] {2442} INFO -  at 451.0s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:04] {2258} INFO - iteration 61, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:55:20] {2442} INFO -  at 466.7s,\testimator catboost's best error=0.2897,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:20] {2258} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:55:22] {2442} INFO -  at 468.8s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:22] {2258} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:55:24] {2442} INFO -  at 470.4s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:24] {2258} INFO - iteration 64, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:55:34] {2442} INFO -  at 480.8s,\testimator catboost's best error=0.2897,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:34] {2258} INFO - iteration 65, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:55:56] {2442} INFO -  at 502.6s,\testimator histgb's best error=0.2961,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:56] {2258} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl.logger: 11-13 14:55:57] {2442} INFO -  at 504.3s,\testimator extra_tree's best error=0.3105,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:55:57] {2258} INFO - iteration 67, current learner histgb\n",
      "[flaml.automl.logger: 11-13 14:57:02] {2442} INFO -  at 569.4s,\testimator histgb's best error=0.2961,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:57:02] {2258} INFO - iteration 68, current learner catboost\n",
      "[flaml.automl.logger: 11-13 14:57:52] {2442} INFO -  at 618.9s,\testimator catboost's best error=0.2897,\tbest estimator catboost's best error=0.2897\n",
      "[flaml.automl.logger: 11-13 14:57:52] {2582} INFO - [('catboost', {'early_stopping_rounds': 11, 'learning_rate': 0.10796565911666488, 'n_estimators': 8192, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('lgbm', {'n_jobs': -1, 'n_estimators': 34, 'num_leaves': 20, 'min_child_samples': 4, 'learning_rate': 0.315031588170898, 'colsample_bytree': 0.7342686157264448, 'reg_alpha': 0.0013803510626088443, 'reg_lambda': 0.034915840503447204, 'max_bin': 255, 'verbose': -1}), ('histgb', {'min_samples_leaf': 7, 'learning_rate': 0.05768742445591144, 'l2_regularization': 17.60794941420495, 'max_iter': 629, 'max_bins': 255, 'max_leaf_nodes': 8, 'random_state': 24092023, 'verbose': 0}), ('extra_tree', {'n_jobs': -1, 'n_estimators': 29, 'max_features': 0.0743773435443346, 'criterion': 'gini', 'max_leaf_nodes': 135, 'random_state': 12032022, 'verbose': 0})]\n",
      "[flaml.automl.logger: 11-13 14:57:52] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 11-13 15:07:47] {2631} INFO - ensemble: StackingClassifier(estimators=[('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x000001E708D886B0>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x000001E72E787860>),\n",
      "                               ('histgb',\n",
      "                                <flaml.automl.contrib.histgb.HistGradientBoostingEstimator object at 0x000001E72E786930>),\n",
      "                               ('extra_tree',\n",
      "                                <flaml.automl.model.ExtraTreesEstimator object at 0x000001E72E786750>)],\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 11-13 15:07:47] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-13 15:07:47] {1986} INFO - Time taken to find the best model: 448.7394857406616\n",
      "[flaml.automl.logger: 11-13 15:07:47] {1996} WARNING - Time taken to find the best model is 75% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "Best Error (1 - Macro F1): 0.28965506323627077\n",
      "Macro F1 Score: 0.7103449367637292\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_ft, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# AutoML 파라미터 설정\n",
    "params = {\n",
    "    \"metric\": \"macro_f1\",          \n",
    "    \"task\": \"classification\",         # 분류 문제\n",
    "    \"time_budget\": 60 * 10,           \n",
    "    \"early_stop\": True,\n",
    "    \"ensemble\": True,\n",
    "    \"estimator_list\": [\n",
    "        'catboost', #0.7103\n",
    "        'lgbm', # 0.721303841676368\n",
    "        #'rf', #0.691736065431348\n",
    "        #'xgboost', #0.7069854650838352\n",
    "        'histgb', # 0.7117400238418008\n",
    "        'lrl1', # 0.7176729253239384\n",
    "        #'lrl2', # 0.6948172472872645\n",
    "        #'kneighbor', #0.6647817600633645\n",
    "        #'svc', #.6716739324544356\n",
    "        'extra_tree', #0.7092695074709463\n",
    "    ]\n",
    "}\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "auto_ml_ens.fit(X_train, y_train, **params)\n",
    "print(\"Best Error (1 - Macro F1):\", auto_ml_ens.best_loss)\n",
    "print(\"Macro F1 Score:\", 1 - auto_ml_ens.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XGboost w  'catboost', 'lgbm', 'rf', 'xgboost', 'histgb', lrl1', 'lrl2', 'kneighbor', 'svc'\n",
    "# print(auto_ml_ens.best_config)\n",
    "# 1-auto_ml_ens.best_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = auto_ml_ens.predict(test_ft)\n",
    "# submit[\"target\"] = pred\n",
    "# submit.to_csv(\"AutoML_xgboost_log.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
