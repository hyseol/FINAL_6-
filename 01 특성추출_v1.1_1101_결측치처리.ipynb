{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zknWXgof5u-B"
   },
   "source": [
    "# 컴피티션 링크\n",
    "- https://www.kaggle.com/t/2e45abe9f1434b59a3358365432a48bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "N44QYORV8wFy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhUuXRB5BCFE"
   },
   "source": [
    "- 데이터 경로 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NfX2HPof87FT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/Desktop/데이터분석/01 Practice/00_data/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/user/Desktop/데이터분석/01 Practice/00_data/\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd7JpzNBHa1"
   },
   "source": [
    "- 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KFGKUIWt89fZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523105, 7), (14940, 2), (441196, 7), (12225, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_tr = pd.read_csv(f\"{DATA_PATH}store_train_transactions.csv\") # 학습용 구매기록 데이터\n",
    "train_target = pd.read_csv(f\"{DATA_PATH}store_train.csv\") # 학습용 정답 데이터\n",
    "test_tr = pd.read_csv(f\"{DATA_PATH}store_test_transactions.csv\") # 테스트용 구매기록 데이터\n",
    "submit = pd.read_csv(f\"{DATA_PATH}store_submission.csv\") # 제출 양식 데이터\n",
    "\n",
    "train_tr.shape , train_target.shape , test_tr.shape , submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tr.isnull().sum().sum(), test_tr.isnull().sum().sum(), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r43SCHUujW-f"
   },
   "source": [
    "# 특성 공학(Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONQYpWOjlbE9"
   },
   "source": [
    "## 날짜 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SYPmQb7dlVTu"
   },
   "outputs": [],
   "source": [
    "train_tr[\"구매일시\"] = pd.to_datetime(train_tr[\"구매일시\"])\n",
    "test_tr[\"구매일시\"] = pd.to_datetime(test_tr[\"구매일시\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzdFiwxsrFa4"
   },
   "source": [
    "## 새로 만든 feature와 병합할 고객ID로만 이루어진 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Is0n2MKZrMWp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 1), (12225, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft = train_target[[\"ID\"]]\n",
    "test_ft = submit[[\"ID\"]]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arH5g0kMmCTa"
   },
   "source": [
    "## 구매일시를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2004년 5월 ~ 2005년 4월 공휴일 리스트\n",
    "holiday_2004 = [\"2004-05-05\", \"2004-05-26\", \"2004-06-06\",\n",
    "                \"2004-07-17\", \"2004-08-15\", \"2004-09-27\",\n",
    "                \"2004-09-28\", \"2004-09-29\", \"2004-10-03\", \"2004-12-25\"]\n",
    "\n",
    "holiday_2005 = [\"2005-01-01\", \"2005-02-08\", \"2005-02-09\",\n",
    "                \"2005-02-10\", \"2005-03-01\", \"2005-04-05\"]\n",
    "\n",
    "holidays = pd.to_datetime(holiday_2004 + holiday_2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJt2fPnXmAsM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 67), (12225, 67))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "        # 컬럼명, 집계 방식\n",
    "        ('내점일수', lambda x: x.dt.date.nunique()),       # 내점일수 수정 : 날짜만 선택해서 nuique\n",
    "        ('구매주기', lambda x: int( (x.max() - x.min()).days / x.dt.date.nunique()) ),\n",
    "        ('주말방문비율', lambda x: np.mean(x.dt.weekday>4)),\n",
    "        ('봄_구매비율', lambda x: np.mean(x.dt.month.isin([3,4,5]))),\n",
    "        ('여름_구매비율', lambda x: np.mean(x.dt.month.isin([6,7,8]))),\n",
    "        ('가을_구매비율', lambda x: np.mean(x.dt.month.isin([9,10,11]))),\n",
    "        ('겨울_구매비율', lambda x: np.mean(x.dt.month.isin([1,2,12]))),\n",
    "        ('주구매요일', lambda x: x.dt.weekday.mode()[0]),\n",
    "        ('일별평균구매건수', lambda x:  x.count() / x.dt.date.nunique() ),\n",
    "        ('거래개월수', lambda x: x.dt.date.astype(str).str[:-3].nunique() ),\n",
    "        \n",
    "        ('아침_구매비율', lambda x: np.mean(x.dt.hour.isin(range(6, 12)))),       # 시간대 별 구매비율 추가\n",
    "        ('점심_구매비율', lambda x: np.mean(x.dt.hour.isin(range(12, 18)))),      # 시간대 별 구매비율 추가\n",
    "        ('저녁_구매비율', lambda x:np.mean(x.dt.hour.isin(range(18, 22)))),       # 시간대 별 구매비율 추가\n",
    "        ('야간_구매비율', lambda x:np.mean(~x.dt.hour.isin(range(6, 22)))),       # 시간대 별 구매비율 추가\n",
    "\n",
    "        ('아침_구매건수', lambda x: np.sum(x.dt.hour.isin(range(6, 12)))),       # 시간대 별 구매건수 추가\n",
    "        ('점심_구매건수', lambda x: np.sum(x.dt.hour.isin(range(12, 18)))),      # 시간대 별 구매건수 추가\n",
    "        ('저녁_구매건수', lambda x:np.sum(x.dt.hour.isin(range(18, 22)))),       # 시간대 별 구매건수 추가\n",
    "        ('야간_구매건수', lambda x:np.sum(~x.dt.hour.isin(range(6, 22)))),       # 시간대 별 구매건수 추가\n",
    "\n",
    "        ('월초_구매비율', lambda x: np.mean(x.dt.day <= 10)),                     # 월초 구매비율 추가(10일 이전)\n",
    "        ('월말_구매비율', lambda x: np.mean(x.dt.day >= 20)),                     # 월말 구매비율 추가(20일 이후)\n",
    "\n",
    "        ('월초_구매건수', lambda x: np.sum(x.dt.day <= 10)),                     # 월초 구매건수 추가(10일 이전)\n",
    "        ('월말_구매건수', lambda x: np.sum(x.dt.day >= 20)),                     # 월말 구매건수 추가(20일 이후)\n",
    "\n",
    "        (\"주_구매_월\", lambda x: x.dt.month.mode()[0]),         # 주구매 월 추가\n",
    "        (\"주_구매시간대\", lambda x: x.dt.hour.mode()[0]),       # 주구매 시간대 추가\n",
    "\n",
    "        ('웨딩성수기_구매비율', lambda x: np.mean(x.dt.month.isin([4, 5, 9, 10]))),  # 결혼 성수기 시즌 구매 비율\n",
    "        ('웨딩성수기_구매횟수', lambda x: ((x.dt.month == 4) | (x.dt.month == 5) | (x.dt.month == 9) | (x.dt.month == 10)).sum()),  # 결혼 성수기 시즌 구매 횟수\n",
    "        \n",
    "        ('1월_구매비율', lambda x: np.mean(x.dt.month == 1)), # 1월 구매비율\n",
    "        ('2월_구매비율', lambda x: np.mean(x.dt.month == 2)), # 2월 구매비율\n",
    "        ('3월_구매비율', lambda x: np.mean(x.dt.month == 3)), # 3월 구매비율\n",
    "        ('4월_구매비율', lambda x: np.mean(x.dt.month == 4)), # 4월 구매비율\n",
    "        ('5월_구매비율', lambda x: np.mean(x.dt.month == 5)), # 5월 구매비율\n",
    "        ('6월_구매비율', lambda x: np.mean(x.dt.month == 6)), # 6월 구매비율\n",
    "        ('7월_구매비율', lambda x: np.mean(x.dt.month == 7)), # 7월 구매비율\n",
    "        ('8월_구매비율', lambda x: np.mean(x.dt.month == 8)), # 8월 구매비율\n",
    "        ('9월_구매비율', lambda x: np.mean(x.dt.month == 9)), # 9월 구매비율\n",
    "        ('10월_구매비율', lambda x: np.mean(x.dt.month == 10)), # 10월 구매비율\n",
    "        ('11월_구매비율', lambda x: np.mean(x.dt.month == 11)), # 11월 구매비율\n",
    "        ('12월_구매비율', lambda x: np.mean(x.dt.month == 12)), # 12월 구매비율\n",
    "\n",
    "        ('1월_구매횟수', lambda x: (x.dt.month == 1).sum()),  # 1월 구매 횟수\n",
    "        ('2월_구매횟수', lambda x: (x.dt.month == 2).sum()),  # 2월 구매 횟수\n",
    "        ('3월_구매횟수', lambda x: (x.dt.month == 3).sum()),  # 3월 구매 횟수\n",
    "        ('4월_구매횟수', lambda x: (x.dt.month == 4).sum()),  # 4월 구매 횟수\n",
    "        ('5월_구매횟수', lambda x: (x.dt.month == 5).sum()),  # 5월 구매 횟수\n",
    "        ('6월_구매횟수', lambda x: (x.dt.month == 6).sum()),  # 6월 구매 횟수\n",
    "        ('7월_구매횟수', lambda x: (x.dt.month == 7).sum()),  # 7월 구매 횟수\n",
    "        ('8월_구매횟수', lambda x: (x.dt.month == 8).sum()),  # 8월 구매 횟수\n",
    "        ('9월_구매횟수', lambda x: (x.dt.month == 9).sum()),  # 9월 구매 횟수\n",
    "        ('10월_구매횟수', lambda x: (x.dt.month == 10).sum()),  # 10월 구매 횟수\n",
    "        ('11월_구매횟수', lambda x: (x.dt.month == 11).sum()),  # 11월 구매 횟수\n",
    "        ('12월_구매횟수', lambda x: (x.dt.month == 12).sum()),   # 12월 구매 횟수\n",
    "\n",
    "        ('1월_방문횟수', lambda x: x[x.dt.month == 1].dt.date.nunique()),\n",
    "        ('2월_방문횟수', lambda x: x[x.dt.month == 2].dt.date.nunique()),\n",
    "        ('3월_방문횟수', lambda x: x[x.dt.month == 3].dt.date.nunique()),\n",
    "        ('4월_방문횟수', lambda x: x[x.dt.month == 4].dt.date.nunique()),\n",
    "        ('5월_방문횟수', lambda x: x[x.dt.month == 5].dt.date.nunique()),\n",
    "        ('6월_방문횟수', lambda x: x[x.dt.month == 6].dt.date.nunique()),\n",
    "        ('7월_방문횟수', lambda x: x[x.dt.month == 7].dt.date.nunique()),\n",
    "        ('8월_방문횟수', lambda x: x[x.dt.month == 8].dt.date.nunique()),\n",
    "        ('9월_방문횟수', lambda x: x[x.dt.month == 9].dt.date.nunique()),\n",
    "        ('10월_방문횟수', lambda x: x[x.dt.month == 10].dt.date.nunique()),\n",
    "        ('11월_방문횟수', lambda x: x[x.dt.month == 11].dt.date.nunique()),\n",
    "        ('12월_방문횟수', lambda x: x[x.dt.month == 12].dt.date.nunique()),\n",
    "\n",
    "        (\"공휴일_구매유무\", lambda x: x.dt.date.isin(holidays.date).any().astype(int)),     # 공휴일 구매 유무(0과 1로 반환)\n",
    "        (\"공휴일_구매비율\", lambda x: np.mean(x.dt.date.isin(holidays.date))),  # 공휴일 구매 비율\n",
    "        (\"여름휴가_구매비율\", lambda x: np.mean(x.dt.month.isin([7,8]))),   # 방학,여름휴가(7,8월) 구매비율\n",
    "        (\"연말_구매비율\", lambda x: np.mean(x.dt.month.isin([12,1,2]))),    # 연말(12월~2월) 구매비율\n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 월별 구매금액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    train_tmp = train_tr[train_tr[\"구매일시\"].dt.month == i].groupby(\"ID\")[\"구매가격\"].sum().reset_index(name=f\"{i}월_구매금액\")\n",
    "    train_ft = train_ft.merge(train_tmp, on= \"ID\", how = \"left\")\n",
    "    train_ft[f\"{i}월_구매금액\"] = train_ft[f\"{i}월_구매금액\"].fillna(0)\n",
    "\n",
    "    test_tmp = test_tr[test_tr[\"구매일시\"].dt.month == i].groupby(\"ID\")[\"구매가격\"].sum().reset_index(name=f\"{i}월_구매금액\")\n",
    "    test_ft = test_ft.merge(test_tmp, on= \"ID\", how = \"left\")\n",
    "    test_ft[f\"{i}월_구매금액\"] = test_ft[f\"{i}월_구매금액\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 휴면회원 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 69), (12225, 69))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [(\"최근구매일\", lambda x: int( (x.max() - x.min()).days))]\n",
    "\n",
    "sort_value = train_tr.sort_values([\"ID\", \"구매일시\"], ascending= False).drop_duplicates(subset=[\"ID\", \"구매일시\"],keep='first').groupby(\"ID\").head(2)\n",
    "tmp = sort_value.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "tmp[\"휴면회원\"] = (tmp[\"최근구매일\"] > 90).astype(int)\n",
    "train_ft = train_ft.merge(tmp, how= 'left', on= \"ID\")\n",
    "\n",
    "sort_value = test_tr.sort_values([\"ID\", \"구매일시\"], ascending= False).drop_duplicates(subset=[\"ID\", \"구매일시\"],keep='first').groupby(\"ID\").head(2)\n",
    "tmp = sort_value.groupby('ID')[\"구매일시\"].agg(agg_list).reset_index()\n",
    "tmp[\"휴면회원\"] = (tmp[\"최근구매일\"] > 90).astype(int)\n",
    "test_ft = test_ft.merge(tmp, how= 'left', on= \"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxm1aP9bstSP"
   },
   "source": [
    "## 지점을 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "NAhiyQqgmAna"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 72), (12225, 72))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "          (\"방문지점수\",\"nunique\"),\n",
    "          ('주구매지점', lambda x: x.mode()[0]),\n",
    "          \n",
    "          (\"지점다양성_비율\", lambda x: x.nunique() / len(x)), # 지점 다양성 비율 추가\n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"지점코드\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"지점코드\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC7i927ntZMf"
   },
   "source": [
    "## 브랜드코드를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "U55_ClZktWbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 74), (12225, 74))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "             ('브랜드코드_nunique', 'nunique'),\n",
    "\n",
    "             ('브랜드다양성_비율',lambda x: x.nunique() / len(x)) # 브랜드다양성 추가\n",
    "\n",
    "             ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"브랜드코드\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"브랜드코드\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, how='left',on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-mYObgFtrgD"
   },
   "source": [
    "## 중분류를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "foQqMMKatWV2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 76), (12225, 76))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "            ('중분류_nunique', 'nunique'),\n",
    "            ('주구매_중분류', lambda x: x.mode()[0]),\n",
    "            ]\n",
    "tmp = train_tr.groupby('ID')[\"중분류\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"중분류\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvwbAgMluAlT"
   },
   "source": [
    "## 대분류를 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>구매일시</th>\n",
       "      <th>지점코드</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>브랜드코드</th>\n",
       "      <th>구매가격</th>\n",
       "      <th>대분류_수정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_13219</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>공산품파트</td>\n",
       "      <td>차류</td>\n",
       "      <td>5100</td>\n",
       "      <td>59700</td>\n",
       "      <td>생활용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_5590</td>\n",
       "      <td>2004-05-01 09:40:00</td>\n",
       "      <td>A144000</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>화장잡화</td>\n",
       "      <td>5101</td>\n",
       "      <td>17000</td>\n",
       "      <td>생활용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_7200</td>\n",
       "      <td>2004-05-01 10:20:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>공산품</td>\n",
       "      <td>용기보증</td>\n",
       "      <td>5100</td>\n",
       "      <td>34937</td>\n",
       "      <td>생활용품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3010</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A373000</td>\n",
       "      <td>아동_스포츠</td>\n",
       "      <td>아동복</td>\n",
       "      <td>5105</td>\n",
       "      <td>19000</td>\n",
       "      <td>아동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_10851</td>\n",
       "      <td>2004-05-01 10:30:00</td>\n",
       "      <td>A112000</td>\n",
       "      <td>가정용품</td>\n",
       "      <td>전화기_카세트</td>\n",
       "      <td>5110</td>\n",
       "      <td>215000</td>\n",
       "      <td>가정용품</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                구매일시     지점코드     대분류      중분류  브랜드코드    구매가격  \\\n",
       "0  train_13219 2004-05-01 09:40:00  A144000   공산품파트       차류   5100   59700   \n",
       "1   train_5590 2004-05-01 09:40:00  A144000    잡화파트     화장잡화   5101   17000   \n",
       "2   train_7200 2004-05-01 10:20:00  A112000     공산품     용기보증   5100   34937   \n",
       "3   train_3010 2004-05-01 10:30:00  A373000  아동_스포츠      아동복   5105   19000   \n",
       "4  train_10851 2004-05-01 10:30:00  A112000    가정용품  전화기_카세트   5110  215000   \n",
       "\n",
       "  대분류_수정  \n",
       "0   생활용품  \n",
       "1   생활용품  \n",
       "2   생활용품  \n",
       "3     아동  \n",
       "4   가정용품  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 대분류 범주 생성\n",
    "def classification(x):\n",
    "    lst_kids = ['아동_스포츠', '아동문화', '케주얼_구두_아동', '아동']\n",
    "    lst_young = [\"영어덜트캐쥬얼\", \"영캐릭터\", \"영플라자\", \"영라이브\"]\n",
    "    lst_foods = [\"생식품파트\", \"생식품\"]\n",
    "    lst_home = [\"가정용품파트\", \"가정용품\"]\n",
    "    lst_clothes = [\"스포츠캐쥬얼\", \"패션잡화\", \"여성캐쥬얼\",\"여성캐주얼\", \"남성정장스포츠\",\n",
    "                   \"남성의류\", \"여성정장\", \"여성의류파트\", \"골프_유니캐쥬얼\" ]\n",
    "    lst_loyal = [\"명품잡화\", \"로얄부띠끄\", \"로얄부틱\"]\n",
    "    lst_daily = [\"공산품\", \"잡화파트\", \"공산품파트\", \"잡화\"]\n",
    "\n",
    "    if x in lst_kids:\n",
    "        ans = \"아동\"\n",
    "    elif x in lst_foods:\n",
    "        ans = \"생식품\"\n",
    "    elif x in lst_home:\n",
    "        ans = \"가정용품\" \n",
    "    elif x in lst_clothes:\n",
    "        ans = \"의류\"      \n",
    "    elif x in lst_loyal:\n",
    "        ans = \"명품\" \n",
    "    elif x in lst_daily:\n",
    "        ans = \"생활용품\" \n",
    "    elif x in lst_young:\n",
    "        ans = \"영\"\n",
    "    return ans\n",
    "\n",
    "train_tr[\"대분류_수정\"] = train_tr[\"대분류\"].apply(classification)\n",
    "test_tr[\"대분류_수정\"] = test_tr[\"대분류\"].apply(classification)\n",
    "\n",
    "train_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 90), (12225, 90))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "            ('대분류_수정_nunique', 'nunique'),                 # 대분류_수정 기준 구매횟수\n",
    "            ('주구매_대분류_수정', lambda x: x.mode()[0]),      # 대분류_수정 기준 주구매\n",
    "\n",
    "            ('대분류_수정_아동_구매여부', lambda x: int(x.str.contains(\"아동\").any())),              # 대분류_수정에서 아동 구매 여부(1/0)\n",
    "            ('대분류_수정_생식품_구매여부', lambda x: int(x.str.contains(\"생식품\").any())),          # 대분류_수정에서 생식품 구매 여부(1/0)\n",
    "            ('대분류_수정_가정용품_구매여부', lambda x: int(x.str.contains(\"가정용품\").any())),      # 대분류_수정에서 가정용품 구매 여부(1/0)\n",
    "            ('대분류_수정_의류_구매여부', lambda x: int(x.str.contains(\"의류\").any())),              # 대분류_수정에서 의류 구매 여부(1/0)\n",
    "            ('대분류_수정_명품_구매여부', lambda x: int(x.str.contains(\"명품\").any())),              # 대분류_수정에서 명품 구매 여부(1/0)\n",
    "            ('대분류_수정_생활용품_구매여부', lambda x: int(x.str.contains(\"생활용품\").any())),      # 대분류_수정에서 생활용품 구매 여부(1/0)\n",
    "\n",
    "            ('대분류_수정_아동_구매횟수', lambda x: int(x.str.contains(\"아동\").sum())),              # 대분류_수정에서 아동 구매횟수\n",
    "            ('대분류_수정_생식품_구매횟수', lambda x: int(x.str.contains(\"생식품\").sum())),          # 대분류_수정에서 생식품 구매횟수\n",
    "            ('대분류_수정_가정용품_구매횟수', lambda x: int(x.str.contains(\"가정용품\").sum())),      # 대분류_수정에서 가정용품 구매횟수\n",
    "            ('대분류_수정_의류_구매횟수', lambda x: int(x.str.contains(\"의류\").sum())),              # 대분류_수정에서 의류 구매횟수\n",
    "            ('대분류_수정_명품_구매횟수', lambda x: int(x.str.contains(\"명품\").sum())),              # 대분류_수정에서 명품 구매횟수\n",
    "            ('대분류_수정_생활용품_구매횟수', lambda x: int(x.str.contains(\"생활용품\").sum())),      # 대분류_수정에서 생활용품 구매횟수\n",
    "\n",
    "            ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"대분류_수정\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"대분류_수정\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, on= \"ID\", how='left')\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mMqLIDKuTgB"
   },
   "source": [
    "## 구매가격을 이용한 특성생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "rlrGtiLZtIuI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 100), (12225, 100))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [\n",
    "        ('총구매액',lambda x: x[x > 0].sum()),         # 0 이상에서 적용\n",
    "        ('구매건수', lambda x: x[x > 0].count()),      # 0 이상에서 적용\n",
    "        ('평균구매액', lambda x: x[x > 0].mean()),     # 0 이상에서 적용\n",
    "        ('최대구매액', 'max'),\n",
    "        ('최소구매액',lambda x: x[x > 0].min() ) ,\n",
    "        ('환불금액',lambda x: x[x < 0].sum() ) ,\n",
    "        ('환불건수', lambda x: ( x < 0 ).sum() ),\n",
    "        ('구매금액표준편차',lambda x: x[x>0].std() ),\n",
    "\n",
    "        ('평균저가구매비율', lambda x: (x <= 102479.91701049241).sum() / len(x)), # 저가 구매 비율 (구매 총평균에 비례)\n",
    "        ('평균고가구매비율', lambda x: (x > 102479.91701049241).sum() / len(x))   # 고가 구매 비율 (구매 총평균에 비례)\n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "tmp = train_tr.groupby('ID')[\"구매가격\"].agg(agg_list).reset_index()\n",
    "train_ft = train_ft.merge(tmp, on= \"ID\", how='left')\n",
    "train_ft[\"구매금액표준편차\"] = train_ft[\"구매금액표준편차\"].fillna(0)\n",
    "\n",
    "tmp = test_tr.groupby('ID')[\"구매가격\"].agg(agg_list).reset_index()\n",
    "test_ft = test_ft.merge(tmp, on= \"ID\", how='left')\n",
    "test_ft[\"구매금액표준편차\"] = test_ft[\"구매금액표준편차\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류_수정 기준 금액 합계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 107), (12225, 107))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in train_tr['대분류_수정'].unique():\n",
    "    tmp = train_tr[train_tr['대분류_수정'] == col].groupby('ID')[\"구매가격\"].sum().reset_index()\n",
    "    tmp.rename(columns={\"구매가격\" : f\"대분류_수정_{col}_구매금액\"}, inplace = True)\n",
    "    train_ft = train_ft.merge(tmp, on= \"ID\", how= \"left\")\n",
    "    train_ft[f\"대분류_수정_{col}_구매금액\"] = train_ft[f\"대분류_수정_{col}_구매금액\"].fillna(0)\n",
    "    \n",
    "\n",
    "for col in train_tr['대분류_수정'].unique():\n",
    "    tmp = test_tr[test_tr['대분류_수정'] == col].groupby('ID')[\"구매가격\"].sum().reset_index()\n",
    "    tmp.rename(columns={\"구매가격\" : f\"대분류_수정_{col}_구매금액\"}, inplace = True)\n",
    "    test_ft = test_ft.merge(tmp, on= \"ID\", how= \"left\")\n",
    "    test_ft[f\"대분류_수정_{col}_구매금액\"] = test_ft[f\"대분류_수정_{col}_구매금액\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류_수정 기준 구입비중\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 113), (12225, 113))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft[\"대분류_수정_생활용품_구입비중\"] = train_ft[\"대분류_수정_생활용품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_아동_구입비중\"] = train_ft[\"대분류_수정_아동_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_가정용품_구입비중\"] = train_ft[\"대분류_수정_가정용품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_의류_구입비중\"] = train_ft[\"대분류_수정_의류_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_생식품_구입비중\"] = train_ft[\"대분류_수정_생식품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "train_ft[\"대분류_수정_명품_구입비중\"] = train_ft[\"대분류_수정_명품_구매금액\"] / train_ft[\"총구매액\"]\n",
    "\n",
    "test_ft[\"대분류_수정_생활용품_구입비중\"] = test_ft[\"대분류_수정_생활용품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_아동_구입비중\"] = test_ft[\"대분류_수정_아동_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_가정용품_구입비중\"] = test_ft[\"대분류_수정_가정용품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_의류_구입비중\"] = test_ft[\"대분류_수정_의류_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_생식품_구입비중\"] = test_ft[\"대분류_수정_생식품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "test_ft[\"대분류_수정_명품_구입비중\"] = test_ft[\"대분류_수정_명품_구매금액\"] / test_ft[\"총구매액\"]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 등급 범주 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 114), (12225, 114))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grade(x):\n",
    "    if x >= 10000000:\n",
    "        ans = 1\n",
    "    elif 5000000 <= x & x < 10000000:\n",
    "        ans = 2\n",
    "    elif 1000000 <= x & x < 5000000:\n",
    "        ans = 3\n",
    "    elif 0 <= x & x < 1000000:\n",
    "        ans = 4\n",
    "    return ans\n",
    "\n",
    "train_ft[\"등급\"] = train_ft[\"총구매액\"].apply(grade)\n",
    "test_ft[\"등급\"] = test_ft[\"총구매액\"].apply(grade)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지점별 금액 합계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_15424\\3346531936.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  a373000_sum = (test_tr[train_tr[\"지점코드\"] == \"A373000\"].groupby('ID')['구매가격'].sum().reset_index(name='A373000지점_구매금액'))\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_15424\\3346531936.py:24: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  a202000_sum = (test_tr[train_tr[\"지점코드\"] == \"A202000\"].groupby('ID')['구매가격'].sum().reset_index(name='A202000지점_구매금액'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((14940, 118), (12225, 118))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 지점별 합계 금액 코드 추가 (train)\n",
    "a144000_sum = (train_tr[train_tr[\"지점코드\"] == \"A144000\"].groupby('ID')['구매가격'].sum().reset_index(name='A144000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a144000_sum, how='left', on='ID')\n",
    "\n",
    "a112000_sum = (train_tr[train_tr[\"지점코드\"] == \"A112000\"].groupby('ID')['구매가격'].sum().reset_index(name='A112000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a112000_sum, how='left', on='ID')\n",
    "\n",
    "a373000_sum = (train_tr[train_tr[\"지점코드\"] == \"A373000\"].groupby('ID')['구매가격'].sum().reset_index(name='A373000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a373000_sum, how='left', on='ID')\n",
    "\n",
    "a202000_sum = (train_tr[train_tr[\"지점코드\"] == \"A202000\"].groupby('ID')['구매가격'].sum().reset_index(name='A202000지점_구매금액'))\n",
    "train_ft = train_ft.merge(a202000_sum, how='left', on='ID')\n",
    "\n",
    "#지점별 합계 금액 코드 추가 (test)\n",
    "a144000_sum = (test_tr[test_tr[\"지점코드\"] == \"A144000\"].groupby('ID')['구매가격'].sum().reset_index(name='A144000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a144000_sum, how='left', on='ID')\n",
    "\n",
    "a112000_sum = (test_tr[test_tr[\"지점코드\"] == \"A112000\"].groupby('ID')['구매가격'].sum().reset_index(name='A112000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a112000_sum, how='left', on='ID')\n",
    "\n",
    "a373000_sum = (test_tr[train_tr[\"지점코드\"] == \"A373000\"].groupby('ID')['구매가격'].sum().reset_index(name='A373000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a373000_sum, how='left', on='ID')\n",
    "\n",
    "a202000_sum = (test_tr[train_tr[\"지점코드\"] == \"A202000\"].groupby('ID')['구매가격'].sum().reset_index(name='A202000지점_구매금액'))\n",
    "test_ft = test_ft.merge(a202000_sum, how='left', on='ID')\n",
    "\n",
    "train_ft[\"A144000지점_구매금액\"] = train_ft[\"A144000지점_구매금액\"].fillna(0)\n",
    "train_ft[\"A112000지점_구매금액\"] = train_ft[\"A112000지점_구매금액\"].fillna(0)\n",
    "train_ft[\"A373000지점_구매금액\"] = train_ft[\"A373000지점_구매금액\"].fillna(0)\n",
    "train_ft[\"A202000지점_구매금액\"] = train_ft[\"A202000지점_구매금액\"].fillna(0)\n",
    "\n",
    "test_ft[\"A144000지점_구매금액\"] = test_ft[\"A144000지점_구매금액\"].fillna(0)\n",
    "test_ft[\"A112000지점_구매금액\"] = test_ft[\"A112000지점_구매금액\"].fillna(0)\n",
    "test_ft[\"A373000지점_구매금액\"] = test_ft[\"A373000지점_구매금액\"].fillna(0)\n",
    "test_ft[\"A202000지점_구매금액\"] = test_ft[\"A202000지점_구매금액\"].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지점별 구매 브랜드 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 122), (12225, 122))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#지점별 구매 브랜드 갯수 추가(train)\n",
    "a144000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A144000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A1440000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a144000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a112000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A112000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A112000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a112000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a373000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A373000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A373000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a373000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a202000_brand_counts = ( train_tr[train_tr['지점코드'] == 'A202000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A202000_구매브랜드_갯수'))\n",
    "train_ft = train_ft.merge(a202000_brand_counts, how='left', on='ID')\n",
    "train_ft.head()\n",
    "\n",
    "#지점별 구매 브랜드 갯수 추가(test)\n",
    "a144000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A144000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A1440000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a144000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a112000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A112000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A112000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a112000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a373000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A373000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A373000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a373000_brand_counts, how='left', on='ID')\n",
    "\n",
    "a202000_brand_counts = ( test_tr[test_tr['지점코드'] == 'A202000'].groupby('ID')['브랜드코드'].nunique().reset_index(name='A202000_구매브랜드_갯수'))\n",
    "test_ft = test_ft.merge(a202000_brand_counts, how='left', on='ID')\n",
    "\n",
    "\n",
    "train_ft[\"A1440000_구매브랜드_갯수\"] = train_ft[\"A1440000_구매브랜드_갯수\"].fillna(0)\n",
    "train_ft[\"A112000_구매브랜드_갯수\"] = train_ft[\"A112000_구매브랜드_갯수\"].fillna(0)\n",
    "train_ft[\"A373000_구매브랜드_갯수\"] = train_ft[\"A373000_구매브랜드_갯수\"].fillna(0)\n",
    "train_ft[\"A202000_구매브랜드_갯수\"] = train_ft[\"A202000_구매브랜드_갯수\"].fillna(0)\n",
    "\n",
    "test_ft[\"A1440000_구매브랜드_갯수\"] = test_ft[\"A1440000_구매브랜드_갯수\"].fillna(0)\n",
    "test_ft[\"A112000_구매브랜드_갯수\"] = test_ft[\"A112000_구매브랜드_갯수\"].fillna(0)\n",
    "test_ft[\"A373000_구매브랜드_갯수\"] = test_ft[\"A373000_구매브랜드_갯수\"].fillna(0)\n",
    "test_ft[\"A202000_구매브랜드_갯수\"] = test_ft[\"A202000_구매브랜드_갯수\"].fillna(0)\n",
    "\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pivot_table을 이용한 특성 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 425), (12225, 425))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 강사님 버전 \n",
    "\n",
    "train_tmp = pd.pivot_table(train_tr,index=\"ID\",columns=\"중분류\",values=\"구매가격\",aggfunc=\"count\",fill_value=0).add_prefix(\"pivot_cnt_\").reset_index()\n",
    "train_ft = train_ft.merge(train_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "test_tmp = pd.pivot_table(test_tr,index=\"ID\",columns=\"중분류\",values=\"구매가격\",aggfunc=\"count\",fill_value=0).add_prefix(\"pivot_cnt_\").reset_index()\n",
    "\n",
    "for col in train_tmp.columns:\n",
    "    if col not in test_tmp.columns:\n",
    "        test_tmp[col] = 0\n",
    "\n",
    "test_tmp = test_tmp[train_tmp.columns]\n",
    "test_ft = test_ft.merge(test_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공휴일에 구매한 대분류별 가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 432), (12225, 432))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공휴일에 구매한 대분류별 가격 - train\n",
    "holiday_data = train_tr[train_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_sums = holiday_data.groupby([\"ID\", \"대분류_수정\"])[\"구매가격\"].sum().reset_index()\n",
    "\n",
    "holiday_sums_pivot = holiday_sums.pivot_table(\n",
    "    index=\"ID\",\n",
    "    columns=\"대분류_수정\",\n",
    "    values=\"구매가격\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# 컬럼명 변경\n",
    "holiday_sums_pivot.columns = [\n",
    "    f\"공휴일_대분류수정_{col}_구매금액\" if col != \"ID\" else col\n",
    "    for col in holiday_sums_pivot.columns\n",
    "]\n",
    "\n",
    "train_ft = train_ft.merge(holiday_sums_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_sums_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        train_ft[col] = train_ft[col].fillna(0)\n",
    "\n",
    "# 공휴일에 구매한 대분류별 가격 - test\n",
    "holiday_data = test_tr[test_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_sums = holiday_data.groupby([\"ID\", \"대분류_수정\"])[\"구매가격\"].sum().reset_index()\n",
    "\n",
    "holiday_sums_pivot = holiday_sums.pivot_table(\n",
    "    index=\"ID\",\n",
    "    columns=\"대분류_수정\",\n",
    "    values=\"구매가격\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# 컬럼명 변경\n",
    "holiday_sums_pivot.columns = [\n",
    "    f\"공휴일_대분류수정_{col}_구매금액\" if col != \"ID\" else col\n",
    "    for col in holiday_sums_pivot.columns\n",
    "]\n",
    "\n",
    "test_ft = test_ft.merge(holiday_sums_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_sums_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        test_ft[col] = test_ft[col].fillna(0)\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공휴일에 구매한 대분류별 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 439), (12225, 439))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공휴일에 구매한 대분류별 횟수 - train\n",
    "holiday_data = train_tr[train_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_purchase_counts = holiday_data.groupby([\"ID\", \"대분류_수정\"]).size().reset_index(name=\"공휴일_대분류수정_구매횟수\")\n",
    "\n",
    "holiday_counts_pivot = holiday_purchase_counts.pivot_table(\n",
    "    index=\"ID\",\n",
    "    columns=\"대분류_수정\",\n",
    "    values=\"공휴일_대분류수정_구매횟수\",\n",
    "    fill_value=0  # 공휴일에 해당 대분류를 구매하지 않은 경우 0으로 표시\n",
    ").reset_index()\n",
    "\n",
    "# 컬럼명 변경\n",
    "holiday_counts_pivot.columns = [\n",
    "    f\"공휴일_{col}_대분류수정_구매횟수\" if col != \"ID\" else col\n",
    "    for col in holiday_counts_pivot.columns\n",
    "]\n",
    "\n",
    "train_ft = train_ft.merge(holiday_counts_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_counts_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        train_ft[col] = train_ft[col].fillna(0)\n",
    "\n",
    "\n",
    "# 공휴일에 구매한 대분류별 횟수 - test\n",
    "holiday_data = test_tr[test_tr[\"구매일시\"].dt.date.isin(holidays.date)]\n",
    "\n",
    "holiday_purchase_counts = holiday_data.groupby([\"ID\", \"대분류_수정\"]).size().reset_index(name=\"공휴일_대분류수정_구매횟수\")\n",
    "\n",
    "holiday_counts_pivot = holiday_purchase_counts.pivot_table(\n",
    "    index=\"ID\",\n",
    "    columns=\"대분류_수정\",\n",
    "    values=\"공휴일_대분류수정_구매횟수\",\n",
    "    fill_value=0  # 공휴일에 해당 대분류를 구매하지 않은 경우 0으로 표시\n",
    ").reset_index()\n",
    "\n",
    "# 컬럼명 변경\n",
    "holiday_counts_pivot.columns = [\n",
    "    f\"공휴일_{col}_대분류수정_구매횟수\" if col != \"ID\" else col\n",
    "    for col in holiday_counts_pivot.columns\n",
    "]\n",
    "\n",
    "test_ft = test_ft.merge(holiday_counts_pivot, how='left', on=\"ID\")\n",
    "\n",
    "for col in holiday_counts_pivot.columns:\n",
    "    if col == \"ID\":\n",
    "        pass\n",
    "    else: \n",
    "        test_ft[col] = test_ft[col].fillna(0) \n",
    "    \n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대분류별 최대평균금액  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 441), (12225, 441))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = train_tr.pivot_table(index= [\"ID\", \"대분류_수정\"], values= \"구매가격\", aggfunc= \"mean\")\\\n",
    "      .sort_values(by=['ID', \"구매가격\"], ascending=False).groupby('ID').head(1).reset_index()\n",
    "train_tmp = train_tmp.rename(columns= {\"대분류_수정\": \"대분류_수정_평균금액최대\", \"구매가격\" : \"대분류_수정_평균구매가격\"})\n",
    "train_ft = train_ft.merge(train_tmp, on= \"ID\", how= \"left\")\n",
    "\n",
    "test_tmp = test_tr.pivot_table(index= [\"ID\", \"대분류_수정\"], values= \"구매가격\", aggfunc= \"mean\")\\\n",
    "      .sort_values(by=['ID', \"구매가격\"], ascending=False).groupby('ID').head(1).reset_index()\n",
    "test_tmp = test_tmp.rename(columns= {\"대분류_수정\": \"대분류_수정_평균금액최대\", \"구매가격\" : \"대분류_수정_평균구매가격\"})\n",
    "test_ft = test_ft.merge(test_tmp, on= \"ID\", how= \"left\")\n",
    "\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지점별 대분류_수정 구매 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tmp = train_tr.pivot_table(index= [\"ID\"], columns= [\"지점코드\",\"대분류_수정\"], values= \"구매가격\", aggfunc= \"count\", fill_value=0 ).reset_index()\n",
    "# train_tmp.columns = ['_'.join([col for col in multi_col if len(col)>0]) for multi_col in train_tmp.columns]\n",
    "\n",
    "# train_ft = train_ft.merge(train_tmp, on= \"ID\", how= \"left\")\n",
    "\n",
    "\n",
    "# test_tmp = train_tr.pivot_table(index= [\"ID\"], columns= [\"지점코드\",\"대분류_수정\"], values= \"구매가격\", aggfunc= \"count\", fill_value=0 ).reset_index()\n",
    "# test_tmp.columns = ['_'.join([col for col in multi_col if len(col)>0]) for multi_col in test_tmp.columns]\n",
    "\n",
    "# for col in train_tmp.columns:\n",
    "#     if col not in test_tmp.columns:\n",
    "#         test_tmp[col] = 0\n",
    "# test_tmp = test_tmp[train_tmp.columns]\n",
    "\n",
    "# test_ft = test_ft.merge(test_tmp,how=\"left\",on=\"ID\")\n",
    "\n",
    "# train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LopLwsb3NaE0"
   },
   "source": [
    "# 항상 확인하기\n",
    "- 학습데이터와 테스트 데이터의 피처개수는 동일해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "At-Xx2XoNXDo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14940, 441), (12225, 441))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxEi3_gLM8rh"
   },
   "source": [
    "# 추출한 피처 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "am-hCMk3M3x-"
   },
   "outputs": [],
   "source": [
    "train_ft.to_csv(f\"{DATA_PATH}train_common_v1.1_1101.csv\",index=False)\n",
    "test_ft.to_csv(f\"{DATA_PATH}test_common_v1.1_1101.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = pd.read_csv(f\"{DATA_PATH}train_common_v1.1_1101.csv\")\n",
    "test_ft = pd.read_csv(f\"{DATA_PATH}test_common_v1.1_1101.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.isnull().sum().sum(), test_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft.drop(columns= \"ID\", inplace= True)\n",
    "test_ft.drop(columns= \"ID\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['주구매지점', '주구매_중분류', '주구매_대분류_수정', '대분류_수정_평균금액최대'], dtype='object')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_ft.select_dtypes(\"object\").columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "# 범주형 변수 원핫인코딩\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(train_ft[cols])\n",
    "tmp = pd.DataFrame(\n",
    "    enc.transform(train_ft[cols]).toarray(),\n",
    "    columns = enc.get_feature_names_out()\n",
    ")\n",
    "train_ft = pd.concat([train_ft,tmp],axis=1).drop(columns=cols)\n",
    "\n",
    "tmp = pd.DataFrame(\n",
    "    enc.transform(test_ft[cols]).toarray(),\n",
    "    columns = enc.get_feature_names_out()\n",
    ")\n",
    "test_ft = pd.concat([test_ft,tmp],axis=1).drop(columns=cols)\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_ft)\n",
    "train_ft[train_ft.columns] = scaler.transform(train_ft)\n",
    "test_ft[test_ft.columns] = scaler.transform(test_ft)\n",
    "\n",
    "# 정답 데이터\n",
    "target = train_target[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-01 10:52:52] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 11-01 10:52:52] {1739} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 11-01 10:52:52] {1838} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 11-01 10:52:52] {1955} INFO - List of ML learners in AutoML Run: ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2', 'kneighbor']\n",
      "[flaml.automl.logger: 11-01 10:52:52] {2258} INFO - iteration 0, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:52:59] {2393} INFO - Estimated sufficient time budget=70392s. Estimated necessary time budget=111s.\n",
      "[flaml.automl.logger: 11-01 10:52:59] {2442} INFO -  at 9.1s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:52:59] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:00] {2442} INFO -  at 9.9s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:00] {2258} INFO - iteration 2, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:01] {2442} INFO -  at 10.9s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:01] {2258} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:02] {2442} INFO -  at 11.6s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:02] {2258} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:03] {2442} INFO -  at 12.2s,\testimator xgboost's best error=0.6223,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:03] {2258} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:03] {2442} INFO -  at 12.8s,\testimator xgboost's best error=0.3967,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:03] {2258} INFO - iteration 6, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:53:08] {2442} INFO -  at 17.6s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:08] {2258} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:09] {2442} INFO -  at 18.3s,\testimator lgbm's best error=0.6223,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:09] {2258} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:09] {2442} INFO -  at 18.9s,\testimator lgbm's best error=0.3802,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:09] {2258} INFO - iteration 9, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:09] {2442} INFO -  at 19.2s,\testimator rf's best error=0.4366,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:09] {2258} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:10] {2442} INFO -  at 19.8s,\testimator lgbm's best error=0.3235,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:10] {2258} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:11] {2442} INFO -  at 20.4s,\testimator lgbm's best error=0.3235,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:11] {2258} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:11] {2442} INFO -  at 20.8s,\testimator rf's best error=0.4000,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:11] {2258} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:11] {2442} INFO -  at 21.1s,\testimator rf's best error=0.3835,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:11] {2258} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:12] {2442} INFO -  at 21.5s,\testimator rf's best error=0.3792,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:12] {2258} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:12] {2442} INFO -  at 21.7s,\testimator rf's best error=0.3733,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:12] {2258} INFO - iteration 16, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:12] {2442} INFO -  at 22.1s,\testimator rf's best error=0.3733,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:12] {2258} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:13] {2442} INFO -  at 23.0s,\testimator lgbm's best error=0.3235,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:13] {2258} INFO - iteration 18, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:14] {2442} INFO -  at 23.7s,\testimator histgb's best error=0.6223,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:14] {2258} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:15] {2442} INFO -  at 24.3s,\testimator lgbm's best error=0.3235,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:15] {2258} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:15] {2442} INFO -  at 24.9s,\testimator xgboost's best error=0.3967,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:15] {2258} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:15] {2442} INFO -  at 25.2s,\testimator rf's best error=0.3408,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:16] {2258} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:16] {2442} INFO -  at 25.8s,\testimator xgboost's best error=0.3327,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:16] {2258} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:17] {2442} INFO -  at 26.5s,\testimator lgbm's best error=0.3172,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:17] {2258} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:17] {2442} INFO -  at 26.8s,\testimator rf's best error=0.3408,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:17] {2258} INFO - iteration 25, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:18] {2442} INFO -  at 27.5s,\testimator histgb's best error=0.3656,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:18] {2258} INFO - iteration 26, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:19] {2442} INFO -  at 28.6s,\testimator histgb's best error=0.3490,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:19] {2258} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:19] {2442} INFO -  at 29.1s,\testimator rf's best error=0.3408,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:19] {2258} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:20] {2442} INFO -  at 29.7s,\testimator xgboost's best error=0.3327,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:20] {2258} INFO - iteration 29, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:21] {2442} INFO -  at 30.4s,\testimator histgb's best error=0.3490,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:21] {2258} INFO - iteration 30, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:22] {2442} INFO -  at 31.4s,\testimator histgb's best error=0.3490,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:22] {2258} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:22] {2442} INFO -  at 32.1s,\testimator lgbm's best error=0.3172,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:22] {2258} INFO - iteration 32, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:53:25] {2442} INFO -  at 34.6s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:25] {2258} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:25] {2442} INFO -  at 35.1s,\testimator rf's best error=0.3408,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:25] {2258} INFO - iteration 34, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:28] {2442} INFO -  at 37.5s,\testimator histgb's best error=0.3130,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:28] {2258} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:29] {2442} INFO -  at 38.2s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:29] {2258} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:29] {2442} INFO -  at 38.7s,\testimator rf's best error=0.3408,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:29] {2258} INFO - iteration 37, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:31] {2442} INFO -  at 40.2s,\testimator histgb's best error=0.3130,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:31] {2258} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:31] {2442} INFO -  at 40.6s,\testimator rf's best error=0.3399,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:31] {2258} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:32] {2442} INFO -  at 41.7s,\testimator xgboost's best error=0.3216,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:32] {2258} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:33] {2442} INFO -  at 42.3s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:33] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:34] {2442} INFO -  at 44.0s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:34] {2258} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:36] {2442} INFO -  at 45.2s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:36] {2258} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:53:42] {2442} INFO -  at 51.7s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:42] {2258} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:44] {2442} INFO -  at 54.0s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:44] {2258} INFO - iteration 45, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:53:50] {2442} INFO -  at 59.4s,\testimator histgb's best error=0.3045,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:50] {2258} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:50] {2442} INFO -  at 59.8s,\testimator rf's best error=0.3399,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:50] {2258} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:51] {2442} INFO -  at 60.6s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:51] {2258} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:53:54] {2442} INFO -  at 64.1s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:54] {2258} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:53:55] {2442} INFO -  at 64.9s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:55] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:53:56] {2442} INFO -  at 65.3s,\testimator rf's best error=0.3399,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:53:56] {2258} INFO - iteration 51, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:54:01] {2442} INFO -  at 70.2s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:01] {2258} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:01] {2442} INFO -  at 71.1s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:01] {2258} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:02] {2442} INFO -  at 72.0s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:02] {2258} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:04] {2442} INFO -  at 73.4s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:04] {2258} INFO - iteration 55, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:54:07] {2442} INFO -  at 76.7s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:07] {2258} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:07] {2442} INFO -  at 77.1s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:07] {2258} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:08] {2442} INFO -  at 77.7s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:08] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:08] {2442} INFO -  at 78.1s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:08] {2258} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:09] {2442} INFO -  at 78.4s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:09] {2258} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:09] {2442} INFO -  at 79.1s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:09] {2258} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:10] {2442} INFO -  at 79.5s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:10] {2258} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:11] {2442} INFO -  at 80.3s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:11] {2258} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:11] {2442} INFO -  at 80.7s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:11] {2258} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:54:12] {2442} INFO -  at 81.9s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:12] {2258} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:14] {2442} INFO -  at 83.3s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:14] {2258} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:14] {2442} INFO -  at 83.9s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:14] {2258} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:54:18] {2442} INFO -  at 88.2s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:18] {2258} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:19] {2442} INFO -  at 88.8s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:19] {2258} INFO - iteration 69, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:54:24] {2442} INFO -  at 93.9s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:24] {2258} INFO - iteration 70, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:25] {2442} INFO -  at 94.3s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:25] {2258} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:54:26] {2442} INFO -  at 95.9s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:26] {2258} INFO - iteration 72, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:27] {2442} INFO -  at 96.3s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:27] {2258} INFO - iteration 73, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:54:32] {2442} INFO -  at 101.2s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:32] {2258} INFO - iteration 74, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:32] {2442} INFO -  at 101.8s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:32] {2258} INFO - iteration 75, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:54:34] {2442} INFO -  at 103.4s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:34] {2258} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:35] {2442} INFO -  at 104.5s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:35] {2258} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:36] {2442} INFO -  at 105.2s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:36] {2258} INFO - iteration 78, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:54:39] {2442} INFO -  at 109.0s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:39] {2258} INFO - iteration 79, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:40] {2442} INFO -  at 109.5s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:40] {2258} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:54:41] {2442} INFO -  at 110.2s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:41] {2258} INFO - iteration 81, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:54:43] {2442} INFO -  at 112.4s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:43] {2258} INFO - iteration 82, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:43] {2442} INFO -  at 113.1s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:43] {2258} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:54:49] {2442} INFO -  at 118.7s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:49] {2258} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:54:51] {2442} INFO -  at 120.3s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:51] {2258} INFO - iteration 85, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:54:57] {2442} INFO -  at 126.3s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:57] {2258} INFO - iteration 86, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:54:57] {2442} INFO -  at 126.6s,\testimator rf's best error=0.3365,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:54:57] {2258} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:55:09] {2442} INFO -  at 138.8s,\testimator xgboost's best error=0.2950,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:09] {2258} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:55:10] {2442} INFO -  at 139.5s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:10] {2258} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:55:11] {2442} INFO -  at 140.2s,\testimator lgbm's best error=0.3023,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:11] {2258} INFO - iteration 90, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:55:20] {2442} INFO -  at 149.3s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:20] {2258} INFO - iteration 91, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:20] {2442} INFO -  at 150.0s,\testimator rf's best error=0.3316,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:20] {2258} INFO - iteration 92, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:55:23] {2442} INFO -  at 152.8s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:23] {2258} INFO - iteration 93, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:25] {2442} INFO -  at 154.6s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:25] {2258} INFO - iteration 94, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:26] {2442} INFO -  at 155.5s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:26] {2258} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:55:27] {2442} INFO -  at 156.9s,\testimator lgbm's best error=0.2992,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:27] {2258} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:55:33] {2442} INFO -  at 163.0s,\testimator xgboost's best error=0.2903,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:33] {2258} INFO - iteration 97, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:35] {2442} INFO -  at 164.6s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:35] {2258} INFO - iteration 98, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:36] {2442} INFO -  at 165.3s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:36] {2258} INFO - iteration 99, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:36] {2442} INFO -  at 166.0s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:36] {2258} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:55:37] {2442} INFO -  at 166.8s,\testimator lgbm's best error=0.2992,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:37] {2258} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:55:39] {2442} INFO -  at 168.6s,\testimator xgboost's best error=0.2903,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:39] {2258} INFO - iteration 102, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:40] {2442} INFO -  at 170.1s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:40] {2258} INFO - iteration 103, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:55:45] {2442} INFO -  at 174.3s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:45] {2258} INFO - iteration 104, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:45] {2442} INFO -  at 174.9s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:45] {2258} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:55:46] {2442} INFO -  at 175.9s,\testimator lgbm's best error=0.2992,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:46] {2258} INFO - iteration 106, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:48] {2442} INFO -  at 177.4s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:48] {2258} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:55:55] {2442} INFO -  at 184.9s,\testimator xgboost's best error=0.2903,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:55] {2258} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:55:56] {2442} INFO -  at 185.8s,\testimator lgbm's best error=0.2992,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:56] {2258} INFO - iteration 109, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:55:58] {2442} INFO -  at 187.9s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:58] {2258} INFO - iteration 110, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:55:59] {2442} INFO -  at 189.1s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:55:59] {2258} INFO - iteration 111, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:56:05] {2442} INFO -  at 194.2s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:05] {2258} INFO - iteration 112, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:56:11] {2442} INFO -  at 200.2s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:11] {2258} INFO - iteration 113, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:56:11] {2442} INFO -  at 201.0s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:11] {2258} INFO - iteration 114, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:56:13] {2442} INFO -  at 202.5s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:13] {2258} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:56:14] {2442} INFO -  at 203.7s,\testimator lgbm's best error=0.2992,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:14] {2258} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:56:15] {2442} INFO -  at 205.0s,\testimator lgbm's best error=0.2992,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:15] {2258} INFO - iteration 117, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:56:23] {2442} INFO -  at 212.7s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:23] {2258} INFO - iteration 118, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:56:24] {2442} INFO -  at 213.6s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:24] {2258} INFO - iteration 119, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:56:27] {2442} INFO -  at 216.7s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:27] {2258} INFO - iteration 120, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:56:28] {2442} INFO -  at 217.7s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:28] {2258} INFO - iteration 121, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:56:29] {2442} INFO -  at 218.8s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:29] {2258} INFO - iteration 122, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:56:33] {2442} INFO -  at 222.8s,\testimator lrl2's best error=0.3231,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:33] {2258} INFO - iteration 123, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:56:37] {2442} INFO -  at 226.3s,\testimator lrl2's best error=0.3231,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:37] {2258} INFO - iteration 124, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:56:40] {2442} INFO -  at 229.8s,\testimator lrl2's best error=0.3227,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:40] {2258} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:56:41] {2442} INFO -  at 230.9s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:41] {2258} INFO - iteration 126, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:56:48] {2442} INFO -  at 237.5s,\testimator catboost's best error=0.2901,\tbest estimator catboost's best error=0.2901\n",
      "[flaml.automl.logger: 11-01 10:56:48] {2258} INFO - iteration 127, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:57:00] {2442} INFO -  at 249.7s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:00] {2258} INFO - iteration 128, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:57:09] {2442} INFO -  at 258.9s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:09] {2258} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:57:10] {2442} INFO -  at 259.9s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:10] {2258} INFO - iteration 130, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:57:13] {2442} INFO -  at 262.5s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:13] {2258} INFO - iteration 131, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:57:16] {2442} INFO -  at 265.5s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:16] {2258} INFO - iteration 132, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:57:20] {2442} INFO -  at 269.2s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:20] {2258} INFO - iteration 133, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:57:23] {2442} INFO -  at 272.6s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:23] {2258} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:57:24] {2442} INFO -  at 273.8s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:24] {2258} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:57:27] {2442} INFO -  at 276.9s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:27] {2258} INFO - iteration 136, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:57:28] {2442} INFO -  at 277.5s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:28] {2258} INFO - iteration 137, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:57:31] {2442} INFO -  at 280.8s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:31] {2258} INFO - iteration 138, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:57:32] {2442} INFO -  at 281.8s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:32] {2258} INFO - iteration 139, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:57:36] {2442} INFO -  at 285.7s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:36] {2258} INFO - iteration 140, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:57:38] {2442} INFO -  at 287.6s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:38] {2258} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:57:39] {2442} INFO -  at 288.3s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:39] {2258} INFO - iteration 142, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:57:43] {2442} INFO -  at 292.3s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:43] {2258} INFO - iteration 143, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:57:44] {2442} INFO -  at 293.5s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:44] {2258} INFO - iteration 144, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:57:45] {2442} INFO -  at 295.1s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:45] {2258} INFO - iteration 145, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:57:50] {2442} INFO -  at 299.7s,\testimator xgboost's best error=0.2903,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:50] {2258} INFO - iteration 146, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:57:51] {2442} INFO -  at 300.5s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:51] {2258} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:57:52] {2442} INFO -  at 301.8s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:52] {2258} INFO - iteration 148, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:57:59] {2442} INFO -  at 308.5s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:57:59] {2258} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:58:01] {2442} INFO -  at 310.3s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:01] {2258} INFO - iteration 150, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:58:07] {2442} INFO -  at 316.9s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:07] {2258} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:58:08] {2442} INFO -  at 317.7s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:08] {2258} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:58:09] {2442} INFO -  at 318.6s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:09] {2258} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:58:12] {2442} INFO -  at 321.2s,\testimator xgboost's best error=0.2903,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:12] {2258} INFO - iteration 154, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:58:12] {2442} INFO -  at 321.8s,\testimator rf's best error=0.3233,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:12] {2258} INFO - iteration 155, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:58:19] {2442} INFO -  at 328.7s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:19] {2258} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:58:21] {2442} INFO -  at 330.3s,\testimator lgbm's best error=0.2979,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:21] {2258} INFO - iteration 157, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:58:22] {2442} INFO -  at 331.6s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:22] {2258} INFO - iteration 158, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:58:23] {2442} INFO -  at 332.8s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:23] {2258} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:58:24] {2442} INFO -  at 333.9s,\testimator lgbm's best error=0.2969,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:24] {2258} INFO - iteration 160, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:25] {2442} INFO -  at 334.4s,\testimator kneighbor's best error=0.3826,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:25] {2258} INFO - iteration 161, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:25] {2442} INFO -  at 334.8s,\testimator kneighbor's best error=0.3806,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:25] {2258} INFO - iteration 162, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:26] {2442} INFO -  at 335.3s,\testimator kneighbor's best error=0.3659,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:26] {2258} INFO - iteration 163, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:26] {2442} INFO -  at 335.8s,\testimator kneighbor's best error=0.3547,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:26] {2258} INFO - iteration 164, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:27] {2442} INFO -  at 336.3s,\testimator kneighbor's best error=0.3547,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:27] {2258} INFO - iteration 165, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:27] {2442} INFO -  at 336.9s,\testimator kneighbor's best error=0.3390,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:27] {2258} INFO - iteration 166, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:28] {2442} INFO -  at 337.5s,\testimator kneighbor's best error=0.3387,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:28] {2258} INFO - iteration 167, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:28] {2442} INFO -  at 338.1s,\testimator kneighbor's best error=0.3387,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:28] {2258} INFO - iteration 168, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:29] {2442} INFO -  at 338.8s,\testimator kneighbor's best error=0.3387,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:29] {2258} INFO - iteration 169, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:30] {2442} INFO -  at 339.4s,\testimator kneighbor's best error=0.3387,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:30] {2258} INFO - iteration 170, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:30] {2442} INFO -  at 339.9s,\testimator kneighbor's best error=0.3372,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:30] {2258} INFO - iteration 171, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:58:31] {2442} INFO -  at 340.6s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:31] {2258} INFO - iteration 172, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:58:40] {2442} INFO -  at 349.4s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:40] {2258} INFO - iteration 173, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:58:41] {2442} INFO -  at 350.5s,\testimator lgbm's best error=0.2969,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:41] {2258} INFO - iteration 174, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:41] {2442} INFO -  at 351.0s,\testimator kneighbor's best error=0.3372,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:41] {2258} INFO - iteration 175, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:42] {2442} INFO -  at 351.6s,\testimator kneighbor's best error=0.3372,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:42] {2258} INFO - iteration 176, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:42] {2442} INFO -  at 352.1s,\testimator kneighbor's best error=0.3372,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:42] {2258} INFO - iteration 177, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:58:44] {2442} INFO -  at 353.4s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:44] {2258} INFO - iteration 178, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:44] {2442} INFO -  at 353.9s,\testimator kneighbor's best error=0.3348,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:44] {2258} INFO - iteration 179, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:45] {2442} INFO -  at 354.4s,\testimator kneighbor's best error=0.3348,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:45] {2258} INFO - iteration 180, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:45] {2442} INFO -  at 355.1s,\testimator kneighbor's best error=0.3348,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:45] {2258} INFO - iteration 181, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:46] {2442} INFO -  at 355.7s,\testimator kneighbor's best error=0.3348,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:46] {2258} INFO - iteration 182, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:47] {2442} INFO -  at 356.2s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:47] {2258} INFO - iteration 183, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:47] {2442} INFO -  at 356.8s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:47] {2258} INFO - iteration 184, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:58:52] {2442} INFO -  at 361.9s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:52] {2258} INFO - iteration 185, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:58:58] {2442} INFO -  at 367.2s,\testimator lgbm's best error=0.2969,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:58] {2258} INFO - iteration 186, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:58] {2442} INFO -  at 367.8s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:58] {2258} INFO - iteration 187, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:58:59] {2442} INFO -  at 368.3s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:58:59] {2258} INFO - iteration 188, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:59:01] {2442} INFO -  at 370.7s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:01] {2258} INFO - iteration 189, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:01] {2442} INFO -  at 371.1s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:01] {2258} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:59:02] {2442} INFO -  at 371.8s,\testimator lgbm's best error=0.2969,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:02] {2258} INFO - iteration 191, current learner histgb\n",
      "[flaml.automl.logger: 11-01 10:59:06] {2442} INFO -  at 375.9s,\testimator histgb's best error=0.2914,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:06] {2258} INFO - iteration 192, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:07] {2442} INFO -  at 376.4s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:07] {2258} INFO - iteration 193, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:59:09] {2442} INFO -  at 378.5s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:09] {2258} INFO - iteration 194, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:09] {2442} INFO -  at 379.1s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:09] {2258} INFO - iteration 195, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:10] {2442} INFO -  at 379.6s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:10] {2258} INFO - iteration 196, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:10] {2442} INFO -  at 380.1s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:10] {2258} INFO - iteration 197, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:59:11] {2442} INFO -  at 381.0s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:11] {2258} INFO - iteration 198, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:59:13] {2442} INFO -  at 382.7s,\testimator lgbm's best error=0.2969,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:13] {2258} INFO - iteration 199, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:13] {2442} INFO -  at 383.2s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:13] {2258} INFO - iteration 200, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:14] {2442} INFO -  at 383.8s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:14] {2258} INFO - iteration 201, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:15] {2442} INFO -  at 384.2s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:15] {2258} INFO - iteration 202, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:15] {2442} INFO -  at 384.8s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:15] {2258} INFO - iteration 203, current learner catboost\n",
      "[flaml.automl.logger: 11-01 10:59:21] {2442} INFO -  at 390.7s,\testimator catboost's best error=0.2877,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:21] {2258} INFO - iteration 204, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:59:22] {2442} INFO -  at 391.7s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:22] {2258} INFO - iteration 205, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:23] {2442} INFO -  at 392.3s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:23] {2258} INFO - iteration 206, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:23] {2442} INFO -  at 392.8s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:23] {2258} INFO - iteration 207, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:24] {2442} INFO -  at 393.3s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:24] {2258} INFO - iteration 208, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:59:25] {2442} INFO -  at 394.7s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:25] {2258} INFO - iteration 209, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:26] {2442} INFO -  at 395.2s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:26] {2258} INFO - iteration 210, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:59:27] {2442} INFO -  at 396.5s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:27] {2258} INFO - iteration 211, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:59:28] {2442} INFO -  at 398.0s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:28] {2258} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:59:41] {2442} INFO -  at 410.8s,\testimator xgboost's best error=0.2903,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:41] {2258} INFO - iteration 213, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:59:43] {2442} INFO -  at 412.5s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:43] {2258} INFO - iteration 214, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 10:59:45] {2442} INFO -  at 414.3s,\testimator lrl2's best error=0.3207,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:45] {2258} INFO - iteration 215, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:45] {2442} INFO -  at 414.8s,\testimator kneighbor's best error=0.3307,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:45] {2258} INFO - iteration 216, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:46] {2442} INFO -  at 415.4s,\testimator kneighbor's best error=0.3261,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:46] {2258} INFO - iteration 217, current learner rf\n",
      "[flaml.automl.logger: 11-01 10:59:47] {2442} INFO -  at 416.3s,\testimator rf's best error=0.3182,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:47] {2258} INFO - iteration 218, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 10:59:47] {2442} INFO -  at 416.9s,\testimator kneighbor's best error=0.3261,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:47] {2258} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:59:48] {2442} INFO -  at 417.8s,\testimator lgbm's best error=0.2969,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:48] {2258} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:59:50] {2442} INFO -  at 419.8s,\testimator lgbm's best error=0.2969,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:50] {2258} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 10:59:51] {2442} INFO -  at 420.5s,\testimator lgbm's best error=0.2944,\tbest estimator catboost's best error=0.2877\n",
      "[flaml.automl.logger: 11-01 10:59:51] {2258} INFO - iteration 222, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 10:59:57] {2442} INFO -  at 427.2s,\testimator xgboost's best error=0.2829,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 10:59:57] {2258} INFO - iteration 223, current learner catboost\n",
      "[flaml.automl.logger: 11-01 11:00:05] {2442} INFO -  at 434.7s,\testimator catboost's best error=0.2877,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:05] {2258} INFO - iteration 224, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:06] {2442} INFO -  at 435.3s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:06] {2258} INFO - iteration 225, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:06] {2442} INFO -  at 436.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:06] {2258} INFO - iteration 226, current learner catboost\n",
      "[flaml.automl.logger: 11-01 11:00:11] {2442} INFO -  at 440.7s,\testimator catboost's best error=0.2877,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:11] {2258} INFO - iteration 227, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:00:13] {2442} INFO -  at 442.9s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:13] {2258} INFO - iteration 228, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:00:15] {2442} INFO -  at 445.0s,\testimator rf's best error=0.3182,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:15] {2258} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:00:16] {2442} INFO -  at 445.5s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:16] {2258} INFO - iteration 230, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:16] {2442} INFO -  at 445.9s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:16] {2258} INFO - iteration 231, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:00:17] {2442} INFO -  at 446.6s,\testimator rf's best error=0.3182,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:17] {2258} INFO - iteration 232, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:17] {2442} INFO -  at 447.1s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:17] {2258} INFO - iteration 233, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:00:19] {2442} INFO -  at 448.5s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:19] {2258} INFO - iteration 234, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:19] {2442} INFO -  at 449.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:19] {2258} INFO - iteration 235, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:20] {2442} INFO -  at 449.4s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:20] {2258} INFO - iteration 236, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:20] {2442} INFO -  at 450.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:20] {2258} INFO - iteration 237, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 11:00:24] {2442} INFO -  at 454.0s,\testimator xgboost's best error=0.2829,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:24] {2258} INFO - iteration 238, current learner histgb\n",
      "[flaml.automl.logger: 11-01 11:00:26] {2442} INFO -  at 455.6s,\testimator histgb's best error=0.2914,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:26] {2258} INFO - iteration 239, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:26] {2442} INFO -  at 456.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:26] {2258} INFO - iteration 240, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:00:30] {2442} INFO -  at 459.4s,\testimator rf's best error=0.3182,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:30] {2258} INFO - iteration 241, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 11:00:31] {2442} INFO -  at 460.8s,\testimator xgboost's best error=0.2829,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:31] {2258} INFO - iteration 242, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:00:32] {2442} INFO -  at 461.9s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:32] {2258} INFO - iteration 243, current learner catboost\n",
      "[flaml.automl.logger: 11-01 11:00:38] {2442} INFO -  at 467.3s,\testimator catboost's best error=0.2877,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:38] {2258} INFO - iteration 244, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:00:39] {2442} INFO -  at 468.5s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:39] {2258} INFO - iteration 245, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:00:40] {2442} INFO -  at 469.5s,\testimator rf's best error=0.3182,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:40] {2258} INFO - iteration 246, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:40] {2442} INFO -  at 470.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:40] {2258} INFO - iteration 247, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:00:42] {2442} INFO -  at 471.5s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:42] {2258} INFO - iteration 248, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:42] {2442} INFO -  at 471.9s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:42] {2258} INFO - iteration 249, current learner histgb\n",
      "[flaml.automl.logger: 11-01 11:00:49] {2442} INFO -  at 478.7s,\testimator histgb's best error=0.2914,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:49] {2258} INFO - iteration 250, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:00:51] {2442} INFO -  at 480.6s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:51] {2258} INFO - iteration 251, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:52] {2442} INFO -  at 481.3s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:52] {2258} INFO - iteration 252, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:00:53] {2442} INFO -  at 482.5s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:53] {2258} INFO - iteration 253, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:00:53] {2442} INFO -  at 483.0s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:53] {2258} INFO - iteration 254, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:00:56] {2442} INFO -  at 485.2s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:56] {2258} INFO - iteration 255, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:00:57] {2442} INFO -  at 486.2s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:57] {2258} INFO - iteration 256, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:00:57] {2442} INFO -  at 486.7s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:00:57] {2258} INFO - iteration 257, current learner catboost\n",
      "[flaml.automl.logger: 11-01 11:01:02] {2442} INFO -  at 492.0s,\testimator catboost's best error=0.2877,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:02] {2258} INFO - iteration 258, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:03] {2442} INFO -  at 492.4s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:03] {2258} INFO - iteration 259, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:04] {2442} INFO -  at 493.6s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:04] {2258} INFO - iteration 260, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:04] {2442} INFO -  at 494.1s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:04] {2258} INFO - iteration 261, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:01:05] {2442} INFO -  at 495.1s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:05] {2258} INFO - iteration 262, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:06] {2442} INFO -  at 495.6s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:06] {2258} INFO - iteration 263, current learner histgb\n",
      "[flaml.automl.logger: 11-01 11:01:07] {2442} INFO -  at 496.7s,\testimator histgb's best error=0.2914,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:07] {2258} INFO - iteration 264, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:01:08] {2442} INFO -  at 497.8s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:08] {2258} INFO - iteration 265, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:01:09] {2442} INFO -  at 498.6s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:09] {2258} INFO - iteration 266, current learner histgb\n",
      "[flaml.automl.logger: 11-01 11:01:15] {2442} INFO -  at 504.2s,\testimator histgb's best error=0.2914,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:15] {2258} INFO - iteration 267, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:15] {2442} INFO -  at 504.7s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:15] {2258} INFO - iteration 268, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:16] {2442} INFO -  at 505.4s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:16] {2258} INFO - iteration 269, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:16] {2442} INFO -  at 506.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:16] {2258} INFO - iteration 270, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:17] {2442} INFO -  at 506.5s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:17] {2258} INFO - iteration 271, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:17] {2442} INFO -  at 507.1s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:17] {2258} INFO - iteration 272, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:18] {2442} INFO -  at 508.2s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:18] {2258} INFO - iteration 273, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:01:20] {2442} INFO -  at 509.3s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:20] {2258} INFO - iteration 274, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:22] {2442} INFO -  at 511.3s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:22] {2258} INFO - iteration 275, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:23] {2442} INFO -  at 512.9s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:23] {2258} INFO - iteration 276, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:25] {2442} INFO -  at 514.6s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:25] {2258} INFO - iteration 277, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:33] {2442} INFO -  at 522.4s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:33] {2258} INFO - iteration 278, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:33] {2442} INFO -  at 523.0s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:33] {2258} INFO - iteration 279, current learner histgb\n",
      "[flaml.automl.logger: 11-01 11:01:35] {2442} INFO -  at 525.0s,\testimator histgb's best error=0.2914,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:35] {2258} INFO - iteration 280, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:37] {2442} INFO -  at 526.4s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:37] {2258} INFO - iteration 281, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:37] {2442} INFO -  at 526.9s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:37] {2258} INFO - iteration 282, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:01:38] {2442} INFO -  at 528.1s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:38] {2258} INFO - iteration 283, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:01:39] {2442} INFO -  at 528.8s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:39] {2258} INFO - iteration 284, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:41] {2442} INFO -  at 530.4s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:41] {2258} INFO - iteration 285, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:01:42] {2442} INFO -  at 531.5s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:42] {2258} INFO - iteration 286, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:42] {2442} INFO -  at 531.9s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:42] {2258} INFO - iteration 287, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:43] {2442} INFO -  at 532.5s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:43] {2258} INFO - iteration 288, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:43] {2442} INFO -  at 533.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:43] {2258} INFO - iteration 289, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:01:44] {2442} INFO -  at 534.0s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:44] {2258} INFO - iteration 290, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:01:45] {2442} INFO -  at 534.6s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:45] {2258} INFO - iteration 291, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:01:47] {2442} INFO -  at 536.4s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:47] {2258} INFO - iteration 292, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:01:47] {2442} INFO -  at 537.0s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:01:47] {2258} INFO - iteration 293, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 11:02:21] {2442} INFO -  at 571.0s,\testimator xgboost's best error=0.2829,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:02:21] {2258} INFO - iteration 294, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:02:22] {2442} INFO -  at 571.7s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:02:22] {2258} INFO - iteration 295, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 11:02:27] {2442} INFO -  at 577.1s,\testimator xgboost's best error=0.2829,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:02:27] {2258} INFO - iteration 296, current learner lrl2\n",
      "[flaml.automl.logger: 11-01 11:02:29] {2442} INFO -  at 578.5s,\testimator lrl2's best error=0.3207,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:02:29] {2258} INFO - iteration 297, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:02:32] {2442} INFO -  at 581.9s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:02:32] {2258} INFO - iteration 298, current learner kneighbor\n",
      "[flaml.automl.logger: 11-01 11:02:33] {2442} INFO -  at 582.6s,\testimator kneighbor's best error=0.3261,\tbest estimator xgboost's best error=0.2829\n",
      "[flaml.automl.logger: 11-01 11:02:33] {2258} INFO - iteration 299, current learner xgboost\n",
      "[flaml.automl.logger: 11-01 11:02:45] {2442} INFO -  at 595.1s,\testimator xgboost's best error=0.2794,\tbest estimator xgboost's best error=0.2794\n",
      "[flaml.automl.logger: 11-01 11:02:45] {2258} INFO - iteration 300, current learner rf\n",
      "[flaml.automl.logger: 11-01 11:02:47] {2442} INFO -  at 596.3s,\testimator rf's best error=0.3133,\tbest estimator xgboost's best error=0.2794\n",
      "[flaml.automl.logger: 11-01 11:02:47] {2258} INFO - iteration 301, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:02:47] {2442} INFO -  at 597.0s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2794\n",
      "[flaml.automl.logger: 11-01 11:02:47] {2258} INFO - iteration 302, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:02:49] {2442} INFO -  at 599.1s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2794\n",
      "[flaml.automl.logger: 11-01 11:02:49] {2258} INFO - iteration 303, current learner lgbm\n",
      "[flaml.automl.logger: 11-01 11:02:50] {2442} INFO -  at 599.8s,\testimator lgbm's best error=0.2944,\tbest estimator xgboost's best error=0.2794\n",
      "[flaml.automl.logger: 11-01 11:02:50] {2258} INFO - iteration 304, current learner lrl1\n",
      "[flaml.automl.logger: 11-01 11:03:04] {2442} INFO -  at 614.1s,\testimator lrl1's best error=0.3209,\tbest estimator xgboost's best error=0.2794\n",
      "[flaml.automl.logger: 11-01 11:03:04] {2582} INFO - [('xgboost', {'n_jobs': -1, 'n_estimators': 255, 'max_leaves': 20, 'min_child_weight': 1.843590113813109, 'learning_rate': 0.1426274236886358, 'subsample': 0.8599550297484456, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0026784891535010275, 'reg_lambda': 2.585411888246577, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('catboost', {'early_stopping_rounds': 12, 'learning_rate': 0.06891048966671508, 'n_estimators': 287, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('histgb', {'min_samples_leaf': 33, 'learning_rate': 0.3206465064026392, 'l2_regularization': 126.12571893717568, 'max_iter': 48, 'max_bins': 31, 'max_leaf_nodes': 793, 'random_state': 24092023, 'verbose': 0}), ('lgbm', {'n_jobs': -1, 'n_estimators': 56, 'num_leaves': 4, 'min_child_samples': 128, 'learning_rate': 1.0, 'colsample_bytree': 0.9326367491412826, 'reg_alpha': 0.011436769982531715, 'reg_lambda': 12.68199078717473, 'max_bin': 31, 'verbose': -1}), ('rf', {'n_jobs': -1, 'n_estimators': 53, 'max_features': 0.05730286383808376, 'criterion': 'entropy', 'max_leaf_nodes': 645, 'random_state': 12032022, 'verbose': 0}), ('lrl2', {'n_jobs': -1, 'C': 0.03125, 'tol': 0.0001, 'solver': 'lbfgs', 'penalty': 'l2'}), ('lrl1', {'n_jobs': -1, 'C': 1.0, 'tol': 0.0001, 'solver': 'saga', 'penalty': 'l1'}), ('kneighbor', {'n_jobs': -1, 'n_neighbors': 128, 'weights': 'distance'})]\n",
      "[flaml.automl.logger: 11-01 11:03:04] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 11-01 11:06:26] {2631} INFO - ensemble: StackingClassifier(estimators=[('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x000002CAA9B74790>),\n",
      "                               ('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x000002CA9DA69BA0>),\n",
      "                               ('histgb',\n",
      "                                <flaml.automl.contrib.histgb.HistGradientBoostingEstimator object at 0x000002CA9AAB7B50>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x000002CA9A...\n",
      "                                                   interaction_constraints=None,\n",
      "                                                   max_bin=None,\n",
      "                                                   max_cat_threshold=None,\n",
      "                                                   max_cat_to_onehot=None,\n",
      "                                                   max_delta_step=None,\n",
      "                                                   max_depth=None,\n",
      "                                                   max_leaves=None,\n",
      "                                                   min_child_weight=None,\n",
      "                                                   missing=nan,\n",
      "                                                   monotone_constraints=None,\n",
      "                                                   multi_strategy=None,\n",
      "                                                   n_estimators=None,\n",
      "                                                   n_jobs=None,\n",
      "                                                   num_parallel_tree=None,\n",
      "                                                   objective='binary:logistic',\n",
      "                                                   random_state=None,\n",
      "                                                   reg_alpha=None, ...),\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 11-01 11:06:26] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-01 11:06:26] {1986} INFO - Time taken to find the best model: 595.0983853340149\n",
      "[flaml.automl.logger: 11-01 11:06:26] {1996} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import xgboost \n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "auto_ml_ens = AutoML()\n",
    "params = { \"metric\" : \"macro_f1\",\n",
    "           \"task\" : \"classification\",\n",
    "           \"time_budget\" : 60*10,\n",
    "           \"seed\" : 42,\n",
    "           \"early_stop\" : True,\n",
    "           \"ensemble\" : {'final_estimator' : XGBRFClassifier() },    # 메타모델이 로지스틱 회귀!\n",
    "           \"estimator_list\" : ['catboost', 'lgbm', 'rf', 'xgboost', 'histgb', 'lrl1', 'lrl2', 'kneighbor']  }   # 앙상블에 사용할 모델 지정\n",
    "auto_ml_ens.fit(train_ft, target, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3366871165644172"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = auto_ml_ens.predict(test_ft)\n",
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = pred\n",
    "\n",
    "submit.to_csv(\"6조_v1.1_1101.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
